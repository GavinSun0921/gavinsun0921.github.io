<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[CVPR'22] Deblurring via Stochastic Refinement | Gavin's Home</title><meta name=keywords content="Diffusion,DPM,Computer Vision,Low-level Vision,Deep Learning"><meta name=description content="Image deblurring with &ldquo;predict-and-refine&rdquo; conditional diffusion model. An brand new strategy for ill-posed problem."><meta name=author content><link rel=canonical href=https://gavinsun0921.github.io/posts/fast-paper-reading-01/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://gavinsun0921.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://gavinsun0921.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://gavinsun0921.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://gavinsun0921.github.io/apple-touch-icon.png><link rel=mask-icon href=https://gavinsun0921.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://gavinsun0921.github.io/posts/fast-paper-reading-01/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css integrity=sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js integrity=sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js integrity=sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],ignoredTags:["script","noscript","style","textarea","pre"],throwOnError:!1})'></script><meta property="og:url" content="https://gavinsun0921.github.io/posts/fast-paper-reading-01/"><meta property="og:site_name" content="Gavin's Home"><meta property="og:title" content="[CVPR'22] Deblurring via Stochastic Refinement"><meta property="og:description" content="Image deblurring with “predict-and-refine” conditional diffusion model. An brand new strategy for ill-posed problem."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-07-22T00:00:00+00:00"><meta property="article:modified_time" content="2023-07-22T00:00:00+00:00"><meta property="article:tag" content="Diffusion"><meta property="article:tag" content="DPM"><meta property="article:tag" content="Computer Vision"><meta property="article:tag" content="Low-Level Vision"><meta property="article:tag" content="Deep Learning"><meta name=twitter:card content="summary"><meta name=twitter:title content="[CVPR'22] Deblurring via Stochastic Refinement"><meta name=twitter:description content="Image deblurring with &ldquo;predict-and-refine&rdquo; conditional diffusion model. An brand new strategy for ill-posed problem."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://gavinsun0921.github.io/posts/"},{"@type":"ListItem","position":2,"name":"[CVPR'22] Deblurring via Stochastic Refinement","item":"https://gavinsun0921.github.io/posts/fast-paper-reading-01/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[CVPR'22] Deblurring via Stochastic Refinement","name":"[CVPR\u002722] Deblurring via Stochastic Refinement","description":"Image deblurring with \u0026ldquo;predict-and-refine\u0026rdquo; conditional diffusion model. An brand new strategy for ill-posed problem.","keywords":["Diffusion","DPM","Computer Vision","Low-level Vision","Deep Learning"],"articleBody":" This paper is published in CVPR 2022. Overview Problem Image deblurring is an ill-posed problem, and most existing mothods are ineffective because they produce a deterministic estimate of the clean image. Point-estimators that directly minimize a distortion loss suffers from the problem of “regression to the mean”. Solution Present a new framework for blind deblurring based on conditional diffusion models. Porducing a diverse set of plausible reconstructions for a given input. Results A significant improvement in perceptual qulity over existing state-of-the-art methods across multiple standard benchmarks. Much more efficient sampling compared to typical diffusion models. Challenging the widely used strategy of producing a single, deterministic reconstruction. Related Work Diffusion Probabilistic Models I’ve written a blog about diffusion probabilistic models (DPM). It has the derivation of the basic formulas of the DPM as well as a simple code implementation.\nA Breif Exploration to Diffusion Probabilistic Models with Code Implementation. The Perception-Distortion Tradeoff Fig. 1. The perception-distortion tradeoff. (Image source: Blau et al. 2018 with a few additional annotations) The ability of a model on a curve is the same. When perceptual metrics get better (smaller y-axis), distortion metrics get worse (bigger x-axis), and vice versa. Usually non-GAN models will tend to be more towards the upper left corner, while GAN models will tend to be more towards the lower right corner.\nMethod This paper introduce a “predict-and-refine” conditional diffusion model, where a deterministic data-adaptive predictor is jointly trained with a stochastic sampler that refines the output of the said predictor (see Fig. 2).\nFig. 2. Diagram of dual-network architechture. (Image source: Jay et al. 2022) The method in this paper is to use an initial predictor $g_\\theta$ to process the blurry image to get the initial prediction, and then models the residual of ground truth and initial prediction using a conditional diffusion model. Fig. 3. Diagram of U-Net architechture used for both the denoiser network and the initial predictor. Note that the input and output depicted here are for the denoiser network. (Image source: Jay et al. 2022) The loss function of predict-and-refine diffusion model in paper is Eq. (6). $$ L_{\\text{Ours}}(\\theta) = \\mathbb{E} \\left \\| \\mathbf{\\epsilon} - f_\\theta \\left ( \\sqrt{\\bar{\\alpha}} (\\underbrace{ \\mathbf{x}_0 - g_\\theta({\\color{red} \\mathbf{x}_0})}_{\\text{residual}}) + \\sqrt{1 - \\bar{\\alpha}} \\epsilon, \\bar{\\alpha}, \\mathbf{y} \\right ) \\right \\| \\tag{6} $$ Gaution! The red part of Eq. (6) is wrong. Here, $\\mathbf{x}_0$ and $g_\\theta$ stands for ground truth and initial predictor. The residual portion in the lower brackets should be the residual of ground truth and initial prediction. Therefore, the input to $g_\\theta$ should be the blurry image $\\mathbf{y}$.\nExperimental Study Quantitative Results The “SA” suffix in the table stands for Sample Averaging, i.e. averaging over multiple samples. This operation can significantly improve the distortion metrics at the expense of the perception metrics.\nTable 1. Image deblurring results on the GoPro dataset (Nah et al. 2017). Best values and second-best values for each metric are color-coded. (Table source: Jay et al. 2022 as a screenshot) Table 2. Image deblurring results on the HIDE dataset (Shen et al. 2019). Best values and second-best values for each metric are color-coded. (Table source: Jay et al. 2022 as a screenshot) The model in this paper achieves state-of-the-art performance across all perceptual metrics while maintaining competitive PSNR and SSIM to existing methods.\nP-D tradeoff Inference steps (T): 10, 20, 30, 50, 100, 200, 300, 500. Fig. 4. Additional Perception-Distortion plots with respect to different metrics. Left column contains perceptual metrics vs. PSNR, and the right column contains SSIM comparisons.(Image source: Jay et al. 2022) Traversing the Perception-Distortion curve: The more steps sampled, the better the subjective quality, and vice versa for the objective quality.\nNetwork Architecture Ablation Study Table 3. Ablation study on the effects of various hyperparameters. (Table source: Jay et al. 2022 as a screenshot) As the results show, all three hyperparameters were critical to the model’s performance.\nSummary The diffusion model is successfully applied to the deblurring task, enhancing the stochastic process of generating clear images. Good results were achieved in the quality of reconstruction observed by the human, and the metrics, such as PSNR, are comparable. The biggest highlight is that the idea of residual is proposed in the model, which makes the inference faster, and together with the initial inference achieved good results.\nReferences [1] Whang Jay et al. “Deblurring via Stochastic Refinement.” CVPR 2022.\n[2] Yochai Blau \u0026 Tomer Michaeli. “The Perception-Distortion Tradeoff.” CVPR 2018.\n[3] Seungjun Nah et al. “Deep Multi-Scale Convolutional Neural Network for Dynamic Scene Deblurring.” CVPR 2017.\n[4] Ziyi Shen et al. “Human-Aware Motion Deblurring.” ICCV 2019.\n","wordCount":"761","inLanguage":"en","datePublished":"2023-07-22T00:00:00Z","dateModified":"2023-07-22T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://gavinsun0921.github.io/posts/fast-paper-reading-01/"},"publisher":{"@type":"Organization","name":"Gavin's Home","logo":{"@type":"ImageObject","url":"https://gavinsun0921.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://gavinsun0921.github.io/ accesskey=h title="Gavin's Home (Alt + H)">Gavin's Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://gavinsun0921.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://gavinsun0921.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://gavinsun0921.github.io/archive/ title=Archive><span>Archive</span></a></li><li><a href=https://gavinsun0921.github.io/about/ title=AboutMe><span>AboutMe</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">[CVPR'22] Deblurring via Stochastic Refinement</h1><div class=post-meta><span title='2023-07-22 00:00:00 +0000 UTC'>July 22, 2023</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;761 words</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#overview aria-label=Overview>Overview</a><ul><li><a href=#problem aria-label=Problem>Problem</a></li><li><a href=#solution aria-label=Solution>Solution</a></li><li><a href=#results aria-label=Results>Results</a></li></ul></li><li><a href=#related-work aria-label="Related Work">Related Work</a><ul><li><a href=#diffusion-probabilistic-models aria-label="Diffusion Probabilistic Models">Diffusion Probabilistic Models</a></li><li><a href=#the-perception-distortion-tradeoff aria-label="The Perception-Distortion Tradeoff">The Perception-Distortion Tradeoff</a></li></ul></li><li><a href=#method aria-label=Method>Method</a></li><li><a href=#experimental-study aria-label="Experimental Study">Experimental Study</a><ul><li><a href=#quantitative-results aria-label="Quantitative Results">Quantitative Results</a></li><li><a href=#p-d-tradeoff aria-label="P-D tradeoff">P-D tradeoff</a></li><li><a href=#network-architecture-ablation-study aria-label="Network Architecture Ablation Study">Network Architecture Ablation Study</a></li></ul></li><li><a href=#summary aria-label=Summary>Summary</a></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div><div class=post-content><ul><li><strong><a href=https://openaccess.thecvf.com/content/CVPR2022/html/Whang_Deblurring_via_Stochastic_Refinement_CVPR_2022_paper.html><strong>This paper</strong></a> is published in CVPR 2022.</strong></li></ul><h2 id=overview>Overview<a hidden class=anchor aria-hidden=true href=#overview>#</a></h2><h3 id=problem>Problem<a hidden class=anchor aria-hidden=true href=#problem>#</a></h3><ul><li>Image deblurring is an ill-posed problem, and most existing mothods are ineffective because they produce a deterministic estimate of the clean image.</li><li>Point-estimators that directly minimize a distortion loss suffers from the problem of &ldquo;regression to the mean&rdquo;.</li></ul><h3 id=solution>Solution<a hidden class=anchor aria-hidden=true href=#solution>#</a></h3><ul><li>Present a new framework for blind deblurring based on conditional diffusion models.</li><li>Porducing a diverse set of plausible reconstructions for a given input.</li></ul><h3 id=results>Results<a hidden class=anchor aria-hidden=true href=#results>#</a></h3><ul><li>A significant improvement in perceptual qulity over existing state-of-the-art methods across multiple standard benchmarks.</li><li>Much more efficient sampling compared to typical diffusion models.</li><li>Challenging the widely used strategy of producing a single, deterministic reconstruction.</li></ul><h2 id=related-work>Related Work<a hidden class=anchor aria-hidden=true href=#related-work>#</a></h2><h3 id=diffusion-probabilistic-models>Diffusion Probabilistic Models<a hidden class=anchor aria-hidden=true href=#diffusion-probabilistic-models>#</a></h3><p>I&rsquo;ve written a blog about diffusion probabilistic models (DPM). It has the derivation of the basic formulas of the DPM as well as a simple code implementation.</p><ul><li><a href=https://gavinsun0921.github.io/posts/paper-reading-01/>A Breif Exploration to Diffusion Probabilistic Models with Code Implementation</a>.</li></ul><h3 id=the-perception-distortion-tradeoff>The Perception-Distortion Tradeoff<a hidden class=anchor aria-hidden=true href=#the-perception-distortion-tradeoff>#</a></h3><div align=center><img src=P-D-tradeoff.png style=zoom:40% alt>
Fig. 1. The perception-distortion tradeoff. (Image source:<br><a href=https://openaccess.thecvf.com/content_cvpr_2018/html/Blau_The_Perception-Distortion_Tradeoff_CVPR_2018_paper.html>Blau <i>et al.</i> 2018</a> with a few additional annotations)</div><p>The ability of a model on a curve is the same. When perceptual metrics get better (smaller y-axis), distortion metrics get worse (bigger x-axis), and vice versa. Usually non-GAN models will tend to be more towards the upper left corner, while GAN models will tend to be more towards the lower right corner.</p><h2 id=method>Method<a hidden class=anchor aria-hidden=true href=#method>#</a></h2><p>This paper introduce a <strong>&ldquo;predict-and-refine&rdquo; conditional diffusion model</strong>, where a deterministic data-adaptive predictor is jointly trained with a stochastic sampler that refines the output of the said predictor (see Fig. 2).</p><div align=center><img src=diagram.png style=zoom:30% alt>
Fig. 2. Diagram of dual-network architechture. (Image source: <a href=https://openaccess.thecvf.com/content/CVPR2022/html/Whang_Deblurring_via_Stochastic_Refinement_CVPR_2022_paper.html>Jay <i>et al.</i> 2022</a>)</div>The method in this paper is to use an initial predictor $g_\theta$ to process the blurry image to get the initial prediction, and then models the residual of ground truth and initial prediction using a conditional diffusion model.<div align=center><img src=unet.png style=zoom:70% alt>
Fig. 3. Diagram of U-Net architechture used for both the denoiser network and<br>the initial predictor. Note that the input and output depicted here are for the<br>denoiser network. (Image source: <a href=https://openaccess.thecvf.com/content/CVPR2022/html/Whang_Deblurring_via_Stochastic_Refinement_CVPR_2022_paper.html>Jay <i>et al.</i> 2022</a>)</div><p>The loss function of <strong>predict-and-refine diffusion model</strong> in paper is Eq. (6).
$$
L_{\text{Ours}}(\theta) = \mathbb{E} \left \| \mathbf{\epsilon} - f_\theta \left ( \sqrt{\bar{\alpha}} (\underbrace{ \mathbf{x}_0 - g_\theta({\color{red} \mathbf{x}_0})}_{\text{residual}}) + \sqrt{1 - \bar{\alpha}} \epsilon, \bar{\alpha}, \mathbf{y} \right ) \right \| \tag{6}
$$
<strong>Gaution! The red part of Eq. (6) is wrong.</strong> Here, $\mathbf{x}_0$ and $g_\theta$ stands for ground truth and initial predictor. The residual portion in the lower brackets should be the residual of ground truth and initial prediction. Therefore, the input to $g_\theta$ should be the blurry image $\mathbf{y}$.</p><h2 id=experimental-study>Experimental Study<a hidden class=anchor aria-hidden=true href=#experimental-study>#</a></h2><h3 id=quantitative-results>Quantitative Results<a hidden class=anchor aria-hidden=true href=#quantitative-results>#</a></h3><p>The &ldquo;SA&rdquo; suffix in the table stands for Sample Averaging, i.e. averaging over multiple samples. This operation can significantly improve the distortion metrics at the expense of the perception metrics.</p><div align=center>Table 1. Image deblurring results on the GoPro dataset (<a href=https://openaccess.thecvf.com/content_cvpr_2017/papers/Nah_Deep_Multi-Scale_Convolutional_CVPR_2017_paper.pdf>Nah <i>et al.</i> 2017</a>).<br><span style=background-color:#d9d9ff>Best values</span> and <span style=background-color:#d9ffd9>second-best values</span> for each metric are color-coded.<br>(Table source: <a href=https://openaccess.thecvf.com/content/CVPR2022/html/Whang_Deblurring_via_Stochastic_Refinement_CVPR_2022_paper.html>Jay <i>et al.</i> 2022</a> as a screenshot)
<img src=table1.png style=zoom:50% alt></div><div align=center>Table 2. Image deblurring results on the HIDE dataset (<a href=https://openaccess.thecvf.com/content_ICCV_2019/papers/Shen_Human-Aware_Motion_Deblurring_ICCV_2019_paper.pdf>Shen <i>et al.</i> 2019</a>).<br><span style=background-color:#d9d9ff>Best values</span> and <span style=background-color:#d9ffd9>second-best values</span> for each metric are color-coded.<br>(Table source: <a href=https://openaccess.thecvf.com/content/CVPR2022/html/Whang_Deblurring_via_Stochastic_Refinement_CVPR_2022_paper.html>Jay <i>et al.</i> 2022</a> as a screenshot)
<img src=table2.png style=zoom:50% alt></div><p>The model in this paper achieves state-of-the-art performance across <strong>all perceptual metrics</strong> while maintaining competitive PSNR and SSIM to existing methods.</p><h3 id=p-d-tradeoff>P-D tradeoff<a hidden class=anchor aria-hidden=true href=#p-d-tradeoff>#</a></h3><ul><li>Inference steps (T): 10, 20, 30, 50, 100, 200, 300, 500.</li></ul><div align=center><img src=trade-off.png style=zoom:80% alt>
Fig. 4. Additional Perception-Distortion plots with respect to different metrics.<br>Left column contains perceptual metrics vs. PSNR, and the right column<br>contains SSIM comparisons.(Image source: <a href=https://openaccess.thecvf.com/content/CVPR2022/html/Whang_Deblurring_via_Stochastic_Refinement_CVPR_2022_paper.html>Jay <i>et al.</i> 2022</a>)</div><p>Traversing the Perception-Distortion curve: The more steps sampled, the better the subjective quality, and vice versa for the objective quality.</p><h3 id=network-architecture-ablation-study>Network Architecture Ablation Study<a hidden class=anchor aria-hidden=true href=#network-architecture-ablation-study>#</a></h3><div align=center>Table 3. Ablation study on the effects of various hyperparameters.<br>(Table source: <a href=https://openaccess.thecvf.com/content/CVPR2022/html/Whang_Deblurring_via_Stochastic_Refinement_CVPR_2022_paper.html>Jay <i>et al.</i> 2022</a> as a screenshot)
<img src=table3.png style=zoom:50% alt></div><p>As the results show, all three hyperparameters were critical to the model&rsquo;s performance.</p><h2 id=summary>Summary<a hidden class=anchor aria-hidden=true href=#summary>#</a></h2><p>The diffusion model is successfully applied to the deblurring task, enhancing the stochastic process of generating clear images. Good results were achieved in the quality of reconstruction observed by the human, and the metrics, such as PSNR, are comparable. The biggest highlight is that the idea of residual is proposed in the model, which makes the inference faster, and together with the initial inference achieved good results.</p><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><p>[1] Whang Jay <em>et al</em>. <a href=https://openaccess.thecvf.com/content/CVPR2022/html/Whang_Deblurring_via_Stochastic_Refinement_CVPR_2022_paper.html>&ldquo;Deblurring via Stochastic Refinement.&rdquo;</a> CVPR 2022.</p><p>[2] Yochai Blau & Tomer Michaeli. <a href=https://openaccess.thecvf.com/content_cvpr_2018/html/Blau_The_Perception-Distortion_Tradeoff_CVPR_2018_paper.html>&ldquo;The Perception-Distortion Tradeoff.&rdquo;</a> CVPR 2018.</p><p>[3] Seungjun Nah <em>et al</em>. <a href=https://openaccess.thecvf.com/content_cvpr_2017/html/Nah_Deep_Multi-Scale_Convolutional_CVPR_2017_paper.html>&ldquo;Deep Multi-Scale Convolutional Neural Network for Dynamic Scene Deblurring.&rdquo;</a> CVPR 2017.</p><p>[4] Ziyi Shen <em>et al</em>. <a href=https://openaccess.thecvf.com/content_ICCV_2019/html/Shen_Human-Aware_Motion_Deblurring_ICCV_2019_paper.html>&ldquo;Human-Aware Motion Deblurring.&rdquo;</a> ICCV 2019.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://gavinsun0921.github.io/tags/diffusion/>Diffusion</a></li><li><a href=https://gavinsun0921.github.io/tags/dpm/>DPM</a></li><li><a href=https://gavinsun0921.github.io/tags/computer-vision/>Computer Vision</a></li><li><a href=https://gavinsun0921.github.io/tags/low-level-vision/>Low-Level Vision</a></li><li><a href=https://gavinsun0921.github.io/tags/deep-learning/>Deep Learning</a></li></ul><nav class=paginav><a class=prev href=https://gavinsun0921.github.io/posts/fast-paper-reading-02/><span class=title>« Prev</span><br><span>[T-PAMI'23] Image Super-Resolution via Iterative Refinement</span>
</a><a class=next href=https://gavinsun0921.github.io/posts/paper-research-01/><span class=title>Next »</span><br><span>A Brief Exploration to Diffusion Probabilistic Models with Code Implementation</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share [CVPR'22] Deblurring via Stochastic Refinement on x" href="https://x.com/intent/tweet/?text=%5bCVPR%2722%5d%20Deblurring%20via%20Stochastic%20Refinement&amp;url=https%3a%2f%2fgavinsun0921.github.io%2fposts%2ffast-paper-reading-01%2f&amp;hashtags=Diffusion%2cDPM%2cComputerVision%2cLow-levelVision%2cDeepLearning"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CVPR'22] Deblurring via Stochastic Refinement on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fgavinsun0921.github.io%2fposts%2ffast-paper-reading-01%2f&amp;title=%5bCVPR%2722%5d%20Deblurring%20via%20Stochastic%20Refinement&amp;summary=%5bCVPR%2722%5d%20Deblurring%20via%20Stochastic%20Refinement&amp;source=https%3a%2f%2fgavinsun0921.github.io%2fposts%2ffast-paper-reading-01%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CVPR'22] Deblurring via Stochastic Refinement on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fgavinsun0921.github.io%2fposts%2ffast-paper-reading-01%2f&title=%5bCVPR%2722%5d%20Deblurring%20via%20Stochastic%20Refinement"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CVPR'22] Deblurring via Stochastic Refinement on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fgavinsun0921.github.io%2fposts%2ffast-paper-reading-01%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CVPR'22] Deblurring via Stochastic Refinement on whatsapp" href="https://api.whatsapp.com/send?text=%5bCVPR%2722%5d%20Deblurring%20via%20Stochastic%20Refinement%20-%20https%3a%2f%2fgavinsun0921.github.io%2fposts%2ffast-paper-reading-01%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CVPR'22] Deblurring via Stochastic Refinement on telegram" href="https://telegram.me/share/url?text=%5bCVPR%2722%5d%20Deblurring%20via%20Stochastic%20Refinement&amp;url=https%3a%2f%2fgavinsun0921.github.io%2fposts%2ffast-paper-reading-01%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CVPR'22] Deblurring via Stochastic Refinement on ycombinator" href="https://news.ycombinator.com/submitlink?t=%5bCVPR%2722%5d%20Deblurring%20via%20Stochastic%20Refinement&u=https%3a%2f%2fgavinsun0921.github.io%2fposts%2ffast-paper-reading-01%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://gavinsun0921.github.io/>Gavin's Home</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>