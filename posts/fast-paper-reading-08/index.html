<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[ICCV'25 Highlight] Shape of Motion: 4D Reconstruction from a Single Video 阅读报告 | Gavin Sun · Spatial Intelligence</title><meta name=keywords content="Point Tracking,4D Reconstruction,Gaussian Splatting,Computer Vision"><meta name=description content="这篇文章提出了一种从单目视频中重建动态场景并估计长程 3D 运动轨迹的新方法。"><meta name=author content><link rel=canonical href=https://gavinsun0921.github.io/posts/fast-paper-reading-08/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://gavinsun0921.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://gavinsun0921.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://gavinsun0921.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://gavinsun0921.github.io/apple-touch-icon.png><link rel=mask-icon href=https://gavinsun0921.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://gavinsun0921.github.io/posts/fast-paper-reading-08/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css integrity=sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js integrity=sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js integrity=sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],ignoredTags:["script","noscript","style","textarea","pre"],throwOnError:!1})'></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-18P7N9RZDS"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-18P7N9RZDS")</script><meta property="og:url" content="https://gavinsun0921.github.io/posts/fast-paper-reading-08/"><meta property="og:site_name" content="Gavin Sun · Spatial Intelligence"><meta property="og:title" content="[ICCV'25 Highlight] Shape of Motion: 4D Reconstruction from a Single Video 阅读报告"><meta property="og:description" content="这篇文章提出了一种从单目视频中重建动态场景并估计长程 3D 运动轨迹的新方法。"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-12-11T00:00:00+00:00"><meta property="article:modified_time" content="2025-12-11T00:00:00+00:00"><meta property="article:tag" content="Point Tracking"><meta property="article:tag" content="4D Reconstruction"><meta property="article:tag" content="Gaussian Splatting"><meta property="article:tag" content="Computer Vision"><meta name=twitter:card content="summary"><meta name=twitter:title content="[ICCV'25 Highlight] Shape of Motion: 4D Reconstruction from a Single Video 阅读报告"><meta name=twitter:description content="这篇文章提出了一种从单目视频中重建动态场景并估计长程 3D 运动轨迹的新方法。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://gavinsun0921.github.io/posts/"},{"@type":"ListItem","position":2,"name":"[ICCV'25 Highlight] Shape of Motion: 4D Reconstruction from a Single Video 阅读报告","item":"https://gavinsun0921.github.io/posts/fast-paper-reading-08/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[ICCV'25 Highlight] Shape of Motion: 4D Reconstruction from a Single Video 阅读报告","name":"[ICCV\u002725 Highlight] Shape of Motion: 4D Reconstruction from a Single Video 阅读报告","description":"这篇文章提出了一种从单目视频中重建动态场景并估计长程 3D 运动轨迹的新方法。","keywords":["Point Tracking","4D Reconstruction","Gaussian Splatting","Computer Vision"],"articleBody":" 这篇文章提出了一种从单目视频中重建动态场景并估计长程 3D 运动轨迹的新方法。\n1. 核心背景与动机 (Motivation \u0026 Challenges) 1.1 问题定义 该研究旨在解决**单目视频 (Monocular Video)**中重建复杂动态场景的几何形状 (3D Geometry)和长程 3D 运动轨迹 (Long-range 3D Motion)这一难题。\n1.2 现有挑战 首先这是一个病态问题 (ill-posed nature)：从单视角恢复动态 3D 场景极其困难，因为每个时刻只能从一个视点观察到移动到物体。\n现有方法的局限性：\n大多数方法依赖多视角视频或 LiDAR 深度传感器。 现有的弹幕方法通常只建模短程场景流 (Scene Flow)，或者仅适用于准静态场景/相机瞬移场景，无法捕捉持续的长程 3D 轨迹。 纯 2D 跟踪方法（如 TAPIR）虽然强大，但缺乏 3D 几何和运动感知。 1.3 核心洞察 (Key Insights) 运动的低维性：虽然图像空间的 2D 动态可能很复杂，但底层的 3D 运动通常是由简单的刚体运动单元组成（例如多个刚体部件的组合）。 数据驱动先验的融合：利用现有的强大先验模型（如弹幕深度估计、长程 2D 跟踪）提供的含噪信号，可以通过优化框架融合为全局一致的 3D 表示。 2. 核心方法 (Methodology) 该方法将动态场景表示为一组**持久的 3D 高斯体 (Persistent 3D Gaussians)，这些高斯体随时间进行平移和旋转。\n2.1 场景表示 (Scene Representation) Canonical 3D Gaussians：场景由 N 个定义在规范帧 (Canonical Frame, $t_0$) 中的 3D 高斯体表示，包含位置、旋转、尺度、不透明度和颜色参数。 SE(3)运动基 (SE(3) Motion Bases)：为了利用运动的低维特性，作者定义了一组全局共享的 SE(3) 运动基 $\\left\\{ T^{(b)} \\right\\}^B_{b=1}(B«N)$。每个高斯体的运动不是独立优化的，而是由这些基的线性组合决定的。 $T_{0\\to t} = \\sum_{t=0}^B w^{(b)} T^{(b)}_{0\\to t}$，其中$w^{(b)}$是每个高斯体特有的运动系数。 这种设计强制了运动的低秩约束，使得运动相似的高斯体（属于同一刚体）具有相似的系数。 2.2 优化流程与先验融合 (Optimization \u0026 Priors) 该系统是一个测试时优化 (Test-time Optimization) 框架，利用现成的工具提取先验信息作为输入：\n输入准备： Camera Pose：使用 MegaSAM 或 COLMAP 估计。 移动物体掩码：使用 Track-Anything。 单目深度图：使用 Depth-Anything，并进行对齐处理。 长程 2D 轨迹：使用 TAPIR 提取前景点的 2D 轨迹。 初始化： 将 2D 轨迹利用深度图 Lift 为含噪声的 3D 轨迹。 通过对这些噪声轨迹的速度进行 K-means 聚类，初始化 SE(3) 运动基。 监督损失函数 (Loss Functions)： 重建损失：渲染出的 RGB 图像、深度图和掩码与输入视频及先验深度/掩码一致。 2D 轨迹损失：渲染出的 3D 轨迹投影回 2D 屏幕后，应与 TAPIR 预测的 2D 轨迹匹配。 刚性/物理先验：强制动态高斯体与其邻居之间的距离随时间保持不变（局部刚性约束）。 3. 实验结果 (Experiments) 作者在合成数据集 (Kubric MOVi-F) 和真实世界数据集 (iPhone Dataset, NVIDIA Dataset) 上进行了广泛评估。\n3.1 评估任务与指标 Long-Range 3D Tracking：指标为 3D EPE 和准确率。 Long-Range 2D Tracking：指标包括 Average Jaccard (AJ) 和遮挡准确率 (OA)。 Novel View Systhesis：指标包括 PSNR, SSIM, LPIPS。 3.2 主要结果 iPhone Dataset (真实场景)： 在所有三个任务上均达到了 SOTA。 3D 跟踪：相比于简单的 “TAPIR + Depth Anything” 组合，该方法显著降低了误差 (EPE 从 0.114 降低至 0.082)，证明了全局优化能有效修正噪声先验。 对比 NeRF/3DGS：相比 HyperNeRF、DynIBaR 和 Deformable-3D-GS，该方法在保持高质量渲染的同时，提供了更准确的运动轨迹。 Kubric Dataset (合成场景)： 在具有快速运动和运动模糊的场景中，该方法的 3D 跟踪精度优于仅依赖 2D 跟踪器加深度提升的 baseline。 可视化效果： 能够生成被称为 “Shape of Motion” 的彩色 3D 轨迹，揭示了物体运动的几何模式（如旋转的风车、抛出的物体）。 PCA 分析显示，优化后的运动系数能够自动将场景分解为不同的刚体运动组。 3.3 消融实验 (Ablation Studies) SE(3) 基的重要性：使用 SE(3) 基比仅使用平移基 (Traslation Bases) 或者每个高斯体独立运动 (Per-Gaussian) 效果更好，能有效减少伪影并提升精度。 2D 轨迹监督的重要性：去掉 2D 轨迹损失会导致性能显著下降，证明了长程 2D 跟踪先验对恢复 3D 运动至关重要。 4. 总结与讨论 (Conclusion) 4.1 主要贡献 提出了一种 4D 场景表示，结合了持久的 3D 高斯体和紧凑的 SE(3) 运动基，支持实时 NVS 和全局一致的 3D 跟踪。 设计了一个优化框架，成功地将单目深度和长程 2D 轨迹等噪声先验融合为一个物理一致的动态场景模型。 在单目视频的 3D/2D 跟踪和 NVS 任务上取得了 SOTA 性能。 4.2 局限性 需要针对每个场景进行测试时优化（Test-time optimization），无法做到实时流式处理。 依赖于现成的先验模型（如相机位姿、掩码），如果这些先验在无纹理区域或剧烈运动下失效，重建质量会下降。 目前需要用户交互来指定移动物体的掩码。 4.3 总结 这篇工作是单目动态场景重建领域的重要进展，它通过显式建模 3D 运动轨迹并融合多模态先验，解决了传统方法难以兼顾渲染质量和运动估计精度的问题。\n","wordCount":"1894","inLanguage":"en","datePublished":"2025-12-11T00:00:00Z","dateModified":"2025-12-11T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://gavinsun0921.github.io/posts/fast-paper-reading-08/"},"publisher":{"@type":"Organization","name":"Gavin Sun · Spatial Intelligence","logo":{"@type":"ImageObject","url":"https://gavinsun0921.github.io/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://gavinsun0921.github.io/ accesskey=h title="Spatial Intelligence (Alt + H)">Spatial Intelligence</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://gavinsun0921.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://gavinsun0921.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://gavinsun0921.github.io/archive/ title=Archive><span>Archive</span></a></li><li><a href=https://gavinsun0921.github.io/about/ title=AboutMe><span>AboutMe</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">[ICCV'25 Highlight] Shape of Motion: 4D Reconstruction from a Single Video 阅读报告</h1><div class=post-meta><span title='2025-12-11 00:00:00 +0000 UTC'>December 11, 2025</span>&nbsp;·&nbsp;<span>4 min</span>&nbsp;·&nbsp;<span>1894 words</span></div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#1-%e6%a0%b8%e5%bf%83%e8%83%8c%e6%99%af%e4%b8%8e%e5%8a%a8%e6%9c%ba-motivation--challenges aria-label="1. 核心背景与动机 (Motivation & Challenges)">1. 核心背景与动机 (Motivation & Challenges)</a><ul><li><a href=#11-%e9%97%ae%e9%a2%98%e5%ae%9a%e4%b9%89 aria-label="1.1 问题定义">1.1 问题定义</a></li><li><a href=#12-%e7%8e%b0%e6%9c%89%e6%8c%91%e6%88%98 aria-label="1.2 现有挑战">1.2 现有挑战</a></li><li><a href=#13-%e6%a0%b8%e5%bf%83%e6%b4%9e%e5%af%9f-key-insights aria-label="1.3 核心洞察 (Key Insights)">1.3 核心洞察 (Key Insights)</a></li></ul></li><li><a href=#2-%e6%a0%b8%e5%bf%83%e6%96%b9%e6%b3%95-methodology aria-label="2. 核心方法 (Methodology)">2. 核心方法 (Methodology)</a><ul><li><a href=#21-%e5%9c%ba%e6%99%af%e8%a1%a8%e7%a4%ba-scene-representation aria-label="2.1 场景表示 (Scene Representation)">2.1 场景表示 (Scene Representation)</a></li><li><a href=#22-%e4%bc%98%e5%8c%96%e6%b5%81%e7%a8%8b%e4%b8%8e%e5%85%88%e9%aa%8c%e8%9e%8d%e5%90%88-optimization--priors aria-label="2.2 优化流程与先验融合 (Optimization & Priors)">2.2 优化流程与先验融合 (Optimization & Priors)</a></li></ul></li><li><a href=#3-%e5%ae%9e%e9%aa%8c%e7%bb%93%e6%9e%9c-experiments aria-label="3. 实验结果 (Experiments)">3. 实验结果 (Experiments)</a><ul><li><a href=#31-%e8%af%84%e4%bc%b0%e4%bb%bb%e5%8a%a1%e4%b8%8e%e6%8c%87%e6%a0%87 aria-label="3.1 评估任务与指标">3.1 评估任务与指标</a></li><li><a href=#32-%e4%b8%bb%e8%a6%81%e7%bb%93%e6%9e%9c aria-label="3.2 主要结果">3.2 主要结果</a></li><li><a href=#33-%e6%b6%88%e8%9e%8d%e5%ae%9e%e9%aa%8c-ablation-studies aria-label="3.3 消融实验 (Ablation Studies)">3.3 消融实验 (Ablation Studies)</a></li></ul></li><li><a href=#4-%e6%80%bb%e7%bb%93%e4%b8%8e%e8%ae%a8%e8%ae%ba-conclusion aria-label="4. 总结与讨论 (Conclusion)">4. 总结与讨论 (Conclusion)</a><ul><li><a href=#41-%e4%b8%bb%e8%a6%81%e8%b4%a1%e7%8c%ae aria-label="4.1 主要贡献">4.1 主要贡献</a></li><li><a href=#42-%e5%b1%80%e9%99%90%e6%80%a7 aria-label="4.2 局限性">4.2 局限性</a></li><li><a href=#43-%e6%80%bb%e7%bb%93 aria-label="4.3 总结">4.3 总结</a></li></ul></li></ul></div></details></div><div class=post-content><figure class=align-center><img src=images/cover.png width=100% style="display:block;margin:0 auto"></figure><p>这篇文章提出了一种从单目视频中重建动态场景并估计长程 3D 运动轨迹的新方法。</p><h2 id=1-核心背景与动机-motivation--challenges>1. 核心背景与动机 (Motivation & Challenges)<a hidden class=anchor aria-hidden=true href=#1-核心背景与动机-motivation--challenges>#</a></h2><h3 id=11-问题定义>1.1 问题定义<a hidden class=anchor aria-hidden=true href=#11-问题定义>#</a></h3><p>该研究旨在解决**单目视频 (Monocular Video)**中重建复杂动态场景的几何形状 (3D Geometry)和长程 3D 运动轨迹 (Long-range 3D Motion)这一难题。</p><h3 id=12-现有挑战>1.2 现有挑战<a hidden class=anchor aria-hidden=true href=#12-现有挑战>#</a></h3><p>首先这是一个病态问题 (ill-posed nature)：从单视角恢复动态 3D 场景极其困难，因为每个时刻只能从一个视点观察到移动到物体。</p><p>现有方法的局限性：</p><ul><li>大多数方法依赖多视角视频或 LiDAR 深度传感器。</li><li>现有的弹幕方法通常只建模短程场景流 (Scene Flow)，或者仅适用于准静态场景/相机瞬移场景，无法捕捉持续的长程 3D 轨迹。</li><li>纯 2D 跟踪方法（如 TAPIR）虽然强大，但缺乏 3D 几何和运动感知。</li></ul><h3 id=13-核心洞察-key-insights>1.3 核心洞察 (Key Insights)<a hidden class=anchor aria-hidden=true href=#13-核心洞察-key-insights>#</a></h3><ol><li>运动的低维性：虽然图像空间的 2D 动态可能很复杂，但底层的 3D 运动通常是由简单的刚体运动单元组成（例如多个刚体部件的组合）。</li><li>数据驱动先验的融合：利用现有的强大先验模型（如弹幕深度估计、长程 2D 跟踪）提供的含噪信号，可以通过优化框架融合为全局一致的 3D 表示。</li></ol><h2 id=2-核心方法-methodology>2. 核心方法 (Methodology)<a hidden class=anchor aria-hidden=true href=#2-核心方法-methodology>#</a></h2><p>该方法将动态场景表示为一组**持久的 3D 高斯体 (Persistent 3D Gaussians)，这些高斯体随时间进行平移和旋转。</p><h3 id=21-场景表示-scene-representation>2.1 场景表示 (Scene Representation)<a hidden class=anchor aria-hidden=true href=#21-场景表示-scene-representation>#</a></h3><ul><li><strong>Canonical 3D Gaussians</strong>：场景由 N 个定义在规范帧 (Canonical Frame, $t_0$) 中的 3D 高斯体表示，包含位置、旋转、尺度、不透明度和颜色参数。</li><li><strong>SE(3)运动基 (SE(3) Motion Bases)</strong>：为了利用运动的低维特性，作者定义了一组全局共享的 SE(3) 运动基 $\left\{ T^{(b)} \right\}^B_{b=1}(B&#171;N)$。每个高斯体的运动不是独立优化的，而是由这些基的线性组合决定的。<ul><li>$T_{0\to t} = \sum_{t=0}^B w^{(b)} T^{(b)}_{0\to t}$，其中$w^{(b)}$是每个高斯体特有的运动系数。</li><li>这种设计强制了运动的低秩约束，使得运动相似的高斯体（属于同一刚体）具有相似的系数。</li></ul></li></ul><h3 id=22-优化流程与先验融合-optimization--priors>2.2 优化流程与先验融合 (Optimization & Priors)<a hidden class=anchor aria-hidden=true href=#22-优化流程与先验融合-optimization--priors>#</a></h3><p>该系统是一个测试时优化 (Test-time Optimization) 框架，利用现成的工具提取先验信息作为输入：</p><ol><li>输入准备：<ul><li>Camera Pose：使用 MegaSAM 或 COLMAP 估计。</li><li>移动物体掩码：使用 Track-Anything。</li><li>单目深度图：使用 Depth-Anything，并进行对齐处理。</li><li>长程 2D 轨迹：使用 TAPIR 提取前景点的 2D 轨迹。</li></ul></li><li>初始化：<ul><li>将 2D 轨迹利用深度图 Lift 为含噪声的 3D 轨迹。</li><li>通过对这些噪声轨迹的速度进行 K-means 聚类，初始化 SE(3) 运动基。</li></ul></li><li>监督损失函数 (Loss Functions)：<ul><li>重建损失：渲染出的 RGB 图像、深度图和掩码与输入视频及先验深度/掩码一致。</li><li>2D 轨迹损失：渲染出的 3D 轨迹投影回 2D 屏幕后，应与 TAPIR 预测的 2D 轨迹匹配。</li><li>刚性/物理先验：强制动态高斯体与其邻居之间的距离随时间保持不变（局部刚性约束）。</li></ul></li></ol><h2 id=3-实验结果-experiments>3. 实验结果 (Experiments)<a hidden class=anchor aria-hidden=true href=#3-实验结果-experiments>#</a></h2><p>作者在合成数据集 (Kubric MOVi-F) 和真实世界数据集 (iPhone Dataset, NVIDIA Dataset) 上进行了广泛评估。</p><h3 id=31-评估任务与指标>3.1 评估任务与指标<a hidden class=anchor aria-hidden=true href=#31-评估任务与指标>#</a></h3><ul><li>Long-Range 3D Tracking：指标为 3D EPE 和准确率。</li><li>Long-Range 2D Tracking：指标包括 Average Jaccard (AJ) 和遮挡准确率 (OA)。</li><li>Novel View Systhesis：指标包括 PSNR, SSIM, LPIPS。</li></ul><h3 id=32-主要结果>3.2 主要结果<a hidden class=anchor aria-hidden=true href=#32-主要结果>#</a></h3><ul><li>iPhone Dataset (真实场景)：<ul><li>在所有三个任务上均达到了 SOTA。</li><li>3D 跟踪：相比于简单的 &ldquo;TAPIR + Depth Anything&rdquo; 组合，该方法显著降低了误差 (EPE 从 0.114 降低至 0.082)，证明了全局优化能有效修正噪声先验。</li><li>对比 NeRF/3DGS：相比 HyperNeRF、DynIBaR 和 Deformable-3D-GS，该方法在保持高质量渲染的同时，提供了更准确的运动轨迹。</li></ul></li><li>Kubric Dataset (合成场景)：<ul><li>在具有快速运动和运动模糊的场景中，该方法的 3D 跟踪精度优于仅依赖 2D 跟踪器加深度提升的 baseline。</li></ul></li><li>可视化效果：<ul><li>能够生成被称为 &ldquo;Shape of Motion&rdquo; 的彩色 3D 轨迹，揭示了物体运动的几何模式（如旋转的风车、抛出的物体）。</li><li>PCA 分析显示，优化后的运动系数能够自动将场景分解为不同的刚体运动组。</li></ul></li></ul><h3 id=33-消融实验-ablation-studies>3.3 消融实验 (Ablation Studies)<a hidden class=anchor aria-hidden=true href=#33-消融实验-ablation-studies>#</a></h3><ul><li>SE(3) 基的重要性：使用 SE(3) 基比仅使用平移基 (Traslation Bases) 或者每个高斯体独立运动 (Per-Gaussian) 效果更好，能有效减少伪影并提升精度。</li><li>2D 轨迹监督的重要性：去掉 2D 轨迹损失会导致性能显著下降，证明了长程 2D 跟踪先验对恢复 3D 运动至关重要。</li></ul><h2 id=4-总结与讨论-conclusion>4. 总结与讨论 (Conclusion)<a hidden class=anchor aria-hidden=true href=#4-总结与讨论-conclusion>#</a></h2><h3 id=41-主要贡献>4.1 主要贡献<a hidden class=anchor aria-hidden=true href=#41-主要贡献>#</a></h3><ol><li>提出了一种 4D 场景表示，结合了持久的 3D 高斯体和紧凑的 SE(3) 运动基，支持实时 NVS 和全局一致的 3D 跟踪。</li><li>设计了一个优化框架，成功地将单目深度和长程 2D 轨迹等噪声先验融合为一个物理一致的动态场景模型。</li><li>在单目视频的 3D/2D 跟踪和 NVS 任务上取得了 SOTA 性能。</li></ol><h3 id=42-局限性>4.2 局限性<a hidden class=anchor aria-hidden=true href=#42-局限性>#</a></h3><ul><li>需要针对每个场景进行测试时优化（Test-time optimization），无法做到实时流式处理。</li><li>依赖于现成的先验模型（如相机位姿、掩码），如果这些先验在无纹理区域或剧烈运动下失效，重建质量会下降。</li><li>目前需要用户交互来指定移动物体的掩码。</li></ul><h3 id=43-总结>4.3 总结<a hidden class=anchor aria-hidden=true href=#43-总结>#</a></h3><p>这篇工作是单目动态场景重建领域的重要进展，它通过显式建模 3D 运动轨迹并融合多模态先验，解决了传统方法难以兼顾渲染质量和运动估计精度的问题。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://gavinsun0921.github.io/tags/point-tracking/>Point Tracking</a></li><li><a href=https://gavinsun0921.github.io/tags/4d-reconstruction/>4D Reconstruction</a></li><li><a href=https://gavinsun0921.github.io/tags/gaussian-splatting/>Gaussian Splatting</a></li><li><a href=https://gavinsun0921.github.io/tags/computer-vision/>Computer Vision</a></li></ul><nav class=paginav><a class=prev href=https://gavinsun0921.github.io/posts/fast-paper-reading-09/><span class=title>« Prev</span><br><span>[arXiv'2512] Efficiently Reconstructing Dynamic Scenes One 🎯 D4RT at a Time 阅读报告</span>
</a><a class=next href=https://gavinsun0921.github.io/posts/fast-paper-reading-07/><span class=title>Next »</span><br><span>[arXiv'2512] Generative Video Motion Editing with 3D Point Tracks 阅读报告</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share [ICCV'25 Highlight] Shape of Motion: 4D Reconstruction from a Single Video 阅读报告 on x" href="https://x.com/intent/tweet/?text=%5bICCV%2725%20Highlight%5d%20Shape%20of%20Motion%3a%204D%20Reconstruction%20from%20a%20Single%20Video%20%e9%98%85%e8%af%bb%e6%8a%a5%e5%91%8a&amp;url=https%3a%2f%2fgavinsun0921.github.io%2fposts%2ffast-paper-reading-08%2f&amp;hashtags=PointTracking%2c4DReconstruction%2cGaussianSplatting%2cComputerVision"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [ICCV'25 Highlight] Shape of Motion: 4D Reconstruction from a Single Video 阅读报告 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fgavinsun0921.github.io%2fposts%2ffast-paper-reading-08%2f&amp;title=%5bICCV%2725%20Highlight%5d%20Shape%20of%20Motion%3a%204D%20Reconstruction%20from%20a%20Single%20Video%20%e9%98%85%e8%af%bb%e6%8a%a5%e5%91%8a&amp;summary=%5bICCV%2725%20Highlight%5d%20Shape%20of%20Motion%3a%204D%20Reconstruction%20from%20a%20Single%20Video%20%e9%98%85%e8%af%bb%e6%8a%a5%e5%91%8a&amp;source=https%3a%2f%2fgavinsun0921.github.io%2fposts%2ffast-paper-reading-08%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [ICCV'25 Highlight] Shape of Motion: 4D Reconstruction from a Single Video 阅读报告 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fgavinsun0921.github.io%2fposts%2ffast-paper-reading-08%2f&title=%5bICCV%2725%20Highlight%5d%20Shape%20of%20Motion%3a%204D%20Reconstruction%20from%20a%20Single%20Video%20%e9%98%85%e8%af%bb%e6%8a%a5%e5%91%8a"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [ICCV'25 Highlight] Shape of Motion: 4D Reconstruction from a Single Video 阅读报告 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fgavinsun0921.github.io%2fposts%2ffast-paper-reading-08%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [ICCV'25 Highlight] Shape of Motion: 4D Reconstruction from a Single Video 阅读报告 on whatsapp" href="https://api.whatsapp.com/send?text=%5bICCV%2725%20Highlight%5d%20Shape%20of%20Motion%3a%204D%20Reconstruction%20from%20a%20Single%20Video%20%e9%98%85%e8%af%bb%e6%8a%a5%e5%91%8a%20-%20https%3a%2f%2fgavinsun0921.github.io%2fposts%2ffast-paper-reading-08%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [ICCV'25 Highlight] Shape of Motion: 4D Reconstruction from a Single Video 阅读报告 on telegram" href="https://telegram.me/share/url?text=%5bICCV%2725%20Highlight%5d%20Shape%20of%20Motion%3a%204D%20Reconstruction%20from%20a%20Single%20Video%20%e9%98%85%e8%af%bb%e6%8a%a5%e5%91%8a&amp;url=https%3a%2f%2fgavinsun0921.github.io%2fposts%2ffast-paper-reading-08%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [ICCV'25 Highlight] Shape of Motion: 4D Reconstruction from a Single Video 阅读报告 on ycombinator" href="https://news.ycombinator.com/submitlink?t=%5bICCV%2725%20Highlight%5d%20Shape%20of%20Motion%3a%204D%20Reconstruction%20from%20a%20Single%20Video%20%e9%98%85%e8%af%bb%e6%8a%a5%e5%91%8a&u=https%3a%2f%2fgavinsun0921.github.io%2fposts%2ffast-paper-reading-08%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer><script src=https://giscus.app/client.js data-repo=GavinSun0921/gavinsun0921.github.io data-repo-id=R_kgDOJgiWSg data-category=Announcements data-category-id=DIC_kwDOJgiWSs4CtrHs data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2025 <a href=https://gavinsun0921.github.io/>Gavin Sun · Spatial Intelligence</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>