<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>A Brief Exploration to Diffusion Probabilistic Models with Code Implementation | Gavin Sun · Spatial Intelligence</title><meta name=keywords content="Diffusion,DPM,Computer Vision,Deep Learning"><meta name=description content="Learn diffusion probabilistic models (DPM) by reading and analyzing the papers: &ldquo;Deep Unsupervised Learning using Nonequilibrium Thermodynamics&rdquo; and &ldquo;Denoising Diffusion Probabilistic Models&rdquo;. This post will introduce the basic work of DPM, including the derivation of formulas and simple code verification."><meta name=author content><link rel=canonical href=https://gavinsun0921.github.io/posts/paper-research-01/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://gavinsun0921.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://gavinsun0921.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://gavinsun0921.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://gavinsun0921.github.io/apple-touch-icon.png><link rel=mask-icon href=https://gavinsun0921.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://gavinsun0921.github.io/posts/paper-research-01/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css integrity=sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js integrity=sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js integrity=sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],ignoredTags:["script","noscript","style","textarea","pre"],throwOnError:!1})'></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-18P7N9RZDS"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-18P7N9RZDS")</script><meta property="og:url" content="https://gavinsun0921.github.io/posts/paper-research-01/"><meta property="og:site_name" content="Gavin Sun · Spatial Intelligence"><meta property="og:title" content="A Brief Exploration to Diffusion Probabilistic Models with Code Implementation"><meta property="og:description" content="Learn diffusion probabilistic models (DPM) by reading and analyzing the papers: “Deep Unsupervised Learning using Nonequilibrium Thermodynamics” and “Denoising Diffusion Probabilistic Models”. This post will introduce the basic work of DPM, including the derivation of formulas and simple code verification."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-06-14T00:00:00+00:00"><meta property="article:modified_time" content="2023-06-14T00:00:00+00:00"><meta property="article:tag" content="Diffusion"><meta property="article:tag" content="DPM"><meta property="article:tag" content="Computer Vision"><meta property="article:tag" content="Deep Learning"><meta name=twitter:card content="summary"><meta name=twitter:title content="A Brief Exploration to Diffusion Probabilistic Models with Code Implementation"><meta name=twitter:description content="Learn diffusion probabilistic models (DPM) by reading and analyzing the papers: &ldquo;Deep Unsupervised Learning using Nonequilibrium Thermodynamics&rdquo; and &ldquo;Denoising Diffusion Probabilistic Models&rdquo;. This post will introduce the basic work of DPM, including the derivation of formulas and simple code verification."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://gavinsun0921.github.io/posts/"},{"@type":"ListItem","position":2,"name":"A Brief Exploration to Diffusion Probabilistic Models with Code Implementation","item":"https://gavinsun0921.github.io/posts/paper-research-01/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"A Brief Exploration to Diffusion Probabilistic Models with Code Implementation","name":"A Brief Exploration to Diffusion Probabilistic Models with Code Implementation","description":"Learn diffusion probabilistic models (DPM) by reading and analyzing the papers: \u0026ldquo;Deep Unsupervised Learning using Nonequilibrium Thermodynamics\u0026rdquo; and \u0026ldquo;Denoising Diffusion Probabilistic Models\u0026rdquo;. This post will introduce the basic work of DPM, including the derivation of formulas and simple code verification.","keywords":["Diffusion","DPM","Computer Vision","Deep Learning"],"articleBody":"This is the first post in the Paper Research series. In this series I will continue to update some personal study notes on reading papers. This post will introduce the basic work of diffusion probabilistic models (DPM), including the derivation of formulas and simple code verification. The content is mainly from Sohl-Dickstein et al. (2015) and Ho et al. (2020). If you have any suggestions on this post or would like to communicate with me, please leave comments below.\nDiffusion Models What are Diffusion Models? Refer to Weng, (2021):\nDiffusion models are inspired by non-equilibrium thermodynamics. They define a Markov chain of diffusion steps to slowly add random noise to data and then learn to reverse the diffusion process to construct desired data samples from the noise.\nFig. 1. Framework Diagram of Diffusion Models.\nMy personal understanding of Diffusion Models is a framework (Fig. 1) where there are no trainable parameters in the forward process and there are training parameters in the reverse process. And there is no restriction on what type of neural network to use in terms of the distribution that needs to be expressed implicitly in the reverse process.\nFig. 2. Flowchart of Diffusion Models. (Image source: Das, 2021)\nForward Process The forward process is a Markov process. According to Wikipedia, a Markov chain or Markov process is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. Informally, this may be thought of as, “What happens next depends only on the state of affairs now.”\nThe main goal of the forward process is to gradually convert the data distribution $q(\\mathbf{x}_0)$ into an analytically tractable distribution $\\pi(\\mathbf{y})$ by repeated application of a Markov diffusion kernel $T_\\pi(\\mathbf{y}|\\mathbf{y}'; \\beta)$ for $\\pi(\\mathbf{y})$, where $\\beta$ is the diffusion rate,\n$$\\pi(\\mathbf{y}) = \\int T_\\pi(\\mathbf{y}|\\mathbf{y}'; \\beta) \\mathrm{d}\\mathbf{y}' \\tag{1}$$ $$q(\\mathbf{x}_t|\\mathbf{x}_{t-1}) = T_\\pi(\\mathbf{x}_t|\\mathbf{x}_{t-1}; \\beta_t) \\tag{2}$$ The forward trajectory (joint distribution), corresponding to starting at the data distribution and performing T steps of diffusion, is thus\n$$q(\\mathbf{x}_0, \\mathbf{x}_1, \\cdots, \\mathbf{x}_T) = q(\\mathbf{x}_{(0\\cdots T)}) = q(\\mathbf{x}_0)\\prod_{t=1}^T q(\\mathbf{x}_t | \\mathbf{x}_{t-1}) \\tag{3}$$ Fig. 3. Illustration of forward (diffusion) trajectory.\nReverse Process The reverse process also is a Markov process. If we can reverse the above process and sample from $q(\\mathbf{x}_{t-1} | \\mathbf{x}_t)$, we will be able to recreate the true sample from a Gaussian noise input, $\\mathbf{x}_T \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$. Unfortunately, we cannot easily estimate $q(\\mathbf{x}_{t-1} | \\mathbf{x}_t)$ and there fore we need to learn a model $p_\\theta$ to approximate these conditional probabilities in order to run the reverse process. We want $p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t)$ to approximate $q(\\mathbf{x}_{t-1} | \\mathbf{x}_t)$ as closely as possible for all $t$.\nThe generative distribution $p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}\\_t)$ will be trained to describe the same trajectory (also a joint distribution), but in reverse,\n$$p_\\theta (\\mathbf{x}_T) = \\pi(\\mathbf{x}_T) \\tag{4}$$ $$ p_\\theta(\\mathbf{x}_0, \\mathbf{x}_1, \\cdots, \\mathbf{x}_T) = p_\\theta(\\mathbf{x}_{(0\\cdots T)}) = p_\\theta(\\mathbf{x}_T)\\prod_{t=1}^T p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}) \\tag{5}$$ Generative Model The forward trajectory (joint distribution): image to noise. The reverse trajectory (joint distribution): noise to image. The Model Probability (marginal distribution): the probability the generative model assigns to the data. The probability the generative model assigns to the data is $$p_\\theta(\\mathbf{x}_0) = \\int \\int \\cdots \\int p_\\theta(\\mathbf{x}_0, \\mathbf{x}_1, \\cdots, \\mathbf{x}_T) \\mathrm{d}\\mathbf{x}_1 \\mathrm{d}\\mathbf{x}_2 \\cdots \\mathrm{d}\\mathbf{x}_T \\tag{6}$$ For convenience, we simply denote it as: $$p_\\theta(\\mathbf{x}_0) = \\int \\mathrm{d}\\mathbf{x}_{(1\\cdots T)} \\ p_\\theta(\\mathbf{x}_{(0\\cdots T)}) \\tag{7}$$\nBut this integral (7) is intractable! We can handle this integral similarly to some of the ways in VAE. Taking a cue from annealed importance sampling and the Jarzynski equality, we instead evaluate the relative probability of the forward and reverse trajectories, averaged over forward trajectories,\n$$ \\begin{equation*} \\begin{split} a=b \\end{split} \\end{equation*} $$ $$ \\begin{equation*} \\begin{split} p_\\theta(\\mathbf{x}_0) \u0026= \\int \\mathrm{d}\\mathbf{x}_{(1\\cdots T)} \\ p_\\theta(\\mathbf{x}_{(0\\cdots T)}) \\frac{q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0)}{q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0)} \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(1\\cdots T)} \\ q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0) \\frac{\\color{red} p_\\theta(\\mathbf{x}_{(0\\cdots T)})}{\\color{blue} q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0)} \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(1\\cdots T)} \\ q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0) \\frac{\\color{red} p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{\\color{blue} \\frac{q(\\mathbf{x}_0, \\mathbf{x}_{(1\\cdots T)})}{q(\\mathbf{x}_0)}} \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(1\\cdots T)} \\ q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0) \\frac{p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{\\color{blue} \\frac{q(\\mathbf{x}_0) \\prod_{t=1}^T q(\\mathbf{x}_t | \\mathbf{x}_{t-1})}{q(\\mathbf{x}_0)}} \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(1\\cdots T)} \\ q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0) \\frac{p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{\\prod_{t=1}^T q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(1\\cdots T)} \\ q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0) p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\end{split} \\end{equation*} \\tag{8} $$ Model Log Likelihood We want the estimated data distribution ($p_\\theta(\\mathbf{x}\\_0)$) to be as close as possible to the actual data distribution ($q(\\mathbf{x}\\_0)$). So training amounts to maximizing the model log likelihood, $$ \\begin{equation*} \\begin{split} \\mathcal{L} \u0026= \\int \\mathrm{d}\\mathbf{x}_0 \\ q(\\mathbf{x}_0) \\log p_\\theta (\\mathbf{x}_0) \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_0 \\ q(\\mathbf{x}_0) { \\log \\left [ \\int \\mathrm{d}\\mathbf{x}_{(1\\cdots T)} q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0) p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ]} \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_0 \\ q(\\mathbf{x}_0) {\\color{blue} \\log \\left \\{\\mathbb{E}_{\\mathbf{x}_{(1\\cdots T)} \\sim q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0)} \\left [ p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] \\right \\}} \\\\ \u0026\\geq \\int \\mathrm{d}\\mathbf{x}_0 \\ q(\\mathbf{x}_0) {\\color{blue} \\mathbb{E}_{\\mathbf{x}_{(1\\cdots T)} \\sim q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0)} \\left \\{ \\log \\left [ p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] \\right \\}} \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_0 \\ q(\\mathbf{x}_0) \\int \\mathbb{d}\\mathbf{x}_{(1\\cdots T)} \\ q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0) \\log \\left [ p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] \\\\ \u0026= \\int \\mathbb{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_0) q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0) \\log \\left [ p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] \\\\ \u0026= \\int \\mathbb{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\log \\left [ p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] \\\\ \\end{split} \\end{equation*} \\tag{9} $$\nThe blue part in Eq. (9) provided by Jensen’s inequality as Fig. 5.\nFig. 4. Visualization of Jensen's inequality in logarithmic function. So we have the lower bound of $\\mathcal{L}$, let’s write it down as $$\\mathcal{K} = \\int \\mathbb{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\log \\left [ p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] \\tag{10}$$\n1) Peel off $p_\\theta(\\mathbf{x}_T)$ in $\\mathcal{K}$ as an entropy\nWe can peel off the contribution from $p_\\theta(\\mathbf{x}_T)$, and rewrite it as an entropy, $$ \\begin{equation*} \\begin{split} \\mathcal{K} \u0026= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) {\\color{blue} \\log \\left [ p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ]} \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) {\\color{blue} \\left \\{ \\log p_\\theta(\\mathbf{x}_T) + \\sum_{t=1}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] \\right \\} } \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) {\\color{blue} \\sum_{t=1}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ]} + \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) {\\color{blue} \\log p_\\theta(\\mathbf{x}_T)} \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) { \\sum_{t=1}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ]} + {\\color{red} \\int \\mathrm{d}\\mathbf{x}_T \\ q(\\mathbf{x}_T) \\log \\underbrace{p_\\theta(\\mathbf{x}_T)}_{{\\normalsize \\pi}(\\mathbf{x}_T)}} \\\\ \\end{split} \\end{equation*} \\tag{11} $$\nBy design, the cross entropy to $\\pi(\\mathbf{x}_T)$ is constant under our diffusion kernels, and equal to the entropy of $p_\\theta(\\mathbf{x}_T)$. Therefore, $$ \\mathcal{K} = \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=1}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] {\\color{red} - \\ \\mathcal{H}_p(\\mathbf{x}_T)} \\tag{12} $$\n2) Remove the edge effect at $t=0$\nIn order to avoid edge effects, we set the final step of the reverse trajectory to be identical to the corresponding forward diffusion step, $$p_\\theta(\\mathbf{x}_0 | \\mathbf{x}_1) = q(\\mathbf{x}_1 | \\mathbf{x}_0) \\frac{\\pi(\\mathbf{x}_{0})}{\\pi(\\mathbf{x}_{1})} = T_\\pi(\\mathbf{x}_0 | \\mathbf{x}_1 ; \\beta) \\tag{13}$$\nWe then use this equivalence to remove the contribution of the first time-step in the sum, $$ \\begin{equation*} \\begin{split} \\mathcal{K} \u0026= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) {\\color{blue} \\sum_{t=1}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ]} - \\mathcal{H}_p(\\mathbf{x}_T) \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) {\\color{blue} \\sum_{t=2}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ]} + \\underbrace{\\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) {\\color{blue} \\log \\frac{p_\\theta(\\mathbf{x}_0 | \\mathbf{x}_1)}{q(\\mathbf{x}_1 | \\mathbf{x}_0)}}}_{ {\\large \\mathbb{E}}_{\\mathbf{x}_{(0\\cdots T)} \\sim q(\\mathbf{x}_{(0\\cdots T)})} {\\normalsize \\log \\frac{p_\\theta(\\mathbf{x}_0 | \\mathbf{x}_1)}{q(\\mathbf{x}_1 | \\mathbf{x}_0)}}} - \\mathcal{H}_p(\\mathbf{x}_T) \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] + \\int \\mathrm{d}\\mathbf{x}_{(0, 1)} \\ q(\\mathbf{x}_0, \\mathbf{x}_1) \\log \\frac{\\color{red} p_\\theta(\\mathbf{x}_0 | \\mathbf{x}_1)}{q(\\mathbf{x}_1 | \\mathbf{x}_0)} - \\mathcal{H}_p(\\mathbf{x}_T) \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] + \\int \\mathrm{d}\\mathbf{x}_{(0, 1)} \\ q(\\mathbf{x}_0, \\mathbf{x}_1) \\log \\frac{\\color{red} q(\\mathbf{x}_1 | \\mathbf{x}_0) \\pi(\\mathbf{x}_0)}{q(\\mathbf{x}_1 | \\mathbf{x}_0) {\\color{red} \\pi(\\mathbf{x}_1)}} - \\mathcal{H}_p(\\mathbf{x}_T) \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] + {\\color{green} \\int \\mathrm{d}\\mathbf{x}_{(0, 1)} \\ q(\\mathbf{x}_0, \\mathbf{x}_1) \\log \\frac{\\pi(\\mathbf{x}_0)}{\\pi(\\mathbf{x}_1)}} - \\mathcal{H}_p(\\mathbf{x}_T) \\\\ \\end{split} \\end{equation*} \\tag{14} $$\nFor ease of presentation, the green part of Eq. (14) is derived separately, $$ \\begin{equation*} \\begin{split} {\\color{green} \\int \\mathrm{d}\\mathbf{x}_{(0, 1)} \\ q(\\mathbf{x}_0, \\mathbf{x}_1) \\log \\frac{\\pi(\\mathbf{x}_0)}{\\pi(\\mathbf{x}_1)}} \u0026= \\int \\mathrm{d}\\mathbf{x}_{(0, 1)} \\ q(\\mathbf{x}_0, \\mathbf{x}_1) \\left [ \\log \\pi(\\mathbf{x}_0) - \\log \\pi(\\mathbf{x}_1) \\right ] \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(0, 1)} \\ q(\\mathbf{x}_0, \\mathbf{x}_1) \\log \\pi(\\mathbf{x}_0) - \\int \\mathrm{d}\\mathbf{x}_{(0, 1)} \\ q(\\mathbf{x}_0, \\mathbf{x}_1) \\log \\pi(\\mathbf{x}_1) \\\\ \u0026= {\\color{red} \\int \\mathrm{d}\\mathbf{x}_{0} \\ q(\\mathbf{x}_{0}) \\log \\pi(\\mathbf{x}_0)} - {\\color{red} \\int \\mathrm{d}\\mathbf{x}_{1} \\ q(\\mathbf{x}_{1}) \\log \\pi(\\mathbf{x}_1)} \\\\ \u0026= {\\color{red} \\mathcal{H}_p(\\mathbf{x}_T)} - {\\color{red} \\mathcal{H}_p(\\mathbf{x}_T)} \\\\ \u0026= 0 \\\\ \\end{split} \\end{equation*} \\tag{15} $$\nwhere we again used the fact that by design $\\color{red} -\\int \\mathrm{d}\\mathbf{x}_t \\ q(\\mathbf{x}_t) \\log \\pi(\\mathbf{x}_t) = \\mathcal{H}_p(\\mathbf{x}_T)$ is a constant for all $t$.\nTherefore, the lower bound in Eq. (14) becomes $$\\mathcal{K} = \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] - \\mathcal{H}_p(\\mathbf{x}_T) \\tag{16}$$\n3) Rewrite in terms of $q(\\mathbf{x}_{t-1} | \\mathbf{x}_t)$\nBecause the forward trajectory is a Markov process, $$ \\begin{equation*} q(\\mathbf{x}_t | \\mathbf{x}_{t-1}) = \\left \\{ \\begin{matrix} q(\\mathbf{x}_t | \\mathbf{x}_{t-1}, \\mathbf{x}_0) \u0026 , t \u003e 1 \\\\ q(\\mathbf{x}_1 | \\mathbf{x}_{0}, \\mathbf{x}_0) = q(\\mathbf{x}_1 | \\mathbf{x}_{0}) \u0026 , t = 1 \\end{matrix} \\right . \\end{equation*} \\tag{17} $$\n$$ \\mathcal{K} = \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{\\color{blue} q(\\mathbf{x}_t | \\mathbf{x}_{t-1}, \\mathbf{x}_0)} \\right ] - \\mathcal{H}_p(\\mathbf{x}_T) \\tag{18} $$\nUsing Bayes’ rule we can rewrite this in terms of a posterior and marginals from the forward trajectory, $$ \\mathcal{K} = \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{\\color{blue} q(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}, \\mathbf{x}_0)} \\frac{\\color{blue} q(\\mathbf{x}_{t-1} | \\mathbf{x}_0)}{\\color{blue} q(\\mathbf{x}_{t} | \\mathbf{x}_0)} \\right ] - \\mathcal{H}_p(\\mathbf{x}_T) \\tag{19} $$\n4) Rewrite in terms of KL divergences and entropies\n$$ \\begin{equation*} \\begin{split} \\mathcal{K} \u0026= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}, \\mathbf{x}_0)} \\frac{q(\\mathbf{x}_{t-1} | \\mathbf{x}_0)}{q(\\mathbf{x}_{t} | \\mathbf{x}_0)} \\right ] - \\mathcal{H}_p(\\mathbf{x}_T) \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\left [ \\log \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}, \\mathbf{x}_0)} + \\log \\frac{q(\\mathbf{x}_{t-1} | \\mathbf{x}_0)}{q(\\mathbf{x}_{t} | \\mathbf{x}_0)} \\right ] - \\mathcal{H}_p(\\mathbf{x}_T) \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}, \\mathbf{x}_0)} \\\\ \u0026\\quad + {\\color{green} \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\frac{q(\\mathbf{x}_{t-1} | \\mathbf{x}_0)}{q(\\mathbf{x}_{t} | \\mathbf{x}_0)}} - \\mathcal{H}_p(\\mathbf{x}_T) \\\\ \\end{split} \\end{equation*} \\tag{20} $$\nFor ease of presentation, the green part of Eq. (20) is derived separately, $$ \\begin{equation*} \\begin{split} {\\color{green} \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)}} \u0026\\ {\\color{green} q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\frac{q(\\mathbf{x}_{t-1} | \\mathbf{x}_0)}{q(\\mathbf{x}_{t} | \\mathbf{x}_0)}} \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\log {\\color{blue} \\prod_{t=2}^T \\frac{q(\\mathbf{x}_{t-1} | \\mathbf{x}_0)}{q(\\mathbf{x}_{t} | \\mathbf{x}_0)}} \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\log {\\color{blue} \\frac{q(\\mathbf{x}_{1} | \\mathbf{x}_0)}{q(\\mathbf{x}_{T} | \\mathbf{x}_0)}} \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\left [ \\log q(\\mathbf{x}_{1} | \\mathbf{x}_0) - \\log q(\\mathbf{x}_{T} | \\mathbf{x}_0) \\right ] \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\log q(\\mathbf{x}_{1} | \\mathbf{x}_0) - \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\log q(\\mathbf{x}_{T} | \\mathbf{x}_0) \\\\ \u0026= {\\color{red} \\int \\mathrm{d}\\mathbf{x}_{(0,1)} \\ q(\\mathbf{x}_0, \\mathbf{x}_1) \\log q(\\mathbf{x}_{1} | \\mathbf{x}_0)} - {\\color{red} \\int \\mathrm{d}\\mathbf{x}_{(0,T)} \\ q(\\mathbf{x}_0, \\mathbf{x}_T) \\log q(\\mathbf{x}_{T} | \\mathbf{x}_0)} \\\\ \u0026= {\\color{red} \\mathcal{H}_q(\\mathbf{x}_T | \\mathbf{x}_0)} - {\\color{red} \\mathcal{H}_q(\\mathbf{x}_1 | \\mathbf{x}_0)} \\quad ; \\text{(conditional entropy)} \\end{split} \\end{equation*} \\tag{21} $$\nTherefore, the lower bound in Eq. (20) becomes $$ \\mathcal{K} = {\\color{brown} \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}, \\mathbf{x}_0)}} + \\mathcal{H}_q(\\mathbf{x}_T | \\mathbf{x}_0) - \\mathcal{H}_q(\\mathbf{x}_1 | \\mathbf{x}_0) - \\mathcal{H}_p(\\mathbf{x}_T) \\tag{22} $$\nFor ease of presentation, the brown part of Eq. (22) is derived separately, $$ \\begin{equation*} \\begin{split} {\\color{brown} \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)}} \u0026 \\ {\\color{brown} q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}, \\mathbf{x}_0)}} \\\\ \u0026= \\sum_{t=2}^T \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\log \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}, \\mathbf{x}_0)} \\\\ \u0026= \\sum_{t=2}^T \\int \\mathrm{d}\\mathbf{x}_{0}\\mathrm{d}\\mathbf{x}_{t-1}\\mathrm{d}\\mathbf{x}_{t} \\ {\\color{blue} q(\\mathbf{x}_0, \\mathbf{x}_{t-1}, \\mathbf{x}_t)} \\log \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}, \\mathbf{x}_0)} \\\\ \u0026= \\sum_{t=2}^T \\int \\mathrm{d}\\mathbf{x}_{0}\\mathrm{d}\\mathbf{x}_{t-1}\\mathrm{d}\\mathbf{x}_{t} \\ {\\color{blue} q(\\mathbf{x}_0, \\mathbf{x}_t) q(\\mathbf{x}_{t-1}| \\mathbf{x}_t, \\mathbf{x}_0)} \\log \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}, \\mathbf{x}_0)} \\\\ \u0026= \\sum_{t=2}^T \\int \\mathrm{d}\\mathbf{x}_{0}\\mathrm{d}\\mathbf{x}_{t} \\ q(\\mathbf{x}_0, \\mathbf{x}_t) \\underbrace{\\color{red} \\left \\{ \\int \\mathrm{d}\\mathbf{x}_{t-1} \\ q(\\mathbf{x}_{t-1}| \\mathbf{x}_t, \\mathbf{x}_0) \\log \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}, \\mathbf{x}_0)} \\right \\} }_{ \\begin{array}{c} \\small \\text{KL Divergence (also called relative entropy)} \\\\ {\\color{violet} \\mathcal{D}_{KL}(P \\| Q) = \\int_{-\\infty}^{+\\infty} p(x) \\log \\frac{p(x)}{q(x)} \\mathrm{d}x} \\end{array} } \\\\ \u0026= {\\color{red} -} \\sum_{t=2}^T \\int \\mathrm{d}\\mathbf{x}_{0}\\mathrm{d}\\mathbf{x}_{t} \\ q(\\mathbf{x}_0, \\mathbf{x}_t) {\\color{red} \\mathcal{D}_{KL}(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) \\| p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t))} \\end{split} \\end{equation*} \\tag{23} $$\nTherefore, the lower bound in Eq. (22) becomes $$ \\begin{equation*} \\begin{split} \\mathcal{K} = \u0026- \\sum_{t=2}^T \\int \\mathrm{d}\\mathbf{x}_{0}\\mathrm{d}\\mathbf{x}_{t} \\ q(\\mathbf{x}_0, \\mathbf{x}_t) \\mathcal{D}_{KL}(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) \\| p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t)) \\\\ \u0026+ \\mathcal{H}_q(\\mathbf{x}_T | \\mathbf{x}_0) - \\mathcal{H}_q(\\mathbf{x}_1 | \\mathbf{x}_0) - \\mathcal{H}_p(\\mathbf{x}_T) \\end{split} \\end{equation*} \\tag{24} $$\nNote that the entropies can be analytically computed, and the KL divergence can be analytically computed given $\\mathbf{x}_0$ and $\\mathbf{x}_t$.\nTraining consists of finding the reverse Markov transitions which maximize this lower bound on the log likelihood, $$ p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t) = \\argmax_{\\theta} \\mathcal{K} \\tag{25} $$\nSpecific Diffusion Kernel Forward Process Specify that the Markov diffusion kernel in Eq. (2) is subject to a Gaussian distribution, $$ q(\\mathbf{x}_t | \\mathbf{x}_{t-1}) = T_\\pi(\\mathbf{x}_t | \\mathbf{x}_{t-1}; \\beta_t) = \\mathcal{N}(\\mathbf{x}_t; \\sqrt{1 - \\beta_t} \\mathbf{x}_{t-1}, \\beta_t \\mathbf{I}) \\tag{26} $$\nA nice property of the above process is that we can sample $\\mathbf{x}_t$ at any arbitrary time step $t$ in a closed form using reparameterization trick. Let $\\alpha_t = 1 - \\beta_t$ and $\\bar{\\alpha}_t = \\prod_{i=1}^t \\alpha_i$ : $$ \\begin{equation*} \\begin{split} \\mathbf{x}_t \u0026= \\sqrt{\\alpha_t} {\\color{blue} \\mathbf{x}_{t-1}} + \\sqrt{1 - \\alpha_t} \\bm{\\epsilon}_{t-1} \\\\ \u0026= \\sqrt{\\alpha_t} {\\color{blue} (\\sqrt{\\alpha_{t-1}} \\mathbf{x}_{t-2} + \\sqrt{1 - \\alpha_{t-1}} \\bm{\\epsilon}_{t-2})} + \\sqrt{1 - \\alpha_t} \\bm{\\epsilon}_{t-1} \\\\ \u0026= \\sqrt{\\alpha_t \\alpha_{t-1}} \\mathbf{x}_{t-2} + {\\color{red} \\sqrt{\\alpha_t - \\alpha_t \\alpha_{t-1}} \\bm{\\epsilon}_{t-2} + \\sqrt{1 - \\alpha_t} \\bm{\\epsilon}_{t-1}} \\\\ \u0026= \\sqrt{\\alpha_t \\alpha_{t-1}} \\mathbf{x}_{t-2} + {\\color{red} \\sqrt{\\sqrt{\\alpha_t - \\alpha_t \\alpha_{t-1}}^2 + \\sqrt{1 - \\alpha_t}^2} \\bar{\\bm{\\epsilon}}_{t-2}} \\\\ \u0026= \\sqrt{\\alpha_t \\alpha_{t-1}} \\mathbf{x}_{t-2} + \\sqrt{1 - \\alpha_t \\alpha_{t-1}} \\bar{\\bm{\\epsilon}}_{t-2} \\\\ \u0026= \\cdots \\\\ \u0026= \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_{0} + \\sqrt{1 - \\bar{\\alpha}_t} \\bar{\\bm{\\epsilon}}_0 \\\\ \u0026= \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_{0} + \\sqrt{1 - \\bar{\\alpha}_t} {\\color{green} \\bm{\\epsilon}_{t}} \\quad \\text{; to correspond to the subscript of } \\mathbf{x}_t \\\\ \\end{split} \\end{equation*} \\tag{27} $$ where ${\\color{green} \\bm{\\epsilon}_{t}}, \\bm{\\epsilon}_{t-1}, \\bm{\\epsilon}_{t-2}, \\cdots \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$.\nRecall the red part of Eq. (27) when we merge two Gaussians with different variance, $\\mathcal{N}(\\mathbf{0}, \\sigma_1^2\\mathbf{I})$ and $\\mathcal{N}(\\mathbf{0}, \\sigma_2^2\\mathbf{I})$, the new distribution is $\\mathcal{N}(\\mathbf{0}, (\\sigma_1^2 + \\sigma_2^2)\\mathbf{I})$.\nThus, we have $$ q(\\mathbf{x}_t | \\mathbf{x}_0) = \\mathcal{N}(\\mathbf{x}_t; \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0, (1 - \\bar{\\alpha}_t) \\mathbf{I}) \\tag{28} $$\nUsually, we can afford a larger update step when the sample gets noisier, so $\\beta_1 \u003c \\beta_2 \u003c \\cdots \u003c \\beta_T$ and therefore $\\bar{\\alpha}_1 \u003e \\bar{\\alpha}_2 \u003e \\cdots \u003e \\bar{\\alpha}_T$.\nReverse Process According to Eq. (26), $$ p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t) = \\mathcal{N}(\\mathbf{x}_{t-1}; \\bm{\\mu}_\\theta(\\mathbf{x}_t, t), \\bm{\\sigma}_\\theta(\\mathbf{x}_t, t)) \\tag{29} $$\nIt is noteworthy that the reverse conditional probability is tractable when conditioned on $\\mathbf{x}_0$: $$ q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) = \\mathcal{N}(\\mathbf{x}_{t-1}; { \\bm{\\tilde{\\mu}}_t(\\mathbf{x}_t, \\mathbf{x}_0)}, { \\tilde{\\beta}_t \\mathbf{I}}) \\tag{30} $$\nUsing Bayes’ rule, we have: $$ \\begin{equation*} \\begin{split} q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) \u0026= q(\\mathbf{x}_{t} | \\mathbf{x}_{t-1}, \\mathbf{x}_0) \\frac{q(\\mathbf{x}_{t-1} | \\mathbf{x}_0)}{q(\\mathbf{x}_{t} | \\mathbf{x}_0)} \\quad ; \\text{bringing in Eq. (26) and Eq. (28)} \\\\ \u0026\\propto \\exp \\left ( -\\frac{1}{2}(\\frac{(\\mathbf{x}_t - \\sqrt{\\alpha_t} \\mathbf{x}_{t-1})^2}{\\beta_t}) \\right ) \\frac{\\displaystyle \\exp \\left ( -\\frac{1}{2}( \\frac{(\\mathbf{x}_{t-1} - \\sqrt{\\bar{\\alpha}_{t-1}} \\mathbf{x}_0)^2}{1 - \\bar{\\alpha}_{t-1}} ) \\right ) }{\\displaystyle \\exp \\left ( -\\frac{1}{2}( \\frac{(\\mathbf{x}_{t} - \\sqrt{\\bar{\\alpha}_{t}} \\mathbf{x}_0)^2}{1 - \\bar{\\alpha}_{t}} ) \\right ) } \\\\ \u0026= \\exp \\left ( -\\frac{1}{2} ( \\frac{(\\mathbf{x}_t - \\sqrt{\\alpha_t} \\mathbf{x}_{t-1})^2}{\\beta_t} + \\frac{(\\mathbf{x}_{t-1} - \\sqrt{\\bar{\\alpha}_{t-1}} \\mathbf{x}_0)^2}{1 - \\bar{\\alpha}_{t-1}} - \\frac{(\\mathbf{x}_{t} - \\sqrt{\\bar{\\alpha}_{t}} \\mathbf{x}_0)^2}{1 - \\bar{\\alpha}_{t}} ) \\right ) \\\\ \u0026= \\exp \\left ( -\\frac{1}{2}( \\frac{ \\mathbf{x}_t^2 - 2\\sqrt{\\alpha_t} \\mathbf{x}_t {\\color{blue} \\mathbf{x}_{t-1}} + \\alpha_t {\\color{red} \\mathbf{x}_{t-1}^2} }{\\beta_t} + \\frac{ {\\color{red} \\mathbf{x}_{t-1}^2} -2\\sqrt{\\bar{\\alpha}_{t-1}}\\mathbf{x}_0 {\\color{blue} \\mathbf{x}_{t-1}} + \\bar{\\alpha}_{t-1} \\mathbf{x}_0^2 }{1 - \\bar{\\alpha}_{t-1}} \\right. \\\\ \u0026\\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\left. - \\ \\frac{(\\mathbf{x}_{t} - \\sqrt{\\bar{\\alpha}_{t}} \\mathbf{x}_0)^2}{1 - \\bar{\\alpha}_{t}} ) \\right ) \\\\ \u0026= \\exp \\left ( -\\frac{1}{2} {\\Large (} (\\frac{\\alpha_t}{\\beta_t} + \\frac{1}{1 - \\bar{\\alpha}_{t-1}}) {\\color{red} \\mathbf{x}_{t-1}^2} - (\\frac{2\\sqrt{\\alpha_t}}{\\beta_t} \\mathbf{x}_t + \\frac{2\\sqrt{\\bar{\\alpha}_{t-1}}}{1 - \\bar{\\alpha}_{t-1}} \\mathbf{x}_t) {\\color{blue} \\mathbf{x}_{t-1}} + C(\\mathbf{x}_t, \\mathbf{x}_0) {\\Large )} \\right ) \\end{split} \\end{equation*} \\tag{31} $$ where $C(\\mathbf{x}_t, \\mathbf{x}_0)$ is some function not involving $\\mathbf{x}_{t-1}$ and details are omitted.\nFollowing the general form of $\\mathcal{N}(\\mu, \\sigma^2)$ probability density function $f(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\left ( -\\frac{1}{2} (\\frac{x - \\mu}{\\sigma})^2 \\right )$, $$ (\\frac{\\alpha_t}{\\beta_t} + \\frac{1}{1 - \\bar{\\alpha}_{t-1}}) {\\color{red} \\mathbf{x}_{t-1}^2} - (\\frac{2\\sqrt{\\alpha_t}}{\\beta_t} \\mathbf{x}_t + \\frac{2\\sqrt{\\bar{\\alpha}_{t-1}}}{1 - \\bar{\\alpha}_{t-1}} \\mathbf{x}_t) {\\color{blue} \\mathbf{x}_{t-1}} + C(\\mathbf{x}_t, \\mathbf{x}_0) = (\\frac{x-\\mu}{\\sigma})^2 = \\frac{{\\color{red} x^2} - 2\\mu {\\color{blue} x} + \\mu^2}{\\sigma^2} \\tag{32} $$\nThe variance $(\\tilde{\\beta}_t \\mathbf{I})$ and mean $(\\bm{\\tilde{\\mu}}_t(\\mathbf{x}_t, \\mathbf{x}_0))$ in Eq. (30) can be parameterized as follows: $$ \\begin{equation*} \\begin{split} \\tilde{\\beta}_t = 1 / (\\frac{\\alpha_t}{\\beta_t} + \\frac{1}{1 - \\bar{\\alpha}_{t-1}}) = \\frac{1 - \\bar{\\alpha}_{t-1}}{1 - \\bar{\\alpha}_{t}} \\beta_t \\end{split} \\end{equation*} \\tag{33} $$\n$$ \\begin{equation*} \\begin{split} \\bm{\\tilde{\\mu}}_t(\\mathbf{x}_t, \\mathbf{x}_0) \u0026= \\frac{(\\frac{2\\sqrt{\\alpha_t}}{\\beta_t} \\mathbf{x}_t + \\frac{2\\sqrt{\\bar{\\alpha}_{t-1}}}{1 - \\bar{\\alpha}_{t-1}} \\mathbf{x}_t) \\tilde{\\beta}_t }{-2} = \\frac{\\sqrt{\\alpha}_t (1 - \\bar{\\alpha}_{t-1})}{1 - \\bar{\\alpha}_t} \\mathbf{x}_t + \\frac{\\sqrt{\\bar{\\alpha}_{t-1}} \\beta_t}{1 - \\bar{\\alpha}_t} \\mathbf{x}_0 \\end{split} \\end{equation*} \\tag{34} $$\nThanks to the nice property, we can represent Eq. (27) to $\\mathbf{x}_0 = (\\mathbf{x}_t - \\sqrt{1 - \\bar{\\alpha}_t} \\bm{\\epsilon}_t) / \\sqrt{\\bar{\\alpha}_t}$ and bring it into Eq. (34), $$ \\begin{equation*} \\begin{split} \\bm{\\mu}_t(\\mathbf{x}_t) \u0026= \\bm{\\tilde{\\mu}}_t\\left (\\mathbf{x}_t, (\\mathbf{x}_t - \\sqrt{1 - \\bar{\\alpha}_t} \\bm{\\epsilon}_t) / \\sqrt{\\bar{\\alpha}_t} \\right ) \\\\ \u0026= \\frac{\\sqrt{\\alpha}_t (1 - \\bar{\\alpha}_{t-1})}{1 - \\bar{\\alpha}_t} \\mathbf{x}_t + \\frac{\\sqrt{\\bar{\\alpha}_{t-1}} \\beta_t}{1 - \\bar{\\alpha}_t} (\\frac{(\\mathbf{x}_t - \\sqrt{1 - \\bar{\\alpha}_t} \\bm{\\epsilon}_t)}{\\sqrt{\\bar{\\alpha}_t}}) \\\\ \u0026= {\\color{red} \\frac{1}{\\sqrt{\\alpha_t}} \\left ( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\bm{\\epsilon}_t \\right ) } \\end{split} \\end{equation*} \\tag{35} $$\nLoss Function We define the lower bound of the negative log likelihood as the variational lower bound loss function, $$ \\begin{equation*} \\begin{split} \\mathcal{L}_{VLB} \u0026= - \\mathcal{K} \\\\ \u0026= \\sum_{t=2}^T \\int \\mathrm{d}\\mathbf{x}_{0}\\mathrm{d}\\mathbf{x}_{t} \\ q(\\mathbf{x}_0, \\mathbf{x}_t) {\\color{blue} \\mathcal{D}_{KL}(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) \\| p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t))} \\\\ \u0026\\quad - \\mathcal{H}_q(\\mathbf{x}_T | \\mathbf{x}_0) + \\mathcal{H}_q(\\mathbf{x}_1 | \\mathbf{x}_0) + \\mathcal{H}_p(\\mathbf{x}_T) \\\\ \u0026= \\sum_{t=2}^T {\\Large \\mathbb{E}}_{\\mathbf{x}_0, \\mathbf{x}_t \\sim q(\\mathbf{x}_0, \\mathbf{x}_t)} {\\Large [} \\underbrace{\\color{blue} \\mathcal{D}_{KL}(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) \\| p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t))}_{\\color{blue} \\mathcal{L}_{t-1}} {\\Large ]} - \\mathcal{H}_q(\\mathbf{x}_T | \\mathbf{x}_0) + \\mathcal{H}_q(\\mathbf{x}_1 | \\mathbf{x}_0) + \\mathcal{H}_p(\\mathbf{x}_T) \\end{split} \\end{equation*} \\tag{36} $$\nRecall that we need to learn a model to approximate the conditioned probability distributions in the reverse diffusion process, $p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t) = \\mathcal{N}(\\mathbf{x}_{t-1}; \\bm{\\mu}_\\theta(\\mathbf{x}_t, t), \\bm{\\sigma}_\\theta(\\mathbf{x}_t, t))$. We would like to train $\\bm{\\mu}_\\theta(\\mathbf{x}_t, t)$ to predict $\\bm{\\mu}_t(\\mathbf{x}_t)$ in Eq. (35), and set $\\bm{\\sigma}_\\theta(\\mathbf{x}_t, t)$ is equal to $\\sigma_t^2\\mathbf{I}$, where $\\sigma_t^2$ is equal to $\\tilde{\\beta}_t$ in Eq. (33) or $\\beta_t$ for simplify. The loss term $\\mathcal{L}_{t-1}$ in Eq. (36) is parameterized to minimize the difference from $\\bm{\\mu}_t(\\mathbf{x}_t)$: $$ \\begin{equation*} \\begin{split} \\mathcal{L}_{t-1} \u0026= \\mathcal{D}_{KL}(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) \\| p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t)) \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{t-1} \\ q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) \\log \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_(t))}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_(t), \\mathbf{x}_0)} \\\\ \u0026= {\\Large \\mathbb{E}}_{\\small \\mathbf{x}_{t-1} \\sim q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0)} \\left [ \\log \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_(t))}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_(t), \\mathbf{x}_0)} \\right ] \\\\ \u0026\\propto {\\Large \\mathbb{E}}_{\\small \\mathbf{x}_0 \\sim q(\\mathbf{x}_0), \\bm{\\epsilon}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})} \\left [ \\frac{1}{2\\sigma_t^2} \\left \\| {\\color{blue} \\bm{\\mu}_t(\\mathbf{x}_t)} - {\\color{red} \\bm{\\mu}_\\theta(\\mathbf{x}_t, t)} \\right \\| ^2 \\right ] \\\\ \u0026= {\\Large \\mathbb{E}}_{\\small \\mathbf{x}_0 \\sim q(\\mathbf{x}_0), \\bm{\\epsilon}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})} \\left [ \\frac{1}{2\\sigma_t^2} \\left \\| {\\color{blue} \\frac{1}{\\sqrt{\\alpha_t}} \\left ( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\bm{\\epsilon}_t \\right )} - {\\color{red} \\bm{\\mu}_\\theta(\\mathbf{x}_t, t)} \\right \\| ^2 \\right ] \\end{split} \\end{equation*} \\tag{37} $$\nBecause $\\mathbf{x}_t$ is available as input at training time, we can reparameterize the Gaussian noise term instead to make it predict $\\bm{\\epsilon}$ from the input $\\mathbf{x}_t$ at time step $t$: $$ \\bm{\\mu}_\\theta(\\mathbf{x}_t, t) = \\frac{1}{\\sqrt{\\alpha_t}} \\left ( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}}_t} \\bm{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\right ) \\tag{38} $$ where $\\bm{\\epsilon}_\\theta$ is a function approximator (the model) intended to predict $\\bm{\\epsilon}$ from $\\mathbf{x}_t$.\nThus, Eq. (29) can be written as $$ p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}) = \\mathcal{N} \\left ( \\mathbf{x}_{t-1} ; \\frac{1}{\\sqrt{\\alpha_t}} \\left ( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}}_t} \\bm{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\right ) , \\tilde{\\beta}_t \\mathbf{I} \\right ) \\tag{39} $$\nAccording to Eq. (39), sampling $\\mathbf{x}_{t-1} \\sim p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})$ is: $$ \\mathbf{x}_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left ( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}}_t} \\bm{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\right ) + \\sqrt{\\tilde{\\beta}_t} \\bm{\\epsilon}^* \\tag{40} $$ where $\\bm{\\epsilon}^* \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$.\nFurthermore, with the parameterization Eq. (38), the $\\mathcal{L}_{t-1}$ in Eq. (37) simplifies to: $$ \\begin{equation*} \\begin{split} \\mathcal{L}_{t-1} \u0026= {\\Large \\mathbb{E}}_{\\small \\mathbf{x}_0 \\sim q(\\mathbf{x}_0), \\bm{\\epsilon}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})} \\left [ \\frac{1}{2\\sigma_t^2} \\left \\| {\\color{blue} \\frac{1}{\\sqrt{\\alpha_t}} \\left ( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\bm{\\epsilon}_t \\right )} - {\\color{red} \\bm{\\mu}_\\theta(\\mathbf{x}_t, t)} \\right \\| ^2 \\right ] \\\\ \u0026= {\\Large \\mathbb{E}}_{\\small \\mathbf{x}_0 \\sim q(\\mathbf{x}_0), \\bm{\\epsilon}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})} \\left [ \\frac{1}{2\\sigma_t^2} \\left \\| {\\color{blue} \\frac{1}{\\sqrt{\\alpha_t}} \\left ( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\bm{\\epsilon}_t \\right )} - {\\color{red} \\frac{1}{\\sqrt{\\alpha_t}} \\left ( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}}_t} \\bm{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\right )} \\right \\| ^2 \\right ] \\\\ \u0026= {\\Large \\mathbb{E}}_{\\small \\mathbf{x}_0 \\sim q(\\mathbf{x}_0), \\bm{\\epsilon}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})} \\left [ \\frac{1}{2\\sigma_t^2} \\left \\| \\frac{1}{\\sqrt{\\alpha_t}} \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\left (\\bm{\\epsilon}_t - \\bm{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\right ) \\right \\| ^2 \\right ] \\\\ \u0026= {\\Large \\mathbb{E}}_{\\small \\mathbf{x}_0 \\sim q(\\mathbf{x}_0), \\bm{\\epsilon}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})} \\left [ \\frac{\\beta_t^2}{2 \\alpha_t (1 - \\alpha_t) \\sigma_t^2} \\left \\| \\bm{\\epsilon}_t - \\bm{\\epsilon}_\\theta({\\color{orange} \\mathbf{x}_t}, t) \\right \\| ^2 \\right ] \\quad ; \\text{bringing in Eq. (27)} \\\\ \u0026= {\\Large \\mathbb{E}}_{\\small \\mathbf{x}_0 \\sim q(\\mathbf{x}_0), \\bm{\\epsilon}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})} \\left [ {\\color{green} \\frac{\\beta_t^2}{2 \\alpha_t (1 - \\alpha_t) \\sigma_t^2}} \\left \\| \\bm{\\epsilon}_t - \\bm{\\epsilon}_\\theta({\\color{orange} \\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\bm{\\epsilon}_t}, t) \\right \\| ^2 \\right ] \\\\ \\end{split} \\end{equation*} \\tag{41} $$\nSimplification Empirically, Ho et al. (2020) found that training the diffusion model works better with a simplified objective that ignores the weighting term (the green part in Eq. (41)): $$ \\mathcal{L}_t^{\\text{simple}} = {\\Large \\mathbb{E}}_{\\small \\mathbf{x}_0 \\sim q(\\mathbf{x}_0), \\bm{\\epsilon}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})} \\left [ \\left \\| \\bm{\\epsilon}_t - \\bm{\\epsilon}_\\theta(\\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\bm{\\epsilon}_t, t) \\right \\| ^2 \\right ] \\tag{42} $$\nSimple Code Implementation The jupyter notebook is available at GitHub Gist.\nYou can click the button at the top of the notebook to open it in Colab and run the code for free.\nCitation Cited as:\nGavin, Sun. (May 2023). A Brief Exploration to Diffusion Probabilistic Models [Blog post]. Retrieved from https://gavinsun0921.github.io/posts/paper-reading-01/. Or\n@online{gavin2023diffusion, title = {A Brief Exploration to Diffusion Probabilistic Models}, author = {Gavin, Sun}, year = {2023}, month = {May}, url = {\\url{https://gavinsun0921.github.io/posts/paper-reading-01/}} } References [1] Jascha Sohl-Dickstein et al. “Deep Unsupervised Learning using Nonequilibrium Thermodynamics.” ICML 2015.\n[2] Jonathan Ho et al. “Denoising Diffusion Probabilistic Models.” NeurIPS 2020.\n[3] Jiaming Song et al. “Denoising Diffusion Implicit Models.” ICLR 2021.\n[4] Alex Nichol \u0026 Prafulla Dhariwal. “Improved Denoising Diffusion Probabilistic Models.” ICML 2021.\n[5] Lilian Weng. “What are Diffusion Models? Lil’Log.” [Blog post] Lil’Log 2021.\n[6] Ayan Das. “An Introduction to Diffusion Probabilistic Models.” [Blog post] Ayan’s Blog 2021.\n","wordCount":"3839","inLanguage":"en","datePublished":"2023-06-14T00:00:00Z","dateModified":"2023-06-14T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://gavinsun0921.github.io/posts/paper-research-01/"},"publisher":{"@type":"Organization","name":"Gavin Sun · Spatial Intelligence","logo":{"@type":"ImageObject","url":"https://gavinsun0921.github.io/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://gavinsun0921.github.io/ accesskey=h title="Spatial Intelligence (Alt + H)">Spatial Intelligence</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://gavinsun0921.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://gavinsun0921.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://gavinsun0921.github.io/archive/ title=Archive><span>Archive</span></a></li><li><a href=https://gavinsun0921.github.io/about/ title=AboutMe><span>AboutMe</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">A Brief Exploration to Diffusion Probabilistic Models with Code Implementation</h1><div class=post-meta><span title='2023-06-14 00:00:00 +0000 UTC'>June 14, 2023</span>&nbsp;·&nbsp;<span>19 min</span>&nbsp;·&nbsp;<span>3839 words</span></div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#diffusion-models aria-label="Diffusion Models">Diffusion Models</a><ul><li><a href=#forward-process aria-label="Forward Process">Forward Process</a></li><li><a href=#reverse-process aria-label="Reverse Process">Reverse Process</a></li><li><a href=#generative-model aria-label="Generative Model">Generative Model</a></li><li><a href=#model-log-likelihood aria-label="Model Log Likelihood">Model Log Likelihood</a></li></ul></li><li><a href=#specific-diffusion-kernel aria-label="Specific Diffusion Kernel">Specific Diffusion Kernel</a><ul><li><a href=#forward-process-1 aria-label="Forward Process">Forward Process</a></li><li><a href=#reverse-process-1 aria-label="Reverse Process">Reverse Process</a></li><li><a href=#loss-function aria-label="Loss Function">Loss Function</a><ul><li><a href=#simplification aria-label=Simplification>Simplification</a></li></ul></li></ul></li><li><a href=#simple-code-implementation aria-label="Simple Code Implementation">Simple Code Implementation</a></li><li><a href=#citation aria-label=Citation>Citation</a></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div><div class=post-content><p>This is the first post in the Paper Research series. In this series I will continue to update some personal study notes on reading papers. <strong>This post will introduce the basic work of diffusion probabilistic models (DPM), including the derivation of formulas and simple code verification.</strong>
The content is mainly from <a href=https://arxiv.org/abs/1503.03585>Sohl-Dickstein <em>et al.</em> (2015)</a> and <a href=https://arxiv.org/abs/2006.11239>Ho <em>et al.</em> (2020)</a>. If you have any suggestions on this post or would like to communicate with me, please leave comments below.</p><h2 id=diffusion-models>Diffusion Models<a hidden class=anchor aria-hidden=true href=#diffusion-models>#</a></h2><p>What are Diffusion Models? Refer to <a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#:~:text=Diffusion%20models%20are%20inspired%20by%20non%2Dequilibrium%20thermodynamics.%20They%20define%20a%20Markov%20chain%20of%20diffusion%20steps%20to%20slowly%20add%20random%20noise%20to%20data%20and%20then%20learn%20to%20reverse%20the%20diffusion%20process%20to%20construct%20desired%20data%20samples%20from%20the%20noise.">Weng, (2021)</a>:</p><blockquote><p>Diffusion models are inspired by non-equilibrium thermodynamics. They define a Markov chain of diffusion steps to slowly add random noise to data and then learn to reverse the diffusion process to construct desired data samples from the noise.</p></blockquote><figure class=align-center><img loading=lazy src=images/Diffusion_Models.png#center alt="Fig. 1. Framework Diagram of Diffusion Models." width=100%><figcaption><p>Fig. 1. Framework Diagram of Diffusion Models.</p></figcaption></figure><p>My personal understanding of Diffusion Models is a framework (Fig. 1) where there are no trainable parameters in the forward process and there are training parameters in the reverse process. And there is no restriction on what type of neural network to use in terms of the distribution that needs to be expressed implicitly in the reverse process.</p><figure class=align-center><img loading=lazy src=images/diffusion_pgm.png#center alt="Fig. 2. Flowchart of Diffusion Models. (Image source: Das, 2021)" width=70%><figcaption><p>Fig. 2. Flowchart of Diffusion Models. (Image source: <a href=https://ayandas.me/blog-tut/2021/12/04/diffusion-prob-models.html>Das, 2021</a>)</p></figcaption></figure><h3 id=forward-process>Forward Process<a hidden class=anchor aria-hidden=true href=#forward-process>#</a></h3><p>The forward process is a <strong>Markov process</strong>. According to <a href="https://en.wikipedia.org/wiki/Markov_chain#:~:text=A%20Markov%20chain%20or%20Markov,the%20state%20of%20affairs%20now.%22">Wikipedia</a>, a Markov chain or Markov process is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. Informally, this may be thought of as, &ldquo;What happens next depends only on the state of affairs now.&rdquo;</p><p>The main goal of the forward process is to gradually convert <strong>the data distribution</strong> <code>$q(\mathbf{x}_0)$</code> into <strong>an analytically tractable distribution</strong> <code>$\pi(\mathbf{y})$</code> by repeated application of a <strong>Markov diffusion kernel</strong> <code>$T_\pi(\mathbf{y}|\mathbf{y}'; \beta)$ for $\pi(\mathbf{y})$</code>, where <code>$\beta$</code> is the diffusion rate,</p><div>$$\pi(\mathbf{y}) = \int T_\pi(\mathbf{y}|\mathbf{y}'; \beta) \mathrm{d}\mathbf{y}' \tag{1}$$</div><div>$$q(\mathbf{x}_t|\mathbf{x}_{t-1}) = T_\pi(\mathbf{x}_t|\mathbf{x}_{t-1}; \beta_t) \tag{2}$$</div><p>The forward trajectory (<strong>joint distribution</strong>), corresponding to starting at the data distribution and performing T steps of diffusion, is thus</p><div>$$q(\mathbf{x}_0, \mathbf{x}_1, \cdots, \mathbf{x}_T) = q(\mathbf{x}_{(0\cdots T)}) = q(\mathbf{x}_0)\prod_{t=1}^T q(\mathbf{x}_t | \mathbf{x}_{t-1}) \tag{3}$$</div><figure class=align-center><img loading=lazy src=images/Forward%20Process.png#center alt="Fig. 3. Illustration of forward (diffusion) trajectory." width=100%><figcaption><p>Fig. 3. Illustration of forward (diffusion) trajectory.</p></figcaption></figure><h3 id=reverse-process>Reverse Process<a hidden class=anchor aria-hidden=true href=#reverse-process>#</a></h3><p>The reverse process also is a <strong>Markov process</strong>. If we can reverse the above process and sample from <code>$q(\mathbf{x}_{t-1} | \mathbf{x}_t)$</code>, we will be able to recreate the true sample from a Gaussian noise input, <code>$\mathbf{x}_T \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$</code>. Unfortunately, we cannot easily estimate <code>$q(\mathbf{x}_{t-1} | \mathbf{x}_t)$</code> and there fore we need to learn a model <code>$p_\theta$</code> to approximate these conditional probabilities in order to run the reverse process. We want <code>$p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t)$</code> to approximate <code>$q(\mathbf{x}_{t-1} | \mathbf{x}_t)$</code> as closely as possible for all <code>$t$</code>.</p><p>The generative distribution <code>$p_\theta(\mathbf{x}_{t-1} | \mathbf{x}\_t)$</code> will be trained to describe the same trajectory (also a <strong>joint distribution</strong>), but in reverse,</p><div>$$p_\theta (\mathbf{x}_T) = \pi(\mathbf{x}_T) \tag{4}$$</div><div>$$ p_\theta(\mathbf{x}_0, \mathbf{x}_1, \cdots, \mathbf{x}_T) = p_\theta(\mathbf{x}_{(0\cdots T)}) = p_\theta(\mathbf{x}_T)\prod_{t=1}^T p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t}) \tag{5}$$</div><h3 id=generative-model>Generative Model<a hidden class=anchor aria-hidden=true href=#generative-model>#</a></h3><ul><li>The forward trajectory (joint distribution): image to noise.</li><li>The reverse trajectory (joint distribution): noise to image.</li><li>The Model Probability (marginal distribution): the probability the generative model assigns to the data.</li></ul><p>The probability the generative model assigns to the data is
$$p_\theta(\mathbf{x}_0) = \int \int \cdots \int p_\theta(\mathbf{x}_0, \mathbf{x}_1, \cdots, \mathbf{x}_T) \mathrm{d}\mathbf{x}_1 \mathrm{d}\mathbf{x}_2 \cdots \mathrm{d}\mathbf{x}_T \tag{6}$$
For convenience, we simply denote it as:
$$p_\theta(\mathbf{x}_0) = \int \mathrm{d}\mathbf{x}_{(1\cdots T)} \ p_\theta(\mathbf{x}_{(0\cdots T)}) \tag{7}$$</p><p>But this integral (7) is intractable! We can handle this integral similarly to some of the ways in <strong>VAE</strong>. Taking a cue from <strong>annealed importance sampling</strong> and <strong>the Jarzynski equality</strong>, we instead evaluate the relative probability of the forward and reverse trajectories, averaged over forward trajectories,</p><div>$$
\begin{equation*}
\begin{split}
a=b
\end{split}
\end{equation*}
$$</div><div>$$
\begin{equation*}
\begin{split}
p_\theta(\mathbf{x}_0) &= \int \mathrm{d}\mathbf{x}_{(1\cdots T)} \ p_\theta(\mathbf{x}_{(0\cdots T)}) \frac{q(\mathbf{x}_{(1\cdots T)} | \mathbf{x}_0)}{q(\mathbf{x}_{(1\cdots T)} | \mathbf{x}_0)} \\
&= \int \mathrm{d}\mathbf{x}_{(1\cdots T)} \ q(\mathbf{x}_{(1\cdots T)} | \mathbf{x}_0) \frac{\color{red} p_\theta(\mathbf{x}_{(0\cdots T)})}{\color{blue} q(\mathbf{x}_{(1\cdots T)} | \mathbf{x}_0)} \\
&= \int \mathrm{d}\mathbf{x}_{(1\cdots T)} \ q(\mathbf{x}_{(1\cdots T)} | \mathbf{x}_0) \frac{\color{red} p_\theta(\mathbf{x}_T) \prod_{t=1}^T p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{\color{blue} \frac{q(\mathbf{x}_0, \mathbf{x}_{(1\cdots T)})}{q(\mathbf{x}_0)}} \\
&= \int \mathrm{d}\mathbf{x}_{(1\cdots T)} \ q(\mathbf{x}_{(1\cdots T)} | \mathbf{x}_0) \frac{p_\theta(\mathbf{x}_T) \prod_{t=1}^T p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{\color{blue} \frac{q(\mathbf{x}_0) \prod_{t=1}^T q(\mathbf{x}_t | \mathbf{x}_{t-1})}{q(\mathbf{x}_0)}} \\
&= \int \mathrm{d}\mathbf{x}_{(1\cdots T)} \ q(\mathbf{x}_{(1\cdots T)} | \mathbf{x}_0) \frac{p_\theta(\mathbf{x}_T) \prod_{t=1}^T p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{\prod_{t=1}^T q(\mathbf{x}_t | \mathbf{x}_{t-1})} \\
&= \int \mathrm{d}\mathbf{x}_{(1\cdots T)} \ q(\mathbf{x}_{(1\cdots T)} | \mathbf{x}_0) p_\theta(\mathbf{x}_T) \prod_{t=1}^T \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_t | \mathbf{x}_{t-1})}
\end{split}
\end{equation*}
\tag{8}
$$</div><h3 id=model-log-likelihood>Model Log Likelihood<a hidden class=anchor aria-hidden=true href=#model-log-likelihood>#</a></h3><p>We want the estimated data distribution (<code>$p_\theta(\mathbf{x}\_0)$</code>) to be as close as possible to the actual data distribution (<code>$q(\mathbf{x}\_0)$</code>).
So training amounts to maximizing the model log likelihood,
$$
\begin{equation*}
\begin{split}
\mathcal{L} &= \int \mathrm{d}\mathbf{x}_0 \ q(\mathbf{x}_0) \log p_\theta (\mathbf{x}_0) \\
&= \int \mathrm{d}\mathbf{x}_0 \ q(\mathbf{x}_0) { \log \left [ \int \mathrm{d}\mathbf{x}_{(1\cdots T)} q(\mathbf{x}_{(1\cdots T)} | \mathbf{x}_0) p_\theta(\mathbf{x}_T) \prod_{t=1}^T \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right ]} \\
&= \int \mathrm{d}\mathbf{x}_0 \ q(\mathbf{x}_0) {\color{blue} \log \left \{\mathbb{E}_{\mathbf{x}_{(1\cdots T)} \sim q(\mathbf{x}_{(1\cdots T)} | \mathbf{x}_0)} \left [ p_\theta(\mathbf{x}_T) \prod_{t=1}^T \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right ] \right \}} \\
&\geq \int \mathrm{d}\mathbf{x}_0 \ q(\mathbf{x}_0) {\color{blue} \mathbb{E}_{\mathbf{x}_{(1\cdots T)} \sim q(\mathbf{x}_{(1\cdots T)} | \mathbf{x}_0)} \left \{ \log \left [ p_\theta(\mathbf{x}_T) \prod_{t=1}^T \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right ] \right \}} \\
&= \int \mathrm{d}\mathbf{x}_0 \ q(\mathbf{x}_0) \int \mathbb{d}\mathbf{x}_{(1\cdots T)} \ q(\mathbf{x}_{(1\cdots T)} | \mathbf{x}_0) \log \left [ p_\theta(\mathbf{x}_T) \prod_{t=1}^T \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right ] \\
&= \int \mathbb{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_0) q(\mathbf{x}_{(1\cdots T)} | \mathbf{x}_0) \log \left [ p_\theta(\mathbf{x}_T) \prod_{t=1}^T \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right ] \\
&= \int \mathbb{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) \log \left [ p_\theta(\mathbf{x}_T) \prod_{t=1}^T \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right ] \\
\end{split}
\end{equation*}
\tag{9}
$$</p><p>The blue part in Eq. (9) provided by <a href=https://en.wikipedia.org/wiki/Jensen%27s_inequality><strong>Jensen&rsquo;s inequality</strong></a> as Fig. 5.</p><div align=center><img src=images/inequality.png alt width=50%>
Fig. 4. Visualization of Jensen's inequality in logarithmic function.</div><p>So we have the lower bound of <code>$\mathcal{L}$</code>, let&rsquo;s write it down as
$$\mathcal{K} = \int \mathbb{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) \log \left [ p_\theta(\mathbf{x}_T) \prod_{t=1}^T \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right ] \tag{10}$$</p><p><strong>1) Peel off $p_\theta(\mathbf{x}_T)$ in $\mathcal{K}$ as an entropy</strong></p><p>We can peel off the contribution from $p_\theta(\mathbf{x}_T)$, and rewrite it as an entropy,
$$
\begin{equation*}
\begin{split}
\mathcal{K} &= \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) {\color{blue} \log \left [ p_\theta(\mathbf{x}_T) \prod_{t=1}^T \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right ]} \\
&= \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) {\color{blue} \left \{ \log p_\theta(\mathbf{x}_T) + \sum_{t=1}^T \log \left [ \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right ] \right \} } \\
&= \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) {\color{blue} \sum_{t=1}^T \log \left [ \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right ]} + \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) {\color{blue} \log p_\theta(\mathbf{x}_T)} \\
&= \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) { \sum_{t=1}^T \log \left [ \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right ]} + {\color{red} \int \mathrm{d}\mathbf{x}_T \ q(\mathbf{x}_T) \log \underbrace{p_\theta(\mathbf{x}_T)}_{{\normalsize \pi}(\mathbf{x}_T)}} \\
\end{split}
\end{equation*}
\tag{11}
$$</p><p>By design, the cross entropy to $\pi(\mathbf{x}_T)$ is constant under our diffusion kernels, and equal to the entropy of $p_\theta(\mathbf{x}_T)$. Therefore,
$$
\mathcal{K} = \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) \sum_{t=1}^T \log \left [ \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right ] {\color{red} - \ \mathcal{H}_p(\mathbf{x}_T)}
\tag{12}
$$</p><p><strong>2) Remove the edge effect at $t=0$</strong></p><p>In order to avoid edge effects, we set the final step of the reverse trajectory to be identical to the corresponding forward diffusion step,
$$p_\theta(\mathbf{x}_0 | \mathbf{x}_1) = q(\mathbf{x}_1 | \mathbf{x}_0) \frac{\pi(\mathbf{x}_{0})}{\pi(\mathbf{x}_{1})} = T_\pi(\mathbf{x}_0 | \mathbf{x}_1 ; \beta) \tag{13}$$</p><p>We then use this equivalence to remove the contribution of <strong>the first time-step</strong> in the sum,
$$
\begin{equation*}
\begin{split}
\mathcal{K} &= \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) {\color{blue} \sum_{t=1}^T \log \left [ \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right ]} - \mathcal{H}_p(\mathbf{x}_T) \\
&= \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) {\color{blue} \sum_{t=2}^T \log \left [ \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right ]} + \underbrace{\int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) {\color{blue} \log \frac{p_\theta(\mathbf{x}_0 | \mathbf{x}_1)}{q(\mathbf{x}_1 | \mathbf{x}_0)}}}_{ {\large \mathbb{E}}_{\mathbf{x}_{(0\cdots T)} \sim q(\mathbf{x}_{(0\cdots T)})} {\normalsize \log \frac{p_\theta(\mathbf{x}_0 | \mathbf{x}_1)}{q(\mathbf{x}_1 | \mathbf{x}_0)}}} - \mathcal{H}_p(\mathbf{x}_T) \\
&= \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) \sum_{t=2}^T \log \left [ \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right ] + \int \mathrm{d}\mathbf{x}_{(0, 1)} \ q(\mathbf{x}_0, \mathbf{x}_1) \log \frac{\color{red} p_\theta(\mathbf{x}_0 | \mathbf{x}_1)}{q(\mathbf{x}_1 | \mathbf{x}_0)} - \mathcal{H}_p(\mathbf{x}_T) \\
&= \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) \sum_{t=2}^T \log \left [ \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right ] + \int \mathrm{d}\mathbf{x}_{(0, 1)} \ q(\mathbf{x}_0, \mathbf{x}_1) \log \frac{\color{red} q(\mathbf{x}_1 | \mathbf{x}_0) \pi(\mathbf{x}_0)}{q(\mathbf{x}_1 | \mathbf{x}_0) {\color{red} \pi(\mathbf{x}_1)}} - \mathcal{H}_p(\mathbf{x}_T) \\
&= \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) \sum_{t=2}^T \log \left [ \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right ] + {\color{green} \int \mathrm{d}\mathbf{x}_{(0, 1)} \ q(\mathbf{x}_0, \mathbf{x}_1) \log \frac{\pi(\mathbf{x}_0)}{\pi(\mathbf{x}_1)}} - \mathcal{H}_p(\mathbf{x}_T) \\
\end{split}
\end{equation*}
\tag{14}
$$</p><p>For ease of presentation, <strong>the green part of Eq. (14)</strong> is derived separately,
$$
\begin{equation*}
\begin{split}
{\color{green} \int \mathrm{d}\mathbf{x}_{(0, 1)} \ q(\mathbf{x}_0, \mathbf{x}_1) \log \frac{\pi(\mathbf{x}_0)}{\pi(\mathbf{x}_1)}} &= \int \mathrm{d}\mathbf{x}_{(0, 1)} \ q(\mathbf{x}_0, \mathbf{x}_1) \left [ \log \pi(\mathbf{x}_0) - \log \pi(\mathbf{x}_1) \right ] \\
&= \int \mathrm{d}\mathbf{x}_{(0, 1)} \ q(\mathbf{x}_0, \mathbf{x}_1) \log \pi(\mathbf{x}_0) - \int \mathrm{d}\mathbf{x}_{(0, 1)} \ q(\mathbf{x}_0, \mathbf{x}_1) \log \pi(\mathbf{x}_1) \\
&= {\color{red} \int \mathrm{d}\mathbf{x}_{0} \ q(\mathbf{x}_{0}) \log \pi(\mathbf{x}_0)} - {\color{red} \int \mathrm{d}\mathbf{x}_{1} \ q(\mathbf{x}_{1}) \log \pi(\mathbf{x}_1)} \\
&= {\color{red} \mathcal{H}_p(\mathbf{x}_T)} - {\color{red} \mathcal{H}_p(\mathbf{x}_T)} \\
&= 0 \\
\end{split}
\end{equation*}
\tag{15}
$$</p><p>where we again used the fact that by design $\color{red} -\int \mathrm{d}\mathbf{x}_t \ q(\mathbf{x}_t) \log \pi(\mathbf{x}_t) = \mathcal{H}_p(\mathbf{x}_T)$ is a constant for all $t$.</p><p>Therefore, the lower bound in Eq. (14) becomes
$$\mathcal{K} = \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) \sum_{t=2}^T \log \left [ \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right ] - \mathcal{H}_p(\mathbf{x}_T) \tag{16}$$</p><p><strong>3) Rewrite in terms of $q(\mathbf{x}_{t-1} | \mathbf{x}_t)$</strong></p><p>Because the forward trajectory is a Markov process,
$$
\begin{equation*}
q(\mathbf{x}_t | \mathbf{x}_{t-1}) = \left \{
\begin{matrix}
q(\mathbf{x}_t | \mathbf{x}_{t-1}, \mathbf{x}_0) & , t > 1 \\
q(\mathbf{x}_1 | \mathbf{x}_{0}, \mathbf{x}_0) = q(\mathbf{x}_1 | \mathbf{x}_{0}) & , t = 1
\end{matrix}
\right .
\end{equation*}
\tag{17}
$$</p><p>$$
\mathcal{K} = \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) \sum_{t=2}^T \log \left [ \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{\color{blue} q(\mathbf{x}_t | \mathbf{x}_{t-1}, \mathbf{x}_0)} \right ] - \mathcal{H}_p(\mathbf{x}_T)
\tag{18}
$$</p><p>Using Bayes’ rule we can rewrite this in terms of a posterior and marginals from the forward trajectory,
$$
\mathcal{K} = \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) \sum_{t=2}^T \log \left [ \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{\color{blue} q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_0)} \frac{\color{blue} q(\mathbf{x}_{t-1} | \mathbf{x}_0)}{\color{blue} q(\mathbf{x}_{t} | \mathbf{x}_0)} \right ] - \mathcal{H}_p(\mathbf{x}_T)
\tag{19}
$$</p><p><strong>4) Rewrite in terms of <a href=https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence><strong>KL divergences</strong></a> and entropies</strong></p><p>$$
\begin{equation*}
\begin{split}
\mathcal{K} &= \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) \sum_{t=2}^T \log \left [ \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_0)} \frac{q(\mathbf{x}_{t-1} | \mathbf{x}_0)}{q(\mathbf{x}_{t} | \mathbf{x}_0)} \right ] - \mathcal{H}_p(\mathbf{x}_T) \\
&= \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) \sum_{t=2}^T \left [ \log \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_0)} + \log \frac{q(\mathbf{x}_{t-1} | \mathbf{x}_0)}{q(\mathbf{x}_{t} | \mathbf{x}_0)} \right ] - \mathcal{H}_p(\mathbf{x}_T) \\
&= \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) \sum_{t=2}^T \log \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_0)} \\
&\quad + {\color{green} \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) \sum_{t=2}^T \log \frac{q(\mathbf{x}_{t-1} | \mathbf{x}_0)}{q(\mathbf{x}_{t} | \mathbf{x}_0)}} - \mathcal{H}_p(\mathbf{x}_T) \\
\end{split}
\end{equation*}
\tag{20}
$$</p><p>For ease of presentation, <strong>the green part of Eq. (20)</strong> is derived separately,
$$
\begin{equation*}
\begin{split}
{\color{green} \int \mathrm{d}\mathbf{x}_{(0\cdots T)}} &\ {\color{green} q(\mathbf{x}_{(0\cdots T)}) \sum_{t=2}^T \log \frac{q(\mathbf{x}_{t-1} | \mathbf{x}_0)}{q(\mathbf{x}_{t} | \mathbf{x}_0)}} \\
&= \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) \log {\color{blue} \prod_{t=2}^T \frac{q(\mathbf{x}_{t-1} | \mathbf{x}_0)}{q(\mathbf{x}_{t} | \mathbf{x}_0)}} \\
&= \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) \log {\color{blue} \frac{q(\mathbf{x}_{1} | \mathbf{x}_0)}{q(\mathbf{x}_{T} | \mathbf{x}_0)}} \\
&= \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) \left [ \log q(\mathbf{x}_{1} | \mathbf{x}_0) - \log q(\mathbf{x}_{T} | \mathbf{x}_0) \right ] \\
&= \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) \log q(\mathbf{x}_{1} | \mathbf{x}_0) - \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) \log q(\mathbf{x}_{T} | \mathbf{x}_0) \\
&= {\color{red} \int \mathrm{d}\mathbf{x}_{(0,1)} \ q(\mathbf{x}_0, \mathbf{x}_1) \log q(\mathbf{x}_{1} | \mathbf{x}_0)} - {\color{red} \int \mathrm{d}\mathbf{x}_{(0,T)} \ q(\mathbf{x}_0, \mathbf{x}_T) \log q(\mathbf{x}_{T} | \mathbf{x}_0)} \\
&= {\color{red} \mathcal{H}_q(\mathbf{x}_T | \mathbf{x}_0)} - {\color{red} \mathcal{H}_q(\mathbf{x}_1 | \mathbf{x}_0)} \quad ; \text{(conditional entropy)}
\end{split}
\end{equation*}
\tag{21}
$$</p><p>Therefore, the lower bound in Eq. (20) becomes
$$
\mathcal{K} = {\color{brown} \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) \sum_{t=2}^T \log \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_0)}} + \mathcal{H}_q(\mathbf{x}_T | \mathbf{x}_0) - \mathcal{H}_q(\mathbf{x}_1 | \mathbf{x}_0) - \mathcal{H}_p(\mathbf{x}_T)
\tag{22}
$$</p><p>For ease of presentation, <strong>the brown part of Eq. (22)</strong> is derived separately,
$$
\begin{equation*}
\begin{split}
{\color{brown} \int \mathrm{d}\mathbf{x}_{(0\cdots T)}} & \ {\color{brown} q(\mathbf{x}_{(0\cdots T)}) \sum_{t=2}^T \log \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_0)}} \\
&= \sum_{t=2}^T \int \mathrm{d}\mathbf{x}_{(0\cdots T)} \ q(\mathbf{x}_{(0\cdots T)}) \log \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_0)} \\
&= \sum_{t=2}^T \int \mathrm{d}\mathbf{x}_{0}\mathrm{d}\mathbf{x}_{t-1}\mathrm{d}\mathbf{x}_{t} \ {\color{blue} q(\mathbf{x}_0, \mathbf{x}_{t-1}, \mathbf{x}_t)} \log \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_0)} \\
&= \sum_{t=2}^T \int \mathrm{d}\mathbf{x}_{0}\mathrm{d}\mathbf{x}_{t-1}\mathrm{d}\mathbf{x}_{t} \ {\color{blue} q(\mathbf{x}_0, \mathbf{x}_t) q(\mathbf{x}_{t-1}| \mathbf{x}_t, \mathbf{x}_0)} \log \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_0)} \\
&= \sum_{t=2}^T \int \mathrm{d}\mathbf{x}_{0}\mathrm{d}\mathbf{x}_{t} \ q(\mathbf{x}_0, \mathbf{x}_t) \underbrace{\color{red} \left \{ \int \mathrm{d}\mathbf{x}_{t-1} \ q(\mathbf{x}_{t-1}| \mathbf{x}_t, \mathbf{x}_0) \log \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})}{q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_0)} \right \} }_{
\begin{array}{c}
\small
\text{KL Divergence (also called relative entropy)} \\
{\color{violet} \mathcal{D}_{KL}(P \| Q) = \int_{-\infty}^{+\infty} p(x) \log \frac{p(x)}{q(x)} \mathrm{d}x}
\end{array}
} \\
&= {\color{red} -} \sum_{t=2}^T \int \mathrm{d}\mathbf{x}_{0}\mathrm{d}\mathbf{x}_{t} \ q(\mathbf{x}_0, \mathbf{x}_t) {\color{red} \mathcal{D}_{KL}(q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0) \| p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t))}
\end{split}
\end{equation*}
\tag{23}
$$</p><p>Therefore, the lower bound in Eq. (22) becomes
$$
\begin{equation*}
\begin{split}
\mathcal{K} = &- \sum_{t=2}^T \int \mathrm{d}\mathbf{x}_{0}\mathrm{d}\mathbf{x}_{t} \ q(\mathbf{x}_0, \mathbf{x}_t) \mathcal{D}_{KL}(q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0) \| p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t)) \\
&+ \mathcal{H}_q(\mathbf{x}_T | \mathbf{x}_0) - \mathcal{H}_q(\mathbf{x}_1 | \mathbf{x}_0) - \mathcal{H}_p(\mathbf{x}_T)
\end{split}
\end{equation*}
\tag{24}
$$</p><p>Note that the entropies can be analytically computed, and the <strong>KL divergence</strong> can be analytically computed given $\mathbf{x}_0$ and $\mathbf{x}_t$.</p><p>Training consists of finding the reverse Markov transitions which maximize this lower bound on the log likelihood,
$$
p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t) = \argmax_{\theta} \mathcal{K}
\tag{25}
$$</p><h2 id=specific-diffusion-kernel>Specific Diffusion Kernel<a hidden class=anchor aria-hidden=true href=#specific-diffusion-kernel>#</a></h2><h3 id=forward-process-1>Forward Process<a hidden class=anchor aria-hidden=true href=#forward-process-1>#</a></h3><p>Specify that the <strong>Markov diffusion kernel</strong> in Eq. (2) is subject to a Gaussian distribution,
$$
q(\mathbf{x}_t | \mathbf{x}_{t-1}) = T_\pi(\mathbf{x}_t | \mathbf{x}_{t-1}; \beta_t) = \mathcal{N}(\mathbf{x}_t; \sqrt{1 - \beta_t} \mathbf{x}_{t-1}, \beta_t \mathbf{I})
\tag{26}
$$</p><p>A nice property of the above process is that we can sample $\mathbf{x}_t$ at any arbitrary time step $t$ in a closed form using reparameterization trick. Let $\alpha_t = 1 - \beta_t$ and $\bar{\alpha}_t = \prod_{i=1}^t \alpha_i$ :
$$
\begin{equation*}
\begin{split}
\mathbf{x}_t &= \sqrt{\alpha_t} {\color{blue} \mathbf{x}_{t-1}} + \sqrt{1 - \alpha_t} \bm{\epsilon}_{t-1} \\
&= \sqrt{\alpha_t} {\color{blue} (\sqrt{\alpha_{t-1}} \mathbf{x}_{t-2} + \sqrt{1 - \alpha_{t-1}} \bm{\epsilon}_{t-2})} + \sqrt{1 - \alpha_t} \bm{\epsilon}_{t-1} \\
&= \sqrt{\alpha_t \alpha_{t-1}} \mathbf{x}_{t-2} + {\color{red} \sqrt{\alpha_t - \alpha_t \alpha_{t-1}} \bm{\epsilon}_{t-2} + \sqrt{1 - \alpha_t} \bm{\epsilon}_{t-1}} \\
&= \sqrt{\alpha_t \alpha_{t-1}} \mathbf{x}_{t-2} + {\color{red} \sqrt{\sqrt{\alpha_t - \alpha_t \alpha_{t-1}}^2 + \sqrt{1 - \alpha_t}^2} \bar{\bm{\epsilon}}_{t-2}} \\
&= \sqrt{\alpha_t \alpha_{t-1}} \mathbf{x}_{t-2} + \sqrt{1 - \alpha_t \alpha_{t-1}} \bar{\bm{\epsilon}}_{t-2} \\
&= \cdots \\
&= \sqrt{\bar{\alpha}_t} \mathbf{x}_{0} + \sqrt{1 - \bar{\alpha}_t} \bar{\bm{\epsilon}}_0 \\
&= \sqrt{\bar{\alpha}_t} \mathbf{x}_{0} + \sqrt{1 - \bar{\alpha}_t} {\color{green} \bm{\epsilon}_{t}} \quad \text{; to correspond to the subscript of } \mathbf{x}_t \\
\end{split}
\end{equation*}
\tag{27}
$$
where ${\color{green} \bm{\epsilon}_{t}}, \bm{\epsilon}_{t-1}, \bm{\epsilon}_{t-2}, \cdots \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$.</p><p>Recall <strong>the red part of Eq. (27)</strong> when we merge two Gaussians with different variance, $\mathcal{N}(\mathbf{0}, \sigma_1^2\mathbf{I})$ and $\mathcal{N}(\mathbf{0}, \sigma_2^2\mathbf{I})$, the new distribution is $\mathcal{N}(\mathbf{0}, (\sigma_1^2 + \sigma_2^2)\mathbf{I})$.</p><p>Thus, we have
$$
q(\mathbf{x}_t | \mathbf{x}_0) = \mathcal{N}(\mathbf{x}_t; \sqrt{\bar{\alpha}_t} \mathbf{x}_0, (1 - \bar{\alpha}_t) \mathbf{I})
\tag{28}
$$</p><p>Usually, we can afford a larger update step when the sample gets noisier, so $\beta_1 &lt; \beta_2 &lt; \cdots &lt; \beta_T$ and therefore $\bar{\alpha}_1 > \bar{\alpha}_2 > \cdots > \bar{\alpha}_T$.</p><h3 id=reverse-process-1>Reverse Process<a hidden class=anchor aria-hidden=true href=#reverse-process-1>#</a></h3><p>According to Eq. (26),
$$
p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1}; \bm{\mu}_\theta(\mathbf{x}_t, t), \bm{\sigma}_\theta(\mathbf{x}_t, t))
\tag{29}
$$</p><p>It is noteworthy that the reverse conditional probability is tractable when conditioned on $\mathbf{x}_0$:
$$
q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0) = \mathcal{N}(\mathbf{x}_{t-1}; { \bm{\tilde{\mu}}_t(\mathbf{x}_t, \mathbf{x}_0)}, { \tilde{\beta}_t \mathbf{I}})
\tag{30}
$$</p><p>Using Bayes&rsquo; rule, we have:
$$
\begin{equation*}
\begin{split}
q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0) &= q(\mathbf{x}_{t} | \mathbf{x}_{t-1}, \mathbf{x}_0) \frac{q(\mathbf{x}_{t-1} | \mathbf{x}_0)}{q(\mathbf{x}_{t} | \mathbf{x}_0)} \quad ; \text{bringing in Eq. (26) and Eq. (28)} \\
&\propto \exp \left ( -\frac{1}{2}(\frac{(\mathbf{x}_t - \sqrt{\alpha_t} \mathbf{x}_{t-1})^2}{\beta_t}) \right ) \frac{\displaystyle \exp \left ( -\frac{1}{2}( \frac{(\mathbf{x}_{t-1} - \sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_0)^2}{1 - \bar{\alpha}_{t-1}} ) \right ) }{\displaystyle \exp \left ( -\frac{1}{2}( \frac{(\mathbf{x}_{t} - \sqrt{\bar{\alpha}_{t}} \mathbf{x}_0)^2}{1 - \bar{\alpha}_{t}} ) \right ) } \\
&= \exp \left ( -\frac{1}{2} ( \frac{(\mathbf{x}_t - \sqrt{\alpha_t} \mathbf{x}_{t-1})^2}{\beta_t} + \frac{(\mathbf{x}_{t-1} - \sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_0)^2}{1 - \bar{\alpha}_{t-1}} - \frac{(\mathbf{x}_{t} - \sqrt{\bar{\alpha}_{t}} \mathbf{x}_0)^2}{1 - \bar{\alpha}_{t}} ) \right ) \\
&= \exp \left ( -\frac{1}{2}( \frac{ \mathbf{x}_t^2 - 2\sqrt{\alpha_t} \mathbf{x}_t {\color{blue} \mathbf{x}_{t-1}} + \alpha_t {\color{red} \mathbf{x}_{t-1}^2} }{\beta_t} + \frac{ {\color{red} \mathbf{x}_{t-1}^2} -2\sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0 {\color{blue} \mathbf{x}_{t-1}} + \bar{\alpha}_{t-1} \mathbf{x}_0^2 }{1 - \bar{\alpha}_{t-1}} \right. \\
&\quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \left. - \ \frac{(\mathbf{x}_{t} - \sqrt{\bar{\alpha}_{t}} \mathbf{x}_0)^2}{1 - \bar{\alpha}_{t}} ) \right ) \\
&= \exp \left ( -\frac{1}{2} {\Large (} (\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar{\alpha}_{t-1}}) {\color{red} \mathbf{x}_{t-1}^2} - (\frac{2\sqrt{\alpha_t}}{\beta_t} \mathbf{x}_t + \frac{2\sqrt{\bar{\alpha}_{t-1}}}{1 - \bar{\alpha}_{t-1}} \mathbf{x}_t) {\color{blue} \mathbf{x}_{t-1}} + C(\mathbf{x}_t, \mathbf{x}_0) {\Large )} \right )
\end{split}
\end{equation*}
\tag{31}
$$
where $C(\mathbf{x}_t, \mathbf{x}_0)$ is some function not involving $\mathbf{x}_{t-1}$ and details are omitted.</p><p>Following the general form of $\mathcal{N}(\mu, \sigma^2)$ <strong>probability density function</strong> $f(x) = \frac{1}{\sigma \sqrt{2 \pi}} \exp \left ( -\frac{1}{2} (\frac{x - \mu}{\sigma})^2 \right )$,
$$
(\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar{\alpha}_{t-1}}) {\color{red} \mathbf{x}_{t-1}^2} - (\frac{2\sqrt{\alpha_t}}{\beta_t} \mathbf{x}_t + \frac{2\sqrt{\bar{\alpha}_{t-1}}}{1 - \bar{\alpha}_{t-1}} \mathbf{x}_t) {\color{blue} \mathbf{x}_{t-1}} + C(\mathbf{x}_t, \mathbf{x}_0) = (\frac{x-\mu}{\sigma})^2 = \frac{{\color{red} x^2} - 2\mu {\color{blue} x} + \mu^2}{\sigma^2}
\tag{32}
$$</p><p>The <strong>variance</strong> $(\tilde{\beta}_t \mathbf{I})$ and <strong>mean</strong> $(\bm{\tilde{\mu}}_t(\mathbf{x}_t, \mathbf{x}_0))$ in Eq. (30) can be parameterized as follows:
$$
\begin{equation*}
\begin{split}
\tilde{\beta}_t = 1 / (\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar{\alpha}_{t-1}}) = \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_{t}} \beta_t
\end{split}
\end{equation*}
\tag{33}
$$</p><p>$$
\begin{equation*}
\begin{split}
\bm{\tilde{\mu}}_t(\mathbf{x}_t, \mathbf{x}_0) &= \frac{(\frac{2\sqrt{\alpha_t}}{\beta_t} \mathbf{x}_t + \frac{2\sqrt{\bar{\alpha}_{t-1}}}{1 - \bar{\alpha}_{t-1}} \mathbf{x}_t) \tilde{\beta}_t }{-2} = \frac{\sqrt{\alpha}_t (1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} \mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t}{1 - \bar{\alpha}_t} \mathbf{x}_0
\end{split}
\end{equation*}
\tag{34}
$$</p><p>Thanks to the nice property, we can represent Eq. (27) to $\mathbf{x}_0 = (\mathbf{x}_t - \sqrt{1 - \bar{\alpha}_t} \bm{\epsilon}_t) / \sqrt{\bar{\alpha}_t}$ and bring it into Eq. (34),
$$
\begin{equation*}
\begin{split}
\bm{\mu}_t(\mathbf{x}_t) &= \bm{\tilde{\mu}}_t\left (\mathbf{x}_t, (\mathbf{x}_t - \sqrt{1 - \bar{\alpha}_t} \bm{\epsilon}_t) / \sqrt{\bar{\alpha}_t} \right ) \\
&= \frac{\sqrt{\alpha}_t (1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} \mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t}{1 - \bar{\alpha}_t} (\frac{(\mathbf{x}_t - \sqrt{1 - \bar{\alpha}_t} \bm{\epsilon}_t)}{\sqrt{\bar{\alpha}_t}}) \\
&= {\color{red} \frac{1}{\sqrt{\alpha_t}} \left ( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \bm{\epsilon}_t \right ) }
\end{split}
\end{equation*}
\tag{35}
$$</p><h3 id=loss-function>Loss Function<a hidden class=anchor aria-hidden=true href=#loss-function>#</a></h3><p>We define the lower bound of the negative log likelihood as the variational lower bound loss function,
$$
\begin{equation*}
\begin{split}
\mathcal{L}_{VLB} &= - \mathcal{K} \\
&= \sum_{t=2}^T \int \mathrm{d}\mathbf{x}_{0}\mathrm{d}\mathbf{x}_{t} \ q(\mathbf{x}_0, \mathbf{x}_t) {\color{blue} \mathcal{D}_{KL}(q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0) \| p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t))} \\
&\quad - \mathcal{H}_q(\mathbf{x}_T | \mathbf{x}_0) + \mathcal{H}_q(\mathbf{x}_1 | \mathbf{x}_0) + \mathcal{H}_p(\mathbf{x}_T) \\
&= \sum_{t=2}^T {\Large \mathbb{E}}_{\mathbf{x}_0, \mathbf{x}_t \sim q(\mathbf{x}_0, \mathbf{x}_t)} {\Large [} \underbrace{\color{blue} \mathcal{D}_{KL}(q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0) \| p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t))}_{\color{blue} \mathcal{L}_{t-1}} {\Large ]} - \mathcal{H}_q(\mathbf{x}_T | \mathbf{x}_0) + \mathcal{H}_q(\mathbf{x}_1 | \mathbf{x}_0) + \mathcal{H}_p(\mathbf{x}_T)
\end{split}
\end{equation*}
\tag{36}
$$</p><p>Recall that we need to learn a model to approximate the conditioned probability distributions in the reverse diffusion process, $p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1}; \bm{\mu}_\theta(\mathbf{x}_t, t), \bm{\sigma}_\theta(\mathbf{x}_t, t))$. We would like to train $\bm{\mu}_\theta(\mathbf{x}_t, t)$ to predict $\bm{\mu}_t(\mathbf{x}_t)$ in Eq. (35), and set $\bm{\sigma}_\theta(\mathbf{x}_t, t)$ is equal to $\sigma_t^2\mathbf{I}$, where $\sigma_t^2$ is equal to $\tilde{\beta}_t$ in Eq. (33) or $\beta_t$ for simplify. The loss term $\mathcal{L}_{t-1}$ in Eq. (36) is parameterized to minimize the difference from $\bm{\mu}_t(\mathbf{x}_t)$:
$$
\begin{equation*}
\begin{split}
\mathcal{L}_{t-1} &= \mathcal{D}_{KL}(q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0) \| p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t)) \\
&= \int \mathrm{d}\mathbf{x}_{t-1} \ q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0) \log \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_(t))}{q(\mathbf{x}_{t-1} | \mathbf{x}_(t), \mathbf{x}_0)} \\
&= {\Large \mathbb{E}}_{\small \mathbf{x}_{t-1} \sim q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0)} \left [ \log \frac{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_(t))}{q(\mathbf{x}_{t-1} | \mathbf{x}_(t), \mathbf{x}_0)} \right ] \\
&\propto {\Large \mathbb{E}}_{\small \mathbf{x}_0 \sim q(\mathbf{x}_0), \bm{\epsilon}_t \sim \mathcal{N}(\mathbf{0}, \mathbf{I})} \left [ \frac{1}{2\sigma_t^2} \left \| {\color{blue} \bm{\mu}_t(\mathbf{x}_t)} - {\color{red} \bm{\mu}_\theta(\mathbf{x}_t, t)} \right \| ^2 \right ] \\
&= {\Large \mathbb{E}}_{\small \mathbf{x}_0 \sim q(\mathbf{x}_0), \bm{\epsilon}_t \sim \mathcal{N}(\mathbf{0}, \mathbf{I})} \left [ \frac{1}{2\sigma_t^2} \left \| {\color{blue} \frac{1}{\sqrt{\alpha_t}} \left ( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \bm{\epsilon}_t \right )} - {\color{red} \bm{\mu}_\theta(\mathbf{x}_t, t)} \right \| ^2 \right ]
\end{split}
\end{equation*}
\tag{37}
$$</p><p>Because $\mathbf{x}_t$ is available as input at training time, we can reparameterize the Gaussian noise term instead to make it predict $\bm{\epsilon}$ from the input $\mathbf{x}_t$ at time step $t$:
$$
\bm{\mu}_\theta(\mathbf{x}_t, t) = \frac{1}{\sqrt{\alpha_t}} \left ( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}}_t} \bm{\epsilon}_\theta(\mathbf{x}_t, t) \right )
\tag{38}
$$
where $\bm{\epsilon}_\theta$ is <strong>a function approximator (the model)</strong> intended to predict $\bm{\epsilon}$ from $\mathbf{x}_t$.</p><p>Thus, Eq. (29) can be written as
$$
p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t}) = \mathcal{N} \left ( \mathbf{x}_{t-1} ; \frac{1}{\sqrt{\alpha_t}} \left ( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}}_t} \bm{\epsilon}_\theta(\mathbf{x}_t, t) \right ) , \tilde{\beta}_t \mathbf{I} \right )
\tag{39}
$$</p><p>According to Eq. (39), <strong>sampling</strong> $\mathbf{x}_{t-1} \sim p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_{t})$ is:
$$
\mathbf{x}_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left ( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}}_t} \bm{\epsilon}_\theta(\mathbf{x}_t, t) \right ) + \sqrt{\tilde{\beta}_t} \bm{\epsilon}^*
\tag{40}
$$
where $\bm{\epsilon}^* \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$.</p><p>Furthermore, with the parameterization Eq. (38), the $\mathcal{L}_{t-1}$ in Eq. (37) simplifies to:
$$
\begin{equation*}
\begin{split}
\mathcal{L}_{t-1} &= {\Large \mathbb{E}}_{\small \mathbf{x}_0 \sim q(\mathbf{x}_0), \bm{\epsilon}_t \sim \mathcal{N}(\mathbf{0}, \mathbf{I})} \left [ \frac{1}{2\sigma_t^2} \left \| {\color{blue} \frac{1}{\sqrt{\alpha_t}} \left ( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \bm{\epsilon}_t \right )} - {\color{red} \bm{\mu}_\theta(\mathbf{x}_t, t)} \right \| ^2 \right ] \\
&= {\Large \mathbb{E}}_{\small \mathbf{x}_0 \sim q(\mathbf{x}_0), \bm{\epsilon}_t \sim \mathcal{N}(\mathbf{0}, \mathbf{I})} \left [ \frac{1}{2\sigma_t^2} \left \| {\color{blue} \frac{1}{\sqrt{\alpha_t}} \left ( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \bm{\epsilon}_t \right )} - {\color{red} \frac{1}{\sqrt{\alpha_t}} \left ( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}}_t} \bm{\epsilon}_\theta(\mathbf{x}_t, t) \right )} \right \| ^2 \right ] \\
&= {\Large \mathbb{E}}_{\small \mathbf{x}_0 \sim q(\mathbf{x}_0), \bm{\epsilon}_t \sim \mathcal{N}(\mathbf{0}, \mathbf{I})} \left [ \frac{1}{2\sigma_t^2} \left \| \frac{1}{\sqrt{\alpha_t}} \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \left (\bm{\epsilon}_t - \bm{\epsilon}_\theta(\mathbf{x}_t, t) \right ) \right \| ^2 \right ] \\
&= {\Large \mathbb{E}}_{\small \mathbf{x}_0 \sim q(\mathbf{x}_0), \bm{\epsilon}_t \sim \mathcal{N}(\mathbf{0}, \mathbf{I})} \left [ \frac{\beta_t^2}{2 \alpha_t (1 - \alpha_t) \sigma_t^2} \left \| \bm{\epsilon}_t - \bm{\epsilon}_\theta({\color{orange} \mathbf{x}_t}, t) \right \| ^2 \right ] \quad ; \text{bringing in Eq. (27)} \\
&= {\Large \mathbb{E}}_{\small \mathbf{x}_0 \sim q(\mathbf{x}_0), \bm{\epsilon}_t \sim \mathcal{N}(\mathbf{0}, \mathbf{I})} \left [ {\color{green} \frac{\beta_t^2}{2 \alpha_t (1 - \alpha_t) \sigma_t^2}} \left \| \bm{\epsilon}_t - \bm{\epsilon}_\theta({\color{orange} \sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \bm{\epsilon}_t}, t) \right \| ^2 \right ] \\
\end{split}
\end{equation*}
\tag{41}
$$</p><h4 id=simplification>Simplification<a hidden class=anchor aria-hidden=true href=#simplification>#</a></h4><p>Empirically, <a href=https://arxiv.org/abs/2006.11239>Ho <em>et al.</em> (2020)</a> found that training the diffusion model works better with a simplified objective that ignores the weighting term (<strong>the green part in Eq. (41)</strong>):
$$
\mathcal{L}_t^{\text{simple}} = {\Large \mathbb{E}}_{\small \mathbf{x}_0 \sim q(\mathbf{x}_0), \bm{\epsilon}_t \sim \mathcal{N}(\mathbf{0}, \mathbf{I})} \left [ \left \| \bm{\epsilon}_t - \bm{\epsilon}_\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \bm{\epsilon}_t, t) \right \| ^2 \right ]
\tag{42}
$$</p><h2 id=simple-code-implementation>Simple Code Implementation<a hidden class=anchor aria-hidden=true href=#simple-code-implementation>#</a></h2><p>The jupyter notebook is available at <a href=https://gist.github.com/GavinSun0921/ac4d07e2e64b3f102693686435e7fe9d><strong>GitHub Gist</strong></a>.</p><p>You can click the button at the top of the notebook to open it in <strong>Colab</strong> and run the code for free.</p><script src=https://gist.github.com/GavinSun0921/ac4d07e2e64b3f102693686435e7fe9d.js></script><h2 id=citation>Citation<a hidden class=anchor aria-hidden=true href=#citation>#</a></h2><p>Cited as:</p><ul><li>Gavin, Sun. (May 2023). A Brief Exploration to Diffusion Probabilistic Models [Blog post]. Retrieved from <a href=https://gavinsun0921.github.io/posts/paper-reading-01/>https://gavinsun0921.github.io/posts/paper-reading-01/</a>.</li></ul><p>Or</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bibtex data-lang=bibtex><span class=line><span class=cl><span class=nc>@online</span><span class=p>{</span><span class=nl>gavin2023diffusion</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>title</span>   <span class=p>=</span> <span class=s>{A Brief Exploration to Diffusion Probabilistic Models}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>author</span>  <span class=p>=</span> <span class=s>{Gavin, Sun}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>year</span>    <span class=p>=</span> <span class=s>{2023}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>month</span>   <span class=p>=</span> <span class=s>{May}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>url</span>     <span class=p>=</span> <span class=s>{\url{https://gavinsun0921.github.io/posts/paper-reading-01/}}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><p>[1] Jascha Sohl-Dickstein <em>et al</em>. <a href=https://arxiv.org/abs/1503.03585>&ldquo;Deep Unsupervised Learning using Nonequilibrium Thermodynamics.&rdquo;</a> ICML 2015.</p><p>[2] Jonathan Ho <em>et al</em>. <a href=https://arxiv.org/abs/2006.11239>&ldquo;Denoising Diffusion Probabilistic Models.&rdquo;</a> NeurIPS 2020.</p><p>[3] Jiaming Song <em>et al.</em> <a href=https://arxiv.org/abs/2010.02502>&ldquo;Denoising Diffusion Implicit Models.&rdquo;</a> ICLR 2021.</p><p>[4] Alex Nichol & Prafulla Dhariwal. <a href=https://arxiv.org/abs/2102.09672>&ldquo;Improved Denoising Diffusion Probabilistic Models.&rdquo;</a> ICML 2021.</p><p>[5] Lilian Weng. <a href=https://lilianweng.github.io/posts/2021-07-11-diffusion-models/>&ldquo;What are Diffusion Models? Lil’Log.&rdquo;</a> [Blog post] <a href=https://lilianweng.github.io/>Lil&rsquo;Log</a> 2021.</p><p>[6] Ayan Das. <a href=https://ayandas.me/blog-tut/2021/12/04/diffusion-prob-models.html>&ldquo;An Introduction to Diffusion Probabilistic Models.&rdquo;</a> [Blog post] <a href=https://ayandas.me/blogs.html>Ayan&rsquo;s Blog</a> 2021.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://gavinsun0921.github.io/tags/diffusion/>Diffusion</a></li><li><a href=https://gavinsun0921.github.io/tags/dpm/>DPM</a></li><li><a href=https://gavinsun0921.github.io/tags/computer-vision/>Computer Vision</a></li><li><a href=https://gavinsun0921.github.io/tags/deep-learning/>Deep Learning</a></li></ul><nav class=paginav><a class=prev href=https://gavinsun0921.github.io/posts/fast-paper-reading-01/><span class=title>« Prev</span><br><span>[CVPR'22] Deblurring via Stochastic Refinement 阅读报告</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share A Brief Exploration to Diffusion Probabilistic Models with Code Implementation on x" href="https://x.com/intent/tweet/?text=A%20Brief%20Exploration%20to%20Diffusion%20Probabilistic%20Models%20with%20Code%20Implementation&amp;url=https%3a%2f%2fgavinsun0921.github.io%2fposts%2fpaper-research-01%2f&amp;hashtags=Diffusion%2cDPM%2cComputerVision%2cDeepLearning"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share A Brief Exploration to Diffusion Probabilistic Models with Code Implementation on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fgavinsun0921.github.io%2fposts%2fpaper-research-01%2f&amp;title=A%20Brief%20Exploration%20to%20Diffusion%20Probabilistic%20Models%20with%20Code%20Implementation&amp;summary=A%20Brief%20Exploration%20to%20Diffusion%20Probabilistic%20Models%20with%20Code%20Implementation&amp;source=https%3a%2f%2fgavinsun0921.github.io%2fposts%2fpaper-research-01%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share A Brief Exploration to Diffusion Probabilistic Models with Code Implementation on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fgavinsun0921.github.io%2fposts%2fpaper-research-01%2f&title=A%20Brief%20Exploration%20to%20Diffusion%20Probabilistic%20Models%20with%20Code%20Implementation"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share A Brief Exploration to Diffusion Probabilistic Models with Code Implementation on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fgavinsun0921.github.io%2fposts%2fpaper-research-01%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share A Brief Exploration to Diffusion Probabilistic Models with Code Implementation on whatsapp" href="https://api.whatsapp.com/send?text=A%20Brief%20Exploration%20to%20Diffusion%20Probabilistic%20Models%20with%20Code%20Implementation%20-%20https%3a%2f%2fgavinsun0921.github.io%2fposts%2fpaper-research-01%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share A Brief Exploration to Diffusion Probabilistic Models with Code Implementation on telegram" href="https://telegram.me/share/url?text=A%20Brief%20Exploration%20to%20Diffusion%20Probabilistic%20Models%20with%20Code%20Implementation&amp;url=https%3a%2f%2fgavinsun0921.github.io%2fposts%2fpaper-research-01%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share A Brief Exploration to Diffusion Probabilistic Models with Code Implementation on ycombinator" href="https://news.ycombinator.com/submitlink?t=A%20Brief%20Exploration%20to%20Diffusion%20Probabilistic%20Models%20with%20Code%20Implementation&u=https%3a%2f%2fgavinsun0921.github.io%2fposts%2fpaper-research-01%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer><script src=https://giscus.app/client.js data-repo=GavinSun0921/gavinsun0921.github.io data-repo-id=R_kgDOJgiWSg data-category=Announcements data-category-id=DIC_kwDOJgiWSs4CtrHs data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2025 <a href=https://gavinsun0921.github.io/>Gavin Sun · Spatial Intelligence</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>