<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>4D Reconstruction on Gavin&#39;s Home</title>
    <link>https://gavinsun0921.github.io/tags/4d-reconstruction/</link>
    <description>Recent content in 4D Reconstruction on Gavin&#39;s Home</description>
    <generator>Hugo -- 0.148.2</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Aug 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://gavinsun0921.github.io/tags/4d-reconstruction/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[ICCV&#39;25] St4RTrack: Simultaneous 4D Reconstruction and Tracking in the World 阅读报告</title>
      <link>https://gavinsun0921.github.io/posts/fast-paper-reading-06/</link>
      <pubDate>Tue, 05 Aug 2025 00:00:00 +0000</pubDate>
      <guid>https://gavinsun0921.github.io/posts/fast-paper-reading-06/</guid>
      <description>本文提出了一个 feed-forward 框架，通过引入一种创新的、依赖于时间的 pointmap 表示，并利用一个双分支 Transformer 架构，实现了在统一的世界坐标系中同时进行动态场景的密集追踪与三维重建。</description>
    </item>
    <item>
      <title>[ICCV&#39;25 Oral] Back on Track: Bundle Adjustment for Dynamic Scene Reconstruction 速读</title>
      <link>https://gavinsun0921.github.io/posts/fast-paper-reading-05/</link>
      <pubDate>Mon, 04 Aug 2025 00:00:00 +0000</pubDate>
      <guid>https://gavinsun0921.github.io/posts/fast-paper-reading-05/</guid>
      <description>本文巧妙地提出了一种“运动解耦”机制，通过一个学习的 3D Tracker 将动态物体的自身运动从观测运动中剥离，使得经典的 Bundle Adjustment 能够首次被统一地应用于含动态物体的场景中，极大地提升了动态场景重建中的相机位姿精度和三维重建质量。</description>
    </item>
    <item>
      <title>[ICCV&#39;25] SpatialTrackerV2: 3D Point Tracking Made Easy 速读</title>
      <link>https://gavinsun0921.github.io/posts/fast-paper-reading-04/</link>
      <pubDate>Tue, 29 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://gavinsun0921.github.io/posts/fast-paper-reading-04/</guid>
      <description>本文提出了一个 feed-forward 3D point tracking architecture，它将 video depth、camera pose 和 object motion 进行统一建模和 end-to-end 优化，并通过在 17 个异构数据集上的可扩展训练，实现了 SOTA 的 3D 追踪精度和推理速度。</description>
    </item>
  </channel>
</rss>
