[{"content":"TL;DR 本文提出了一个 feed-forward 3D point tracking architecture，它将 video depth、camera pose 和 object motion 进行统一建模和 end-to-end 优化，并通过在 17 个异构数据集上的可扩展训练，实现了 SOTA 的 3D 追踪精度和推理速度。\n1. 研究动机 (Motivation) 1.1 背景 (Background) 3D point tracking，即从弹幕视频中恢复长期的 3D trajectories，是一种通用的 dynamic scene representation，它在机器人、视频生成、3D/4D 重建等领域有巨大潜力 。\n1.2 现有方法的局限性 (Gap/Limitation of Existing Work) 作者指出了当前方法的两大核心痛点：\n模块化 pipeline 导致的误差累积：现有方法大多依赖于现成的视觉模型（如 optical flow 、monocular depth estimation）构建模块化的 pipeline 。这种分离式的处理方式忽略了 scene geometry、camera motion 和 object motion 三者之间内在的强关联性，导致误差在不同模块间传递和累积。 训练数据限制了泛化能力：以往的 feed-forward 3D tracking models 严重依赖带有 ground-truth 3D tracks 的数据集进行监督训练。这类数据集难以大规模获取，导致模型在多样的 in-the-wild 视频上表现不佳，扩展性差。而基于优化的方法虽然效果好，但因其 per-scene optimization 的设计，推理速度很慢。 1.3 本文价值 (Value Proposition) 本文认为必须将 scene geometry、camera motion 和 object motion 三者进行联合推理和显式解耦，并设计一个能利用多样化、弱监督数据源的框架。其价值在于，通过一个统一、可微的 end-to-end pipeline，实现一个高精度、高速度、高泛化性的通用 3D point tracker。\n2. 解决的关键问题与贡献 (Key Problem Solved \u0026amp; Contribution) 2.1 解决的关键技术问题 如何设计一个可扩展的、feed-forward 的 3D tracking model，该模型能够显式地解耦（disentangle）并联合优化 scene geometry (depth), camera ego-motion (pose) 和 object motion，从而摆脱对 ground-truth 监督的强依赖，并利用海量异构视频数据提升模型的泛化性和鲁棒性？\n2.2 核心贡献 Unified Optimization Framework：提出了一个将 video depth, camera pose 和 pixel-wise 3D motion 分解并集成到一个 fully differentiable, end-to-end pipeline 中的新架构。 SyncFormer 模块：设计了一个名为 SyncFormer 的核心模块，它采用双分支（2D \u0026amp; 3D）结构，通过 cross-attention 进行信息交互，有效解耦了在图像空间（2D）和相机坐标空间（3D）中进行的 trajectories 更新，同时支持在循环中进行可微的 Bundle Adjustment。 Scalable Heterogeneous Training：该框架使得在17个不同类型的数据集上进行大规模联合训练成为可能，这些数据集的监督形式各异（如有标注的RGB-D视频、仅有位姿的视频、甚至是无标签的视频）。 SOTA的性能：实验证明，该方法在 3D tracking benchmark (TAPVid-3D) 上性能相对现有方法提升超过 30%，在 dynamic reconstruction 任务上，其性能与顶尖的 optimization-based 方法相当，而推理速度快50倍。 3. 方法详述 (Method) Fig. 1. SpatialTrackerV2 Pipeline Overview\nSpatialTrackerV2采用了一个前后端架构的设计。\n3.1 Front-end：尺度对齐的 video depth \u0026amp; camera pose estimation 使用 Temporal Encoder 来预测 consistent video depth，同时一个 Neural Camera Tracker 得到 coarse camera（包括 pose, scale, shift）。\n$$\\mathcal{P}^{t},a,b = \\mathcal{H}(\\mathbf{P}_{tok}, \\mathbf{S}\\_{tok}) \\tag{1}$$ 3.2 Back-end: Joint Motion Optimization Fig. 2. SyncFormer\n核心组件：SyncFormer，一个迭代式的 Transformer module。用来联合优化估计 2D trajectories $\\mathcal{T}^{2d} \\in \\mathbb{R}^{T \\times N \\times 2}$ in UV space 以及 3D trajectories $\\mathcal{T}^{3d} \\in \\mathbb{R}^{T \\times N \\times 3}$ in the camera coordinate system。同时对每一个 trajectory 它还动态估计 visibility probability $p^{vis}$ 和 dynamic probability $p^{dyn}$。\n$$ \\mathcal{T}^{2d}_{k+1}, \\mathcal{T}^{3d}_{k+1}, p^{vis}_{k+1}, p^{vis}_{k+1} = f_{sync}(\\mathcal{T}^{2d}_{k}, \\mathcal{T}^{3d}_{k}, p^{vis}_{k}, p^{vis}_{k}, \\mathcal{P}_k) $$ 在每次迭代中，SyncFormer同时更新 2D trajectories、3D trajectories 和 camera pose。\ncamera pose 通过一个可微的 Bundle Adjustment 过程进行优化，该过程利用了 2D 和 3D 轨迹之间的重投影一致性约束。\nSyncFormer 关键采用了双分支（2D \u0026amp; 3D）解耦设计。2D 和 3D 的 Embeddings 在各自的分之内通过 self attention 处理，并通过 proxy tokens 之间的 cross attention 进行信息交换。这防止了两种不同空间（图像空间 vs. 相机空间）的更新信号相互干扰。\n4. 实验分析 (Experiments) 4.1 3D Point Tracking Tab. 1. 3D Point Tracking Results\n4.2 Dynamic 3D Reconstruction 4.2.1 Video Depth Evaluation Tab. 2. Video Depth Evaluation Results\n4.2.2 Camera Poses Tab. 3. Camera Poses Evaluation Results\n4.3 消融实验 (Ablation Analysis) Tab. 4. Ablation Study Results\n消融实验证明简单的 3D lifting (CoTracker3-3D baseline) 会导致 2D 追踪性能急剧下降（AJ 从 64.4 下降至 51.6）。这证明了 SyncFormer 的双分支解耦设计是有效且必要的，因为它避免了不同模态信号的纠缠。\nTab. 5. Heterogeneous Training Analysis\n实验表明，在更多、更真实的视频数据集上进行联合训练能显著提升模型在真实场景上的表现。\n5. 批判性思考 (Cirical Analysis \u0026amp; Personal Thoughts) 5.1 优点 (Strengths) 立意高远且切中要害: 准确地指出了现有模块化 pipeline 的核心弊病，并提出了一个逻辑自洽、优雅的“大一统”解决方案。 结构设计巧妙: SyncFormer 的双分支解耦设计和循环内的 differentiable BA，是解决 2D/3D 联合追踪问题的非常聪明的方案。 工程实践强大: 成功地在17个异构数据集上进行了复杂的多阶段训练，展示了强大的工程能力和模型的可扩展性，这是其取得 SOTA 性能的关键。 5.2 潜在缺点/可疑点 (Weaknesses/ Questionable Points) 复现门槛极高: 训练流程非常复杂，分为三阶段，使用了64块H20 GPU 。这对于算力有限的研究者来说，几乎无法复现或在此基础上进行改进。 对长视频的泛化能力: 论文中训练的视频长度在12-48帧之间 ，测试视频最长为300帧 。对于更长的视频（如数分钟级别），其累积误差和计算开销如何，没有深入探讨。 对 failure cases 分析不足: 尽管定性结果图很惊艳，但论文缺乏对模型典型 failure cases 的深入分析，例如在极端光照、快速运动模糊、或大面积无纹理区域下的表现。 5.3 Ideas to Borrow “分解+统一”：将一个复杂问题分解为几个更明确的子问题，然后设计一个统一框架进行联合优化的思想，值得借鉴。 异构数据训练策略：对于一个新任务如何整合多种不同监督形式的数据集来提升模型泛化能力，可以参考这个工作。 SyncFormer Architecture Pattern：在多模态或多任务学习中，当不同任务的 feature space 或更新动态不一致时，采用类似的解耦-交互的结构，可能是一个通用的有效策略。 ","permalink":"https://gavinsun0921.github.io/posts/fast-paper-reading-04/","summary":"本文提出了一个 feed-forward 3D point tracking architecture，它将 video depth、camera pose 和 object motion 进行统一建模和 end-to-end 优化，并通过在 17 个异构数据集上的可扩展训练，实现了 SOTA 的 3D 追踪精度和推理速度。","title":"[ICCV'25] SpatialTrackerV2: 3D Point Tracking Made Easy"},{"content":"0. 环境基础 系统平台配置： 图 1. 操作系统环境配置 Neovim版本： $ nvim --version NVIM v0.11.3 Build type: Release LuaJIT 2.1.1748459687 Run \u0026#34;nvim -V1 -v\u0026#34; for more info 配置目标：一个轻量化的 C++ 开发环境，带有自动补全、语法高亮、注释、括号补全等功能。 1. 安装 NvChad git clone https://github.com/NvChad/starter ~/.config/nvim \u0026amp;\u0026amp; nvim 安装好之后默认在 ~/.config/nvim 下的文件结构是这样的：\n$ tree nvim/ Wed Jul 23 19:44:25 2025 nvim/ ├── init.lua ├── LICENSE ├── lua │ ├── autocmds.lua │ ├── chadrc.lua │ ├── configs │ │ ├── conform.lua │ │ ├── lazy.lua │ │ └── lspconfig.lua │ ├── mappings.lua │ ├── options.lua │ └── plugins │ └── init.lua └── README.md 4 directories, 11 files 2. 配置 NvChad 2.1 配置 LSP Language Server Protocal (LSP)，即语言服务器协议，用于 编辑器或IDE 和 语言服务器 之间的通信。服务器提供特定于语言的功能，例如代码补全、错误检查、跳转到定义等，而 LSP 确保了不同编辑器和语言服务器之间的互操作性。\n直接在系统安装好 clangd ，能够直接在命令行直接调用，所以就不用再通过 Mason 再安装一份了，直接在 ~/.config/nvim/lua/configs/lspconfig.lua 文件内添加一行：\nrequire(\u0026#34;lspconfig\u0026#34;).clangd.setup {} 现在通过 Neovim 编辑 C/C++ 的文件已经有代码补全等功能了。\n2.2 配置代码缩进和格式化 在 ~/.config/nvim/lua/options.lua 文件中进行配置，原文件使用的 \u0026ldquo;nvchad.options\u0026rdquo; 默认的行缩进是2，我将其修改为4，修改后的文件内容为：\n-- ~/.config/nvim/lua/options.lua require \u0026#34;nvchad.options\u0026#34; -- add yours here! local o = vim.o o.cursorlineopt =\u0026#39;both\u0026#39; -- to enable cursorline! -- Indenting o.expandtab = true o.shiftwidth = 4 o.tabstop = 4 o.softtabstop = 4 然后在 ~/.config/nvim/lua/autocmds.lua 文件中进行配置，调用我们的 clangd 去执行 .clang-format 格式化代码。\n-- ~/.config/nvim/lua/autocmds.lua require \u0026#34;nvchad.autocmds\u0026#34; local autocmd = vim.api.nvim_create_autocmd -- 自动保存时用指定的 .clang-format 格式化 C/C++ 文件 autocmd(\u0026#34;BufWritePre\u0026#34;, { pattern = { \u0026#34;*.cpp\u0026#34;, \u0026#34;*.cc\u0026#34;, \u0026#34;*.c\u0026#34;, \u0026#34;*.h\u0026#34;, \u0026#34;*.hpp\u0026#34; }, callback = function() vim.lsp.buf.format({ async = false }) end, }) LSP（clangd）会自动查找 .clang-format 文件，查找顺序是：\n当前文件目录 -\u0026gt; 父目录 -\u0026gt; ... -\u0026gt; 根目录 -\u0026gt; 用户主目录（$HOME） 所以可以配置一个全局配置文件放在用户主目录里，如果具体文件内有更详细的要求，只要在贴近文件的目录或者项目目录再添加配置文件即可。\n目前在用的 .clang-foramt 配置文件供参考：\nLanguage: Cpp BasedOnStyle: LLVM AccessModifierOffset: -4 NamespaceIndentation: All IndentWidth: 4 TabWidth: 4 UseTab: Never BreakBeforeBraces: Attach IndentCaseLabels: true ColumnLimit: 120 # 连续赋值时，对齐所有等号 AlignConsecutiveAssignments: true # 连续声明时，对齐所有声明的变量名 AlignConsecutiveDeclarations: true AlignTrailingComments: true AllowAllArgumentsOnNextLine: true AllowAllConstructorInitializersOnNextLine: true AllowAllParametersOfDeclarationOnNextLine: true AllowShortBlocksOnASingleLine: Empty AlwaysBreakAfterReturnType: None AllowShortIfStatementsOnASingleLine: true BinPackArguments: false BinPackParameters: false 2.3 配置一键编译并运行 配置单文件编译并运行快捷键，主要用途是用于进行轻量化 C++ 编程，如果是基于 CMake 等工具进行构建的项目同理可以参考进行配置，在 ~/.config/nvim/lua/mappings.lua 添加对应内容：\n-- Compile \u0026amp; run current C++ file map(\u0026#39;n\u0026#39;, \u0026#39;\u0026lt;leader\u0026gt;rr\u0026#39;, function() local filename = vim.fn.expand(\u0026#39;%:t\u0026#39;) local output = vim.fn.expand(\u0026#39;%:r\u0026#39;) local cmd = string.format(\u0026#39;g++ -std=c++14 -O2 -Wall \u0026#34;%s\u0026#34; -o \u0026#34;%s\u0026#34; \u0026amp;\u0026amp; ./%s; rm \u0026#34;%s\u0026#34;\u0026#39;, filename, output, output, output) vim.cmd(\u0026#39;split | terminal \u0026#39; .. cmd) end, { noremap = true, silent = true, desc = \u0026#34;Compile \u0026amp; run current C++ file\u0026#34; }) 这段代码内的对应功能是按下 \u0026lt;leader\u0026gt;rr 快捷键后（默认 \u0026lt;leader\u0026gt; 键是空格），会以 C++ 14 标准去编译当前打开的文件并运行，且会在运行结束后删除编译出来的可执行文件 ，在运行时会拆分出来一个 buffer 用来显示执行界面。\n图 2. 按下 \u0026lt;leader\u0026gt; 键后的提示 图 3. 按下 r 键后的提示 图 4. 再次按下 r 键后运行效果，开始执行程序 图 5. 按下 i 键后进入 INSERT 模式，可以在可执行程序中输入数据 ⚠️注意：执行界面也是需要按下 i 进入 INSERT 模式的。\n3. 竞赛的额外配置（个性化） 3.1 一键复制代码 自己本地运行完代码经常需要复制代码提交到在线 OJ 上，所以额外配置了一个一键将当前编辑代码复制到剪贴板上的快捷键，添加到 ~/.config/nvim/lua/mappings.lua 末尾即可：\n-- 一键拷贝当前文件全部内容到系统剪贴板 map(\u0026#39;n\u0026#39;, \u0026#39;\u0026lt;leader\u0026gt;rc\u0026#39;, function() vim.cmd(\u0026#39;:%y+\u0026#39;) end, { noremap = true, silent = true, desc = \u0026#34;Copy entire file to clipboard\u0026#34; }) 依次按下 空格 r c 三个键后代码就被拷贝到剪贴板内了。\n3.2 更多操作 可以参考上方的操作自定义更多的快捷键。\n4. 尽情使用 可以使用它来写简单的 C++ 单文件代码了，完美的算法竞赛（ICPC/OI等）选手使用场景！\n简单做一道真题吧：P11361 [NOIP2024] 编辑字符串\n图 6. P11361 AC代码在 Neovim 中效果 图 7. P11361 提交结果 ","permalink":"https://gavinsun0921.github.io/posts/neovim01/","summary":"这篇教程为在macOS系统上基于NvChad配置Neovim简单C++开发环境的记录。","title":"Neovim简单C++开发环境配置过程"},{"content":"1. 这篇教程是做什么的？ 在科研工作中，普通用户在服务器上需要使用的 CUDA Toolkit 版本和服务器上已经安装的 CUDA Toolkit 版本不一定一致，在没有 ROOT 权限的情况下，也可以安装需要的 CUDA Toolkit 版本和对应的 cuDNN，本文的实践教程是在 Ubuntu 上。\n⚠️注意：非 ROOT 权限不应该对驱动（CUDA Driver）进行任何修改（也无法修改），如果驱动版本过低，请联系服务器管理员。\n1.1 使用服务器上已有的 CUDA Toolkit 和 cuDNN 常规服务器应该会有已安装的 CUDA Toolkit 和 cuDNN，一般位于 /usr/local/ 目录下，使用时仅需要配置环境变量即可！\n一般来说将下方命令添加到 ~/.bashrc 文件中，CUDA_HOME 环境变量就是 CUDA 对应位置（如果有多个版本，可以自行选择启用哪个版本）。\nexport CUDA_HOME=/usr/local/cuda export CPATH=$CUDA_HOME/include:$CPATH export PATH=$CUDA_HOME/bin:$PATH export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH export LIBRARY_PATH=$CUDA_HOME/lib64:$LIBRARY_PATH ⚠️注意：配置完环境变量后需要重新登陆账户或者 source ~/.bashrc 后才能生效。\n2. 无 ROOT 权限安装 CUDA Toolkit 和 cuDNN 2.1 安装 CUDA Toolkit 首先确定你需要下载的 CUDA Toolkit 版本，然后在官网下载对应版本的 CUDA，官网链接：CUDA Toolkit Archive 。\n这里以 CUDA Toolkit 12.1.0 为例，根据服务器的架构以及版本进行选择，最后的 Installer Type 选择 runfile(local) 。\n图 1. CUDA 安装包下载页面截图1 在选择完毕之后下方会出现对应的下载命令，我们仅运行 wget 命令（红框中圈出的命令）下载对应文件，由于没有 ROOT 权限，所以无法 sudo 运行该脚本。\n图 2. CUDA 安装包下载页面截图2 同时由于我们没有 ROOT 权限，所以安装的 CUDA Toolkit 不能放置在 /usr/local/ 目录中，我们需要提前创建一个安装 CUDA Toolkit 的目录，在之后执行安装文件时会用到，如：/home/gavin/environment/cuda-12.1。\n之后通过下方的命令给该脚本添加运行权限，然后开始运行安装脚本（可能会卡）：\nchmod +x cuda_*.run sh cuda_*.run 由于我们下载的 CUDA 安装包内同时包含 CUDA Driver 和 CUDA Toolkit，所以这里会有这个提示，我们不安装驱动，没有影响，选择 Continue。\n图 3. CUDA 安装页面截图1 输入 accept 同意用户协议（也没法不同意）\n图 4. CUDA 安装页面截图2 使用回车将除 CUDA Toolkit 12.1 以外的全部取消勾选，之后不要选 Install ，选择 Options 。\n图 5. CUDA 安装页面截图3 选择 Toolkit Options 进行设置。\n图 6. CUDA 安装页面截图4 取消选择所有选项，并且更改安装路径（选择 Change Toolkit Install Path ）。\n图 7. CUDA 安装页面截图5 将前方提前创建好的目录填写进去（建议复制粘贴，不会出错，pwd 可以获得当前位置的绝对路径），之后回车确认，\n图 8. CUDA 安装页面截图6 然后一路选择 Done 回退到如图5的界面选择 Install ，运行结束后会有如下信息。\n图 9. CUDA 安装页面截图7 2.2 启用刚刚安装的 CUDA Toolkit 配置环境变量，如同 1.1 章节的操作。\n将下方命令添加到 ~/.bashrc 文件中，CUDA_HOME 环境变量就是 CUDA 对应位置（如果有多个版本，可以自行选择启用哪个版本）。\nexport CUDA_HOME=/home/gavin/environment/cuda-12.1 # 选择你安装的路径 export CPATH=$CUDA_HOME/include:$CPATH export PATH=$CUDA_HOME/bin:$PATH export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH export LIBRARY_PATH=$CUDA_HOME/lib64:$LIBRARY_PATH ⚠️注意：配置完环境变量后需要重新登陆账户或者 source ~/.bashrc 后才能生效。\n在终端中运行 nvcc -V 后，输出的信息应该匹配你所安装的 CUDA Toolkit 版本。\n图 10. 环境变量配置完毕后检测 2.3 安装对应版本的 cuDNN 根据你安装的 CUDA Toolkit 版本在 cuDNN Archive 中选择对应的 cuDNN 包。\n图 11. cuDNN Archive 网页截图 这里选择 Linux x86_64 (Tar) 包，不选择 Deb 包，因为我们是无 ROOT 权限自定义安装的路径，而且 cuDNN 的安装非常简单，直接拷贝文件就可以了。\n图 12. cuDNN 下载对应 Tar 包 下载后使用下方命令将压缩包解压：\nxz -d cudnn-*-archive.tar.xz tar -xvf cudnn-*-archive.tar 之后复制对应文件到 CUDA Toolkit 安装目录\ncp cudnn-*-archive/include/cudnn*.h $CUDA_HOME/include cp -P cudnn-*-archive/lib/libcudnn* $CUDA_HOME/lib64 chmod a+r $CUDA_HOME/include/cudnn*.h $CUDA_HOME/lib64/libcudnn* 2.4 ⚠️注意 PyTorch 无法查看 CUDA 和 cuDNN 版本 这个其实显示的是当前 PyTorch 支持的最高 CUDA 版本，并不是当前的 CUDA 版本号。\n图 13. torch.version.cuda 的输出截图 这个其实显示的是 PyTorch 内部捆绑的 cuDNN 版本，而不是本地安装的 cuDNN 版本。输出的 90100 则表示内部捆绑的 cuDNN 版本为 9.1.0 。\n图 13. torch.backends.cudnn.version() 的输出截图 ","permalink":"https://gavinsun0921.github.io/posts/install_cuda_and_cudnn/","summary":"这篇教程为无ROOT权限的Ubuntu服务器用户提供了完整的CUDA Toolkit与cuDNN安装指南。采用静默安装模式将CUDA Toolkit部署到用户目录，通过交互式界面调整安装路径并仅保留必要组件。特别指出PyTorch内置版本与本地安装版本的区别，避免开发者误判环境状态。","title":"无ROOT权限在服务器安装CUDA和CUDNN教程"},{"content":"This is the second post in the Paper Research series. In this series I will continue to update some personal study notes on reading papers. This post will introduce the basic work of variational autoencoder (VAE), including the derivation of formulas and simple code verification.\nAutoencoder Autoencoder is a neural network designed to learn an identity function in an unsupervised way to reconstruct the original input while compressing the data in the process so as to discover a more efficient and compressed representation. The autoencoder was first proposed as a nonlinear generalization of principal components analysis (PCA) in Kramer, (1991). And later promoted by the seminal paper by Hinton \u0026amp; Salakhutdinov, (2006).\nIt consists of two networks:\nEncoder network $g_\\phi$: It translates the original high-dimension input into the latent low-dimensional code. The input size is larger than the output size. Decoder network $f_\\theta$: The decoder network recovers the high-dimension data from the latent low-dimensional code. The input size is smaller than the output size. Fig. 1. Illustration of autoencoder model architecture. (Image source: Weng, 2018) The encoder network essentially accomplishes the dimensionality reduction, just like how we would use Principal Component Analysis (PCA) or Matrix Factorization (MF) for. In addition, the autoencoder is explicitly optimized for the data reconstruction from the code. A good intermediate representation not only can capture latent variables, but also benefits a full decompression process.\nThe model contains an encoder function $g_\\phi(\\cdot)$ parameterized by $\\phi$ and a decoder function $f_\\theta(\\cdot)$ parameterized by $\\theta$. The latent low-dimensional code learned for input $\\mathbf{x}$ in the bottleneck layer is $\\mathbf{z} = g_\\phi(\\mathbf{x})$ and reconstructed input is $\\mathbf{x}' = f_\\theta(\\mathbf{z}) = f_\\theta(g_\\phi(\\mathbf{x}))$. The parameters $(\\phi, \\theta)$ are learned together to output a reconstructed data sample same as the original input $\\mathbf{x} \\approx f_\\theta(g_\\phi(\\mathbf{x}))$.\nVAE The idea of Variational Autoencoder (Kingma \u0026amp; Welling, 2014), short for VAE, is actually less similar to the autoencoder model above, but deeply rooted in the methods of variational bayesian and graphical model.\nFig. 2. The type of directed graphical model under consideration. (Image source: Kingma \u0026 Welling, 2014) Instead of mapping the input into a fixed vector, we want to map it into a distribution. In Fig. 2, solid lines denote the generative model $p_\\theta(\\mathbf{x} \\mid \\mathbf{z})$ with the analytically tractable prior distribution $p_\\theta(\\mathbf{z})$， dashed lines denote the variational approximation $q_\\phi(\\mathbf{z} \\mid \\mathbf{x})$ to the intractable posterior distribution $p_\\text{data}(\\mathbf{z} \\mid \\mathbf{x})$. The variational parameters $\\phi$ are learned jointly with the generative model parameters $\\theta$.\nProblem Scenario Suppose our dataset consists of i.i.d. samples $\\{ \\mathbf{x}_i \\in \\mathbb{R}^D \\} _ {i=1} ^N$ from an unknown data distribution $p_\\text{data}(\\mathbf{x})$. We wish to represent the distribution $p_\\text{data}(\\mathbf{x})$ of $\\mathbf{x}$ with the help of the latent variable $\\mathbf{z}$.\n$$ p_\\theta(\\mathbf{x}) = \\int p_\\theta(\\mathbf{x} \\mid \\mathbf{z}) p_\\theta(\\mathbf{z}) \\mathrm{d} \\mathbf{z} \\tag{1} $$\nWe want $p_\\theta(\\mathbf{x})$ to approximate $p_\\text{data}(\\mathbf{x})$, so that (theoretically) we both represent $p_\\text{data}(\\mathbf{x})$ in terms of latent variable $\\mathbf{z}$ and get the generative model $p_\\theta(\\mathbf{x} \\mid \\mathbf{z})$, killing two birds with one stone.\nLoss Function: ELBO Assuming that we know the real parameter $\\theta^*$ for this distribution. In order to generate a sample that looks like a real data point $\\mathbf{x}^{(i)}$, we follow these steps:\nSample a $\\mathbf{z}^{(i)}$ from the prior distribution $p_{\\theta^*}(\\mathbf{z})$. Generate the $\\mathbf{x}^{(i)}$ from the condition distribution (generative model) $p_{\\theta^*}(\\mathbf{x} \\mid \\mathbf{z} = \\mathbf{z}^{(i)})$. The optimal parameter $\\theta^{*}$ is the one that maximizes the probability of generating real data samples:\n$$ \\theta^* = \\argmax_\\theta \\prod_{i=1}^n p_\\theta(\\mathbf{x}^{(i)}) \\tag{2} $$\nCommonly we use the log probability to convert the product on RHS to a sum:\n$$ \\theta^* = \\argmax_\\theta \\sum_{i=1}^n \\log p_\\theta(\\mathbf{x}^{(i)}) \\tag{3} $$\nUnfortunately, the integral of $p_\\theta(\\mathbf{x})$ in Eq. (1) is not well calculated. Kingma \u0026amp; Welling, (2014) chose to use $q_\\phi(\\mathbf{z} \\mid \\mathbf{x})$ to approximate $p_\\text{data}(\\mathbf{z} \\mid \\mathbf{x})$. They focused primarily on describing the posterior $p_\\text{data}(\\mathbf{z} \\mid \\mathbf{x})$, which is difficult to compute so the EM algorithm could not be applied to this problem. But Su. (2018) gives another idea for approaching: a straightforward joint distribution. First we write out the joint probability distribution of the prior distribution $p_\\theta(\\mathbf{z})$ and the conditional distribution (generative model) $p_\\theta(\\mathbf{x} \\mid \\mathbf{z})$:\n$$ p_\\theta(\\mathbf{x}, \\mathbf{z}) = p_\\theta(\\mathbf{x} \\mid \\mathbf{z}) p_\\theta(\\mathbf{z}) \\tag{4} $$\nWe define the joint probability distribution $q_\\phi(\\mathbf{x}, \\mathbf{z})$ based on the data distribution $p_\\text{data}(\\mathbf{x})$ and the variational approximation $q_\\phi(\\mathbf{z} \\mid \\mathbf{x})$ of the posterior distribution.\n$$ q_\\phi(\\mathbf{x}, \\mathbf{z}) = p_\\phi(\\mathbf{z} \\mid \\mathbf{x}) p_\\text{data}(\\mathbf{x}) \\tag{5} $$\nWe want these two joint probability distributions to be as close together as possible, so we use KL divergence to measure the distance between these two distributions, and we want their KL divergence to be as small as possible.\n$$ \\begin{align} D_\\text{KL}(q_\\phi(\\mathbf{x},\\mathbf{z}) \\| p_\\theta(\\mathbf{x}, \\mathbf{z})) \u0026amp; = \\int\\int q_\\phi(\\mathbf{x}, \\mathbf{z}) \\ln \\frac{q_\\phi(\\mathbf{x}, \\mathbf{z})}{p_\\theta(\\mathbf{x}, \\mathbf{z})} \\mathrm{d}\\mathbf{z} \\mathrm{d}\\mathbf{x} \\\\ \u0026amp;= \\int\\int p_\\text{data}(\\mathbf{x})q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\ln \\frac{p_\\text{data}(\\mathbf{x})q_\\phi(\\mathbf{z} \\mid \\mathbf{x})}{p_\\theta(\\mathbf{x},\\mathbf{z})} \\mathrm{d} \\mathbf{z} \\mathrm{d} \\mathbf{x} \\\\ \u0026amp;= \\int p_\\text{data}(\\mathbf{x}) \\left [ \\int q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\ln \\frac{p_\\text{data}(\\mathbf{x})q_\\phi(\\mathbf{z} \\mid \\mathbf{x})}{p_\\theta(\\mathbf{x},\\mathbf{z})} \\mathrm{d}\\mathbf{z} \\right ] \\mathrm{d} \\mathbf{x} \\\\ \u0026amp;= \\mathbb{E}_{\\mathbf{x} \\sim p_\\text{data}(\\mathbf{x})} \\left [ \\int q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\ln \\frac{p_\\text{data}(\\mathbf{x})q_\\phi(\\mathbf{z} \\mid \\mathbf{x})}{p_\\theta(\\mathbf{x},\\mathbf{z})} \\mathrm{d}\\mathbf{z} \\right ] \\\\ \u0026amp;= \\mathbb{E}_{\\mathbf{x} \\sim p_\\text{data}(\\mathbf{x})} \\left [ \\int q_\\phi(\\mathbf{z}) \\ln p_\\text{data}(\\mathbf{x}) \\mathrm{d} \\mathbf{z} + \\int q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\ln \\frac{q_\\phi(\\mathbf{z} \\mid \\mathbf{x})}{p_\\theta(\\mathbf{x},\\mathbf{z})} \\mathrm{d}\\mathbf{z} \\right ] \\\\ \u0026amp;= \\mathbb{E}_{\\mathbf{x} \\sim p_\\text{data}(\\mathbf{x})} \\left [ \\ln p_\\text{data}(\\mathbf{x}) {\\color{blue} \\int q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\mathrm{d} \\mathbf{z}} \\right ] + \\mathbb{E}_{\\mathbf{x} \\sim p_\\text{data}(\\mathbf{x})} \\left [ \\int q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\ln \\frac{q_\\phi(\\mathbf{z} \\mid \\mathbf{x})}{p_\\theta(\\mathbf{x},\\mathbf{z})} \\mathrm{d} \\mathbf{z} \\right ] \\\\ \u0026amp;= {\\color{red} \\mathbb{E}_{\\mathbf{x} \\sim p_\\text{data}(\\mathbf{x})} \\left [ \\ln p_\\text{data}(\\mathbf{x}) \\right ]} + \\mathbb{E}_{\\mathbf{x} \\sim p_\\text{data}(\\mathbf{x})} \\left [ \\int q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\ln \\frac{q_\\phi(\\mathbf{z} \\mid \\mathbf{x})}{p_\\theta(\\mathbf{x},\\mathbf{z})} \\mathrm{d} \\mathbf{z} \\right ] \\end{align} \\tag{6} $$ where the integral of the blue part is equal to 1.\n$p_\\text{data}(\\mathbf{x})$ is the prior over $\\mathbf{x}$ determined from the samples $\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_n$. Although we cannot write its expression explicitly, it does exist. So for any particular dataset, the red part in Eq. (6) is a constant.\nSo the loss function can be written as:\n$$ \\mathcal{L} = D_\\text{KL}(q_\\phi(\\mathbf{x},\\mathbf{z}) \\| p_\\theta(\\mathbf{x}, \\mathbf{z})) - {\\color{red} C_\\text{data}} = \\mathbb{E}_{\\mathbf{x} \\sim p_\\text{data}(\\mathbf{x})} \\left [ \\int q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\ln \\frac{q_\\phi(\\mathbf{z} \\mid \\mathbf{x})}{\\color{blue} p_\\theta(\\mathbf{x},\\mathbf{z})} \\mathrm{d} \\mathbf{z} \\right ] \\tag{7} $$\nBecause of the nonnegativity of the KL divergence, our loss function possesses a lower bound $-\\mathbb{E}_{\\mathbf{x} \\sim p_\\text{data}(\\mathbf{x})} \\left [ \\ln p_\\text{data}(\\mathbf{x}) \\right ]$.\nTo obtain the generative model $p_\\theta(\\mathbf{x} \\mid \\mathbf{z})$, we write $p_\\theta(\\mathbf{x} \\mid \\mathbf{z}) p_\\theta(\\mathbf{z})$ for the joint probability distribution $p_\\theta(\\mathbf{x},\\mathbf{z})$ of the blue part in Eq. (7):\n$$ \\begin{align} \\mathcal{L} \u0026amp;= \\mathbb{E}_{\\mathbf{x} \\sim p_\\text{data}(\\mathbf{x})} \\left [ \\int q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\ln \\frac{q_\\phi(\\mathbf{z} \\mid \\mathbf{x})}{p_\\theta(\\mathbf{x} \\mid \\mathbf{z}) p_\\theta(\\mathbf{z})} \\mathrm{d} \\mathbf{z} \\right ] \\\\ \u0026amp;= \\mathbb{E}_{\\mathbf{x} \\sim p_\\text{data}(\\mathbf{x})} \\left [ \\int q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\left ( \\ln \\frac{q_\\phi(\\mathbf{z} \\mid \\mathbf{x})}{p_\\theta(\\mathbf{z})} - \\ln p_\\theta(\\mathbf{x} \\mid \\mathbf{z}) \\right ) \\mathrm{d} \\mathbf{z} \\right ] \\\\ \u0026amp;= \\mathbb{E}_{\\mathbf{x} \\sim p_\\text{data}(\\mathbf{x})} \\left [ \\int q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\ln \\frac{q_\\phi(\\mathbf{z} \\mid \\mathbf{x})}{p_\\theta(\\mathbf{z})} \\mathrm{d} \\mathbf{z} - \\int q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\ln p_\\theta(\\mathbf{x} \\mid \\mathbf{z}) \\mathrm{d} \\mathbf{z} \\right ] \\\\ \u0026amp;= \\mathbb{E}_{\\mathbf{x} \\sim p_\\text{data}(\\mathbf{x})} \\left [ D_\\text{KL}(q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\| p_\\theta(\\mathbf{z})) - \\mathbb{E}_{\\mathbf{z} \\sim q_\\phi(\\mathbf{z} \\mid \\mathbf{x})} [\\ln p_\\theta(\\mathbf{x} \\mid \\mathbf{z})] \\right ] \\end{align} \\tag{8} $$\nThe center bracket of Eq. (8) is the loss function of the VAE. Note that although the loss function in Eq. (8) are composed of two parts, the cannot be viewed as optimization problems in which the two parts are minimized separately.\nWhen $D_\\text{KL}(q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\| p_\\theta(\\mathbf{z}))$ is 0, it shows that there is no difference between the two distributions $q_\\phi(\\mathbf{z} \\mid \\mathbf{x})$ and $p_\\theta(\\mathbf{z})$, i.e., $\\mathbf{x}$ and $\\mathbf{z}$ they two are both independent of each other, then the process of predicting $\\mathbf{x}$ using $\\mathbf{z}$ at this point must be inaccurate, i.e., $-\\mathbb{E}_{\\mathbf{z} \\sim q_\\phi(\\mathbf{z} \\mid \\mathbf{x})} [\\ln p_\\theta(\\mathbf{x} \\mid \\mathbf{z})]$ cannot be small. When $-\\mathbb{E}_{\\mathbf{z} \\sim q_\\phi(\\mathbf{z} \\mid \\mathbf{x})} [\\ln p_\\theta(\\mathbf{x} \\mid \\mathbf{z})]$ is small, it implies that $\\mathbb{E}_{\\mathbf{z} \\sim q_\\phi(\\mathbf{z} \\mid \\mathbf{x})} \\left [ p_\\theta(\\mathbf{x} \\mid \\mathbf{z}) \\right ]$ is large, i.e., predicting $\\mathbf{x}$ using $\\mathbf{z}$ is very accurate, and the relationship between $\\mathbf{x}$ and $\\mathbf{z}$ will be very strong at this time, i.e., $q_\\phi(\\mathbf{z} \\mid \\mathbf{x})$ will not be too random, so $D_\\text{KL}(q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\| p_\\theta(\\mathbf{z}))$ will not be small. So these two parts of the loss are actually antagonistic to each other, and the loss function cannot be viewed separately, but as a whole. In fact, this is exactly what GANs dream of: having a total metric that can indicate the training process of the generative model. This capability is naturally available in VAE models, and GANs can\u0026rsquo;t do it until WGAN.\nBuild the Network So far, there are three distributions in the loss function in Eq. (8) that we don\u0026rsquo;t know: $q_\\phi(\\mathbf{z} \\mid \\mathbf{x})$, $p_\\theta(\\mathbf{x} \\mid \\mathbf{z})$, and $p_\\theta(\\mathbf{z})$. As for $p_\\text{data}(\\mathbf{x})$, while we can\u0026rsquo;t write its expression explicitly, sampling from it is easy to do (samples from the dataset). In order to solve the problem practically, we need to identify the three unknown distributions mentioned above or determine their form.\nFig. 3. Illustration of variational autoencoder model with the multivariate Gaussian assumption.\n(Image source: Weng, 2018) 1) latent variable distribution\nTo facilitate the generative model in sampling the latent variable $\\mathbf{z}$ when generating samples, we assume that $\\mathbf{z} \\sim p_\\theta(\\mathbf{z}) = \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$.\n2) posterior distribution approximation\nWe assume that $q_\\phi(\\mathbf{z} \\mid \\mathbf{x})$ is also multivariate normally distributed (with independent components), with its mean and variance determined by $\\mathbf{x}$. The \u0026ldquo;determination\u0026rdquo; process is in fact a neural network with parameter $\\phi$. $$ \\begin{align} q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) = \\frac{1}{\\prod\\limits_{i=1}\\limits^n \\sqrt{2\\pi[\\pmb{\\sigma}_\\phi(\\mathbf{x}_i)]^2}} \\exp ( - \\frac{1}{2} \\| \\frac{\\mathbf{z} - \\pmb{\\mu}_\\phi(\\mathbf{x}_i)}{\\pmb{\\sigma}_\\phi(\\mathbf{x}_i)} \\|^2) \\end{align} \\tag{9} $$\nTherefore, the KL divergence part of the loss function in Eq. (8) can be pre-written as a concrete expression by referring to Appendix B in Kingma \u0026amp; Welling, (2014):\n$$ \\begin{align} D_\\text{KL}(q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\| p_\\theta(\\mathbf{x})) \u0026amp;= \\int q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\ln \\frac{q_\\phi(\\mathbf{z} \\mid \\mathbf{x})}{p_\\theta(\\mathbf{z})} \\mathrm{d} \\mathbf{z} \\\\ \u0026amp;= \\int q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) (\\ln q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) - \\ln p_\\theta(\\mathbf{z})) \\mathrm{d} \\mathbf{z} \\\\ \u0026amp;= {\\color{blue} \\int q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\ln q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\mathrm{d} \\mathbf{z}} - {\\color{red} \\int q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\ln p_\\theta(\\mathbf{z})) \\mathrm{d} \\mathbf{z}} \\end{align} \\tag{10} $$\nLet $\\mathcal{J}$ be the dimensionality of $\\mathbf{z}$, and let $\\mu_j$ and $\\sigma_j$ denote the $j\\text{-th}$ element of $\\pmb{\\mu}_\\phi(\\mathbf{x})$ and $\\pmb{\\sigma}_\\phi(\\mathbf{x})$. The blue part of Eq. (10): $$ \\begin{align} {\\color{blue} \\int q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\ln q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\mathrm{d} \\mathbf{z}} \u0026amp;= \\int \\mathcal{N}(\\mathbf{z}; \\pmb{\\mu}_\\phi(\\mathbf{x}), \\pmb{\\sigma}_\\phi^2(\\mathbf{x})) \\ln \\mathcal{N}(\\mathbf{z}; \\pmb{\\mu}_\\phi(\\mathbf{x}), \\pmb{\\sigma}_\\phi^2(\\mathbf{x})) \\mathrm{d} \\mathbf{z} \\\\ \u0026amp;= - \\frac{\\mathcal{J}}{2} \\ln(2\\pi) - \\frac{1}{2} \\sum_{j=1}^{\\mathcal{J}} (\\mu_j^2 + \\sigma_j^2) \\end{align} \\tag{11} $$\nThe red part of Eq. (10): $$ \\begin{align} {\\color{red} \\int q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\ln p_\\theta(\\mathbf{z})) \\mathrm{d} \\mathbf{z}} \u0026amp;= \\int \\mathcal{N}(\\mathbf{z}; \\pmb{\\mu}_\\phi(\\mathbf{x}), \\pmb{\\sigma}_\\phi^2(\\mathbf{x})) \\ln \\mathcal{N}(\\mathbf{z}; \\mathbf{0}, \\mathbf{I}) \\mathrm{d} \\mathbf{z} \\\\ \u0026amp;= \\frac{1}{2} \\sum_{j=1}^{\\mathcal{J}} (1 + \\ln \\sigma_j^2) \\end{align} \\tag{12} $$\nThus, Eq. (10) can be written as\n$$ D_\\text{KL}(q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\| p_\\theta(\\mathbf{x})) = \\frac{1}{2} \\sum_{j=1}^{\\mathcal{J}} (\\mu_j^2 + \\sigma_j^2 - \\ln \\sigma_j^2 - 1) \\tag{13} $$\n3) generative model approximation\nFor the distributional assumptions of generative model $p_\\theta(\\mathbf{x} \\mid \\mathbf{z})$, Kingma \u0026amp; Welling, (2014) gives two options: Bernoulli distribution or Normal distribution.\n3.1) Bernoulli distribution\nThe Bernoulli distribution is the discrete probability distribution of a random variable which takes the value 1 with probability $\\rho$ and the value 0 with probability $1−\\rho$. The probability mass function $\\operatorname{f}$ of this distribution, over possible outcomes $\\xi$, is\n$$ \\begin{cases} \\rho \u0026amp;,\\text{if } \\xi = 1 \\\\ 1 - \\rho \u0026amp;,\\text{if } \\xi = 0 \\tag{14} \\end{cases} $$\nSo when the generating model $p_\\theta(\\mathbf{x} \\mid \\mathbf{z})$ is a Bernoulli distribution, it is only appropriate for the case where $\\mathbf{x}$ is a multivariate binary vector, since the binary distribution can only produce 0s and 1s. The mnist dataset we\u0026rsquo;ll be working on later for a simple code demonstration can be viewed as this case. In this case, we use the neural network $\\rho(z)$ to count the parameters $\\rho$ and thus obtain\n$$ p_\\theta(\\mathbf{x} \\mid \\mathbf{z}) = \\prod_{k=1}^D \\left ( \\rho_{(k)}(\\mathbf{z}) \\right )^{\\mathbf{x}_{(k)}} \\left ( 1 - \\rho_{(k)}(\\mathbf{z}) \\right )^{1 - \\mathbf{x}_{(k)}} \\tag{15} $$\nwhere $D$ is the dimensionality of $\\mathbf{x}$. Thus, from the preceding equation, we deduce that\n$$ -\\ln p_\\theta(\\mathbf{x} \\mid \\mathbf{z}) = \\sum_{k=1}^D \\left [ -\\mathbf{x}_{(k)} \\ln \\rho_{(k)}(\\mathbf{z}) - (1 - \\mathbf{x}_{(k)}) \\ln \\left (1 - \\rho_{(k)}(\\mathbf{z}) \\right ) \\right] \\tag{16} $$\nThis suggests that $\\rho(\\mathbf{z})$ has to be compressed to between 0 and 1 (e.g., with sigmoid activation), and then cross entropy is used as the loss function, where $\\rho(\\mathbf{z})$ then plays a role similar to that of a decoder.\n3.2) Normal distribution / Gaussian distribution\nIn statistics, a normal distribution or Gaussian distribution is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function is\n$$ \\operatorname{f}(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp \\left \\{ -\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2 \\right \\} \\tag{17} $$\nWhen the generated model $p_\\theta(\\mathbf{x} \\mid \\mathbf{z})$ is normally distributed, it is suitable for general data. In this case, we use the neural networks $\\tilde{\\mu}(\\mathbf{z})$ and $\\tilde{\\sigma}(\\mathbf{z})$ to compute the mean and variance , which yields $$ p_\\theta(\\mathbf{x} \\mid \\mathbf{z}) = \\frac{1}{\\prod\\limits_{k=1}^D \\sqrt{2 \\pi \\tilde{\\sigma}_{(k)}^2(\\mathbf{z})}} \\exp \\left ( -\\frac{1}{2} \\left \\| \\frac{\\mathbf{x} - \\tilde{\\mu}(\\mathbf{z})}{\\tilde{\\sigma}(\\mathbf{z})} \\right \\| \\right ) \\tag{18} $$\nThus, from the preceding equation, we deduce that $$ -\\ln p_\\theta(\\mathbf{x} \\mid \\mathbf{z}) = \\frac{1}{2} \\left \\| \\frac{\\mathbf{x} - \\tilde{\\mu}(\\mathbf{z})}{\\tilde{\\sigma}(\\mathbf{z})} \\right \\| + \\frac{D}{2} \\ln 2\\pi + \\frac{1}{2} \\sum_{k=1}^D \\ln \\tilde{\\sigma}_{(k)}^2(\\mathbf{z}) \\tag{19} $$\nFor ease of computation, we usually fix the variance as a constant $\\sigma^*$. Then the above equation can be written as\n$$ -\\ln p_\\theta(\\mathbf{x} \\mid \\mathbf{z}) = \\frac{1}{2 \\sigma^*} \\left \\| \\mathbf{x} - \\tilde{\\mu}(\\mathbf{z}) \\right \\| + C \\tag{20} $$\nSo this part becomes the MSE loss function.\nSampling Calculation After the previous efforts, we were finally able to write the loss function Eq. (8) concretely after making assumptions about each of the three as-yet-undetermined distributions $q_\\phi(\\mathbf{z} \\mid \\mathbf{x})$, $p_\\theta(\\mathbf{x} \\mid \\mathbf{z})$, and $p_\\theta(\\mathbf{z})$. When $q_\\phi(\\mathbf{z} \\mid \\mathbf{x})$ and $p_\\theta(\\mathbf{z})$ are both Gaussian distributions, the KL divergence portion of Equation (8) results in Equation (13). We also write out the corresponding generative modeling part of the loss when $p_\\theta(\\mathbf{x} \\mid \\mathbf{z})$ is either Bernoulli or Gaussian distributed. So we\u0026rsquo;re now just short of sampling from the model.\nThe expectation term in the loss function invokes generating samples from $\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\mid \\mathbf{x})$. Sampling is a stochastic process and therefore we cannot backpropagate the gradient. To make it trainable, the reparameterization trick is introduced: It is often possible to express the random variable $\\mathbf{z}$ as a deterministic variable $\\mathbf{z} = \\mathcal{F}_\\phi(\\mathbf{x}, \\epsilon)$, where $\\epsilon$ is an auxiliary independent random variable, and the transformation function $\\mathcal{F}_\\phi$ parameterized by $\\phi$ converts $\\epsilon$ to $\\mathbf{z}$.\nReparameterization Trick in Lil\u0026rsquo;Log\nSimple Code Implementation You can open it in Colab and run the code for free.\nReferences [1] Diederik P. Kingma \u0026amp; Max Welling. “Auto-Encoding Variational Bayes.” ICLR 2014.\n[2] Mark A. Kramer. “Nonlinear Principal Component Analysis Using Autoassociative Neural Networks.” AIChE Journal 1991.\n[3] Geoffrey E. Hinton \u0026amp; Ruslan R. Salakhutdinov. “Reducing the Dimensionality of Data with Neural Networks.” Science 2006.\n[4] Lilian Weng. “From Autoencoder to Beta-VAE.” [Blog post] Lil\u0026rsquo;Log 2018.\n[5] Jianlin Su. “变分自编码器（二）：从贝叶斯观点出发.” [Blog post] Scientific Spaces 2018.\n","permalink":"https://gavinsun0921.github.io/posts/paper-research-02/","summary":"Learn variational autoencoder (VAE) by reading and analyzing the paper: \u0026ldquo;Auto-Encoding Variational Bayes\u0026rdquo;. This post will introduce the basic work of VAE, including the derivation of formulas and simple code verification.","title":"A Brief Exploration to Variational Autoencoder (VAE) with Code Implementation"},{"content":"Overview This paper introduce a new generative model where samples are produced via Langevin dynamics using gradients of the data distribution estimated with score matching. And it is important to learn Score-Based generative network and Ito diffusion SDE. In this paper, the training and inference phases are analyzed separately and solutions are proposed for different problems. Different levels of noise are used during training to overcome the problem that gradients can be ill-defined and hard to estimate when the data resides on low-dimensional manifolds. For sampling, we propose an annealed Langevin dynamics where we use gradients corresponding to gradually decreasing noise levels as the sampling process gets closer to the data manifold. The models in this paper produce samples comparable to GANs on MNIST, CelebA and CIFAR-10 datasets, achieving a new state-of-the-art inception score of 8.87 on CIFAR-10.\nScore-based Generative Modeling Defination of Score Suppose our dataset consists of i.i.d. samples $\\{ \\mathbf{x}_i \\in \\mathbb{R}^D \\} _ {i=1} ^N$ from an unknown data distribution $p_\\text{data}(\\mathbf{x})$.\nWe define the score of a probability density $p(\\mathbf{x})$ to be $\\nabla_\\mathbf{x}\\log p(\\mathbf{x})$. The score network $\\mathbf{s}_\\mathbf{\\theta}:\\mathbb{R}^D \\to \\mathbb{R}^D$ is a neural network parameterized by $\\mathbf{\\theta}$, which will be trained to approximate the score of $p_\\text{data}(\\mathbf{x})$ The goal of generative modeling is to use the dataset to learn a model for generating new samples from $p_\\text{data}(\\mathbf{x})$. The framework of score-based generative modeling has two ingredients: score matching and Langevin dynamics.\nScore Matching for Score Estimation Score matching (Aapo Hyvärinen, 2005) is originally designed for learning non-normalized statistical models based on i.i.d. samples from an unknown data distribution. Following Song et al. (2019), authors repurpose it for score estimation. Using score matching, authors can directly train a score network $\\mathbf{s}_\\mathbf{\\theta}(\\mathbf{x})$ to estimate $\\nabla_\\mathbf{x}\\log p_\\text{data}(\\mathbf{x})$ without training a model to estimate $p_\\text{data}(\\mathbf{x})$ first. Different from the typical usage of score matching, authors opt not to use the gradient of an energy-based model as the score network to avoid extra computation due to higher-order gradients.\nThe objective minimizes $\\frac{1}{2}\\mathbb{E}_{p_\\text{data}(\\mathbf{x})}\\left[\\left \\| \\mathbf{s}_\\mathbf{\\theta}(\\mathbf{x}) - \\nabla_\\mathbf{x} \\log p_\\text{data}(\\mathbf{x}) \\right \\|^2_2 \\right]$, which can be shown equivalent to the following up to a constant $$ \\frac{1}{2}\\mathbb{E}_{p_\\text{data}(\\mathbf{x})}\\left[ \\text{tr}(\\nabla _\\mathbf{x} \\mathbf{s}_\\mathbf{\\theta}(\\mathbf{x})) + \\frac{1}{2} \\left \\| \\mathbf{s}_\\mathbf{\\theta}(\\mathbf{x}) \\right \\|^2_2 \\right] \\tag{1} $$ where $\\nabla _\\mathbf{x} \\mathbf{s}_\\mathbf{\\theta}(\\mathbf{x})$ denotes the Jacobian of $\\mathbf{s}_\\mathbf{\\theta}(\\mathbf{x})$. However, score matching is not scalable to deep networks and high dimensional data due to the computation of $\\text{tr}(\\nabla _\\mathbf{x} \\mathbf{s}_\\mathbf{\\theta}(\\mathbf{x}))$. Below authors discuss two popular methods for large scale score mathing.\nDenoising Score Mathcing This is the main method used by the authors in the methodology below.\nDenoising score mathcing (Pascal Vincent, 2011) is a variant of score matching that completely circumvents $\\text{tr}(\\nabla _\\mathbf{x} \\mathbf{s}_\\mathbf{\\theta}(\\mathbf{x}))$. It first perturbs the data point $\\mathbf{x}$ with a pre-specified noise distribution $q_\\sigma(\\tilde{\\mathbf{x}} \\mid \\mathbf{x})$ and then employs score matching to estimate the score of the perturbed data distribution $q_\\sigma(\\tilde{\\mathbf{x}}) \\triangleq \\int q_\\sigma (\\tilde{\\mathbf{x}} \\mid \\mathbf{x}) \\mathrm{d}\\mathbf{x}$. The objective was proved equivalent to the following: $$ \\frac{1}{2}\\mathbb{E}_{q_\\sigma(\\tilde{\\mathbf{x}} \\mid \\mathbf{x}) p_\\text{data}(\\mathbf{x}) } \\left [ \\| \\mathbf{s}_\\mathbf{\\theta}(\\tilde{\\mathbf{x}}) - \\nabla_{\\tilde{\\mathbf{x}}} \\log q_\\sigma (\\tilde{\\mathbf{x}} \\mid \\mathbf{x}) \\|^2_2 \\right ] \\tag{2} $$ However, $\\mathbf{s}_\\mathbf{\\theta}^{*} = \\nabla_\\mathbf{x} \\log q_\\sigma(\\mathbf{x}) \\approx \\nabla_\\mathbf{x} \\log p_{\\text{data}}(\\mathbf{x})$ is true only when the noise is small enough such that $q_\\sigma(\\mathbf{x}) \\approx p_\\text{data}(\\mathbf{x})$.\nSliced Score Matching Sliced score matching (Song et al. 2019) uses random projections to approximate $\\text{tr}(\\nabla _\\mathbf{x} \\mathbf{s}_\\mathbf{\\theta}(\\mathbf{x}))$ in score matching. The objective is $$ \\mathbb{E}_{p_\\mathbf{v}}\\mathbb{E}_{p_\\text{data}} \\left [ \\mathbf{v}^\\top \\nabla_\\mathbf{x}\\mathbf{s}_\\mathbf{\\theta}(\\mathbf{x})\\mathbf{v} + \\frac{1}{2} \\| \\mathbf{s}_\\mathbf{\\theta}(\\mathbf{x}) \\|^2_2 \\right ] \\tag{3} $$ where $p_\\mathbf{v}$ is a simple ditribution of random vectors, e.g., the multivariate standard normal. The term $\\mathbf{v}^\\top \\nabla_\\mathbf{x}\\mathbf{s}_\\mathbf{\\theta}(\\mathbf{x})\\mathbf{v}$ can be efficiently computed by forward mode auto-differentiation. Unlike denoising score matching which estimates the scores of perturbed data, sliced score matching provides score estimation for the original unperturbed data distribution, but requires around four times more computations due to the forward mode auto-differentiation.\nSampling with Langevin Dynamics Langevin dynamics can produce samples from a probability density $p(\\mathbf{x})$ using only the score function $\\nabla_\\mathbf{x} \\log p(\\mathbf{x})$. Given a fixed step size $\\epsilon \u0026gt; 0$, and an initial value $\\tilde{\\mathbf{x}}_0 \\sim \\pi(\\mathbf{x})$ with $\\pi$ being a prior distribution (arbitrary), the Langevin method recursively computes the following $$ \\tilde{\\mathbf{x}}_t = \\tilde{\\mathbf{x}}_{t-1} + \\frac{\\epsilon}{2} \\nabla_\\mathbf{x} \\log p(\\tilde{\\mathbf{x}}_{t-1}) + \\sqrt{\\epsilon} \\mathbf{z}_t \\tag{4} $$ where $\\mathbf{z}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$. The distribution of $\\tilde{\\mathbf{x}}_T$ equals $p(\\mathbf{x})$ when $\\epsilon \\to 0$ and $T \\to \\infin$, in which case $\\tilde{x}_T$ becomes an exact sample from $p(\\mathbf{x})$ under some regularity conditions. When $\\epsilon \u0026gt; 0$ and $T \u0026lt; \\infin$, a Metropolis-Hastings update is needed to correct the error of Eq. (4), but it can often be ignored in practice. In this work, authors assume this error is negligible when $\\epsilon$ is small and $T$ is large.\nThe authors give the goals and reasons for network modeling. Sampling from Eq. (4) only requires the score function $\\nabla_\\mathbf{x} \\log p(\\mathbf{x})$. Therefore, in order to obtain samples from $p_\\text{data}(\\mathbf{x})$, authors first train score network such that $\\mathbf{s}_\\theta(\\mathbf{x}) \\approx \\nabla_\\mathbf{x} \\log p_\\text{data}(\\mathbf{x})$ and then approximately obtain samples with Langevin dynamics using $\\mathbf{s}_\\mathbf{\\theta}(\\mathbf{x})$. This is the key idea of our framework of score-based generative modeling.\nChallenges of Low Data Density Regions In regions of low data density, score matching may not have enough evidence to estimate score functions accurately, due to the lack of data samples. When sampling with Langevin dynamics, our initial sample is highly likely in low density regions when data reside in a high dimensional space. Therefore, having an inaccurate score-based model will derail Langevin dynamics from the very beginning of the procedure, preventing it from generating high quality samples that are representative of the data.\nFig. 1. Estimated scores are only accurate in high density regions. (Image source: Yang Song\u0026rsquo; blog, 2021)\nAuthors solution is to perturb data points with noise and train score-based models on the noisy data points instead. When the noise magnitude is sufficiently large, it can populate low data density regions to improve the accuracy of estimated scores. For example, here is what happens when we perturb a mixture of two Gaussians perturbed by additional Gaussian noise.\nFig. 2. Estimated scores are accurate everywhere for the noise-perturbed data distribution due to reduced low data density regions. (Image source: Yang Song\u0026rsquo; blog, 2021)\nYet another question remains: how to choose an appropriate noise scale for the perturbation process? Larger noise can obviously cover more low density regions for better score estimation, but it over-corrupts the data and alters it significantly from the original distribution. Smaller noise, on the other hand, causes less corruption of the original data distribution, but does not cover the low density regions as well as we would like. To achieve the best of both worlds, authors use multiple scales of noise perturbations simultaneously.\nNoise Conditional Score Networks Perturbing the data using various levels of noise; Simultaneously estimating scores corresponding all noise levels by training a single conditional score network. After training, when using Langevin dynamics to generate samples, we initially use scores corresponding to large noise, and gradually anneal down the noise level. Note that conditional in NCSN is for noise and remains unconditional for the image generation task. Define Noise Condtional Score Networks Let $ \\{ \\sigma_i \\} _{i=1}^L $ be a positive geometric sequence that satisfies $\\frac{\\sigma_1}{\\sigma_2} = \\cdots = \\frac{\\sigma_{L-1}}{\\sigma_{L}} \u0026gt; 1$.\nLet $q_\\sigma(\\mathbf{x}) \\triangleq \\int p_\\text{data}(\\mathbf{t}) \\mathcal{N}(\\mathbf{x} \\mid \\mathbf{t}, \\sigma^2 \\mathbf{I}) \\mathrm(d) \\mathbf{t}$ denote the perturbed data distribution.\nAuthors choose the noise levels $\\{ \\sigma_i \\}_{i=1}^L$ such that $\\sigma_1$ is large enough to mitigate the difficulties discussed in Eq. (4), and $\\sigma_L$ is small enough to minimize the effect on data.\nAuthors aim to train a conditional score network to jointly estimate the scores of all perturbed data distributions, i.e., $\\forall \\sigma \\in \\{ \\sigma_i \\}_{i=1}^L : \\mathbf{s}_\\mathbf{\\theta}(\\mathbf{x}, \\sigma) \\approx \\nabla_\\mathbf{x} \\log q_\\sigma(\\mathbf{x})$. Note that $\\mathbf{s}_\\mathbf{\\theta}(\\mathbf{x}, \\sigma) \\in \\mathbb{R}^D$ when $\\mathbf{x} \\in \\mathbb{R}^D$. Authors call $\\mathbf{s}_\\mathbf{\\theta}(\\mathbf{x}, \\sigma)$ a Noise Conditional Score Network (NCSN).\nTraining NCSNs via score matching Both sliced and denoising score matching can train NCSNs. Authors adopt denoising score matching as it is slightly faster and naturally fits the task of estimating scores of noise-perturbed data distributions.\nAuthors choose the noise distribution to be $q_\\sigma(\\tilde{\\mathbf{x}} \\mid \\mathbf{x}) = \\mathcal{N}(\\tilde{\\mathbf{x}} \\mid \\mathbf{x}, \\sigma^2\\mathbf{I})$; therefore $\\nabla_{\\tilde{\\mathbf{x}}} \\log q_\\sigma (\\tilde{\\mathbf{x}} \\mid \\mathbf{x}) = - \\frac{\\tilde{\\mathbf{x}} - \\mathbf{x}}{\\sigma^2}$. For a given $\\sigma$, the denoising score matching objective is $$ \\ell(\\mathbf{\\theta; \\sigma}) \\triangleq \\frac{1}{2} \\mathbb{E}_{p_\\text{data}(\\mathbf{x})} \\mathbb{E}_{\\tilde{\\mathbf{x}} \\sim \\mathcal{N}(\\mathbf{x}, \\sigma^2\\mathbf{I})} \\left [ \\left \\| \\mathbf{s}_\\mathbf{\\theta}(\\tilde{\\mathbf{x}}, \\sigma) + \\frac{\\tilde{\\mathbf{x}} - \\mathbf{x}}{\\sigma^2} \\right \\|^2_2 \\right ] \\tag{5} $$ Then, author combine Eq. (5) for all $\\sigma \\in \\{ \\sigma_i \\}_{i=1}^L$ to get one unified objective $$ \\mathcal{L}(\\mathbf{\\theta}; \\{ \\sigma_i \\}_{i=1}^L) \\triangleq \\frac{1}{L} \\sum_{i=1}^L \\lambda(\\sigma_i) \\ell(\\mathbf{\\theta; \\sigma_i}) \\tag{6} $$ where $\\lambda(\\sigma_i) \u0026gt; 0$ is a coefficient function depending on $\\sigma_i$. Assuming $\\mathbf{s}_\\mathbf{\\theta}(\\mathbf{x}, \\sigma)$ has enough capacity, $\\mathbf{s}_\\mathbf{\\theta}^*(\\mathbf{x}, \\sigma)$ minimizes Eq. (6) iff $\\mathbf{s}_\\mathbf{\\theta}(\\mathbf{x}, \\sigma_i) = \\nabla_\\mathbf{x} \\log q_{\\sigma_i}(\\mathbf{x})$ a.s. for all $i \\in \\{ 1, 2, \\cdots, L \\}$, because Eq. (6) is a conical combination of $L$ denoising score matching objectives.\niff: if and only if a.s.: almost surely There can be many possible choices of $\\lambda(\\cdot)$. Ideally, authors hope that the values of $\\lambda(\\sigma_i)\\ell(\\mathbf{\\theta};\\sigma_i)$ for all $\\{ \\sigma_i \\}_{i=1}^L$ are roughly of the same order of magnitude. Empirically, we observe that when the score networks are trained to optimality, authors approximately have $\\| \\mathbf{s}_\\mathbf{\\theta}(\\mathbf{x}, \\sigma) \\|_2 \\propto \\frac{1}{\\sigma}$. This inspires authors to choose $\\lambda(\\sigma) = \\sigma^2$. Because under this choice, there is $\\lambda(\\sigma)\\ell(\\mathbf{\\theta};\\sigma) = \\sigma^2 \\ell(\\mathbf{\\theta}; \\sigma) = \\frac{1}{2} \\mathbb{E} [ \\| \\sigma \\mathbf{s}_\\mathbf{\\theta}(\\tilde{\\mathbf{x}}, \\sigma) + \\frac{\\tilde{\\mathbf{x}} - \\mathbf{x}}{\\sigma} \\|_2^2 ]$. Since $\\frac{\\tilde{\\mathbf{x}} - \\mathbf{x}}{\\sigma} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$ and $\\| \\sigma \\mathbf{s}_\\mathbf{\\theta}(\\mathbf{x}, \\sigma) \\|_2 \\propto 1$, authors conclude that the order of magnitude of $\\lambda(\\sigma)\\ell(\\mathbf{\\theta};\\sigma)$ does not depend on $\\sigma$.\nWhat specific benefit this has it not stated by the authors in the original article, but I think it should be to standardize the magnitude for different levels of noise, so that a single loss function (Eq. (5)) after perturbation of the data by different levels of noise will have the same weight in the overall loss function (Eq. (6)), i.e., the supervisory weights for matching scores to the data after perturbation of all levels of noise at training time are equal.\nNCSN inference via annealed Langevin dynamics After the NCSN $\\mathbf{s}_\\mathbf{\\theta}(\\mathbf{x}, \\sigma)$ is trained, authors proposed a sampling approach\u0026mdash;annealed Langevin dynamics (Fig. 3).\nFig. 3. Algorithm of annealed Langevin dynamics. (Algorithm source: Song \u0026amp; Ermon, 2019)\nThis algorithm is inspired by simulated annealing and annealed importance sampling. This algorithm start annealed Langevin dynamics by initializing the samples from some fixed prior distribution, e.g., uniform noise. Then run Langevin dynamics to sample from $q_{\\sigma_1}(\\mathbf{x})$ with step size $\\alpha_1$. Next run Langevin dynamics to sample $q_{\\sigma_2}(\\mathbf{x})$, starting from the final samples of the previous simulation and using a reduced step size $\\alpha_2$. Authors continue in this fashion, using the final samples of Langevin dynamics for $q_{\\sigma_{i-1}}(\\mathbf{x})$ as the initial samples of Lnagevin dynamic for $q_{\\sigma_i}(\\mathbf{x})$, and tuning down the step size $\\alpha_i$ gradually with $\\alpha_i = \\epsilon \\cdot \\sigma_i^2 / \\sigma_L^2$. Finnaly, run Langevin dynamics to sample from $q_{\\sigma_L}(\\mathbf{x})$, which is close to $p_\\text{data}(\\mathbf{x})$ when $\\sigma_L \\approx 0$.\nResult and Conclusion The authors conducted quantitative tests with excellent results, but of more interest in this article is the theoretical foundation of the Score-Based Generative Model, and much of the knowledge and assumptions in this article were utilized in Yang Songs subsequent diffusion work.\nAs an unconditional model, we achieve the state-of-the-art inception score of 8.87, which is even better than most reported values for class-conditional generative models.\nTable. 1. Inception and FID scores for CIFAR-10. (Table source: Song \u0026amp; Ermon, 2019)\nReferences [1] Yang Song \u0026amp; Stefano Ermon. \u0026ldquo;Generative Modeling by Estimating Gradients of the Data Distribution.\u0026rdquo; NeurIPS 2019.\n[2] Aapo Hyvärinen. \u0026ldquo;Estimation of Non-Normalized Statistical Models by Score Matching.\u0026rdquo; JMLR 2005.\n[3] Yang Song et al. \u0026ldquo;Sliced Score Matching: A Scalable Approach to Density and Score Estimation.\u0026rdquo; Uncertainty in Artificial Intelligence 2019.\n[4] Pascal Vincent. \u0026ldquo;A Connection Between Score Matching and Denoising Autoencoders.\u0026rdquo; Neural Computation 2011.\n","permalink":"https://gavinsun0921.github.io/posts/fast-paper-reading-03/","summary":"This paper introduce a new generative model where samples are produced via Langevin dynamics using gradients of the data distribution estimated with score matching. And it is important to learn Score-Based generative network and Ito diffusion SDE.","title":"[NeurIPS'19 Oral] Generative Modeling by Estimating Gradients of the Data Distribution"},{"content":" This paper is published in TPAMI 2023. Overview Problem In the field of image super-resolution, existing approaches often suffer from various limitations; e.g., autoregressive models are prohibitively expensive for high-resolution image generation, Normalizing Flows (NFs) and variational autoencoders (VAEs) often yield sub-optimal sample quality, and GANs require carefully designed regularization and optimization tricks to tame optimization instability and model collapse. Solution Present SR3, an approach to image super-resolution via repeated refinement based on DDPM. Results The high-frequency information of the image can be well resored compared to other methods. Despite mediocre performance in SSIM and PSNR metrics, visualization and consistency are good. Related Work Diffusion Probabilistic Models I\u0026rsquo;ve written a blog about diffusion probabilistic models (DPM). It has the derivation of the basic formulas of the DPM as well as a simple code implementation.\nA Breif Exploration to Diffusion Probabilistic Models with Code Implementation. Method Fig. 1. The forward diffusion process $q$ (left to right) gradually adds Gaussian noise to the target image. The reverse inference process $p$ (right to left) iteratively denoises the target image conditioned on a source image x. (Image source: Saharia et al. 2023) SR3 is a model obtained by improving on DDPM. Instead of randomly generating images, low resolution images are used as conditions to generate images. The main changes in SR3 are:\nThe low resolution image is concatenated to the original input (x_t-1) after bicubic interpolation to get a 6-channel tensor as the new input to the DDPM. We experimented with more sophisticated methods of conditioning, such as using FiLM (Perez et al. 2018), but we found that the simple concatenation yielded similar generation quality.\nInstead of sampling $\\bar{\\alpha}_t$ directly using timestep $t$ to compute the correlation variable and loss, a random value is sampled from the distribution $\\bar{\\alpha} \\sim p(\\bar{\\alpha}) = U(\\bar{\\alpha}_{t-1}, \\bar{\\alpha}_{t})$. (Section 2.4 in Saharia et al. 2023) The model receives noise level $\\bar{\\alpha}_t$ directly instead of timestamp $t$. This allows flexibility in adjusting the noise level and the number of sampling steps during inferring. Experrimental Study New metric: Consistency As a measure of the consistentcy of the superresolution outputs, we compute MSE between the downsampled outputs and the low resolution inputs.\nNew metric: Classification Accuracy In the field of low-level vision, metrics often do not comprehensively represent the quality of images. Therefore the effectiveness of low-level models is often evaluated in terms of proxy tasks.\nThis paper mirror the evalution setup of Zhang et al. (2018) and apply 4$\\times$ superresolution models to 56$\\times$56 center crops from the validation set of ImageNet.\nQuantitative Results Compared to PULSE (Menon et al. 2020), FSRGAN (Chen et al. 2018), and Regressive models, the results in terms of PSNR and SSIM are relatively average. This is because traditional super-resolution models are typically trained based on PSNR, which SR3 is not. Therefore, it is normal for the metrics to be relatively low. However, the consistency metrics, on the other hand, perform very well.\nTable 1. PSNR \u0026 SSIM on 16$\\times$16 $\\to$ 128$\\times$128 face superresolution. Consistency measures MSE ($\\times10^{−5}$) between the lowresolution inputs and the down-sampled super-resolution outputs. (Table source: Saharia et al. 2023 as a screenshot) Table 2. Performance comparison between SR3 and Regression baseline on natural image super-resolution using standard metrics computed on the ImageNet validation set. (Table source: Saharia et al. 2023 as a screenshot) Evaluation of Proxy Task Object recognition baseline: ResNet-50 (He et al. 2016). Table 3. Comparison of classification accuracy scores for 4$\\times$ natural image super-resolution on the first 1K images from the ImageNet Validation set. (Table source: Saharia et al. 2023 as a screenshot) Human Evaluation (2AFC) This paper use a 2-alternative forced-choice (2AFC) paradigm to measure how well humans can discriminate true images from those generated from a model.\nFig. 2. Face super-resolution human fool rates (higher is better, photo-realistic samples yield a fool rate of 50%). Outputs of 4 models are compared against ground truth. (top) Subjects are shown low-resolution inputs. (bottom) Inputs are not shown. (Image source: Saharia et al. 2023) Fig. 3. ImageNet super-resolution fool rates (higher is better, photo-realistic samples yield a fool rate of 50%). SR3 and Regression outputs are compared against ground truth. (top) Subjects are shown low-resolution inputs. (bottom) Inputs are not shown. (Image source: Saharia et al. 2023) Visualization Fig. 3. Comparison of different methods on the 16$\\times$16 $\\to$ 128$\\times$128 face super-resolution task. Reference image has not been included because of privacy concerns. (Image source: Saharia et al. 2023) Fig. 4. Results of a SR3 model (64$\\times$64 $\\to$ 512$\\times$512), trained on FFHQ, and applied to images outside of the training set, along with enlarged patches to show finer details. (Image source: Saharia et al. 2023) Fig. 4 shows that the image obtained by SR3 has more details (high-frequency information of the image) compared to the regression model.\nSummary SR3 employs a completely novel approach to super-resolution, distinct from previous approaches based on GANs and CNNs. It primarily generates high-resolution images by denoising progressively from low resolution images conditioned on diffusion models. In the experimental section, the PSNR and SSIM metrics show relatively less impressive performance compared to other methods. However, it outperforms the Regression model in terms of FID and IS metrics, which would be more convincing if PULSE and FSRGAN also be evaluated. Personally, I find the consistency metric not very meaningful. Still, its remarkable performance in proxy task compared to the Regression model is worth attention (through there is still a lack of experimental comparisons with PULSE and FSRGAN). The approach of using diffusion models for image super-resolution is effective, and there is potential for further research in the future.\nReference [1] Chitwan Saharia et al. \u0026ldquo;Image Super-Resolution via Iterative Refinement.\u0026rdquo; TPAMI 2023.\n[2] Ethan Perez et al. \u0026ldquo;FiLM: Visual Reasoning with a General Conditioning Layer.\u0026rdquo; AAAI 2018.\n[3] Yulun Zhang et al. \u0026ldquo;Image Super-Resolution Using Very Deep Residual Channel Attention Networks.\u0026rdquo; ECCV 2018.\n[4] Sachit Menon et al. \u0026ldquo;PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models.\u0026rdquo; CVPR 2020.\n[5] Yu Chen et al. \u0026ldquo;FSRNet: End-to-End Learning Face Super-Resolution With Facial Priors.\u0026rdquo; CVPR 2018.\n[6] Kaiming He et al. \u0026ldquo;Deep residual learning for image recognition.\u0026rdquo; CVPR 2016.\n","permalink":"https://gavinsun0921.github.io/posts/fast-paper-reading-02/","summary":"Image super-resolution with conditional diffusion model.","title":"[T-PAMI'23] Image Super-Resolution via Iterative Refinement"},{"content":" This paper is published in CVPR 2022. Overview Problem Image deblurring is an ill-posed problem, and most existing mothods are ineffective because they produce a deterministic estimate of the clean image. Point-estimators that directly minimize a distortion loss suffers from the problem of \u0026ldquo;regression to the mean\u0026rdquo;. Solution Present a new framework for blind deblurring based on conditional diffusion models. Porducing a diverse set of plausible reconstructions for a given input. Results A significant improvement in perceptual qulity over existing state-of-the-art methods across multiple standard benchmarks. Much more efficient sampling compared to typical diffusion models. Challenging the widely used strategy of producing a single, deterministic reconstruction. Related Work Diffusion Probabilistic Models I\u0026rsquo;ve written a blog about diffusion probabilistic models (DPM). It has the derivation of the basic formulas of the DPM as well as a simple code implementation.\nA Breif Exploration to Diffusion Probabilistic Models with Code Implementation. The Perception-Distortion Tradeoff Fig. 1. The perception-distortion tradeoff. (Image source: Blau et al. 2018 with a few additional annotations) The ability of a model on a curve is the same. When perceptual metrics get better (smaller y-axis), distortion metrics get worse (bigger x-axis), and vice versa. Usually non-GAN models will tend to be more towards the upper left corner, while GAN models will tend to be more towards the lower right corner.\nMethod This paper introduce a \u0026ldquo;predict-and-refine\u0026rdquo; conditional diffusion model, where a deterministic data-adaptive predictor is jointly trained with a stochastic sampler that refines the output of the said predictor (see Fig. 2).\nFig. 2. Diagram of dual-network architechture. (Image source: Jay et al. 2022) The method in this paper is to use an initial predictor $g_\\theta$ to process the blurry image to get the initial prediction, and then models the residual of ground truth and initial prediction using a conditional diffusion model. Fig. 3. Diagram of U-Net architechture used for both the denoiser network and the initial predictor. Note that the input and output depicted here are for the denoiser network. (Image source: Jay et al. 2022) The loss function of predict-and-refine diffusion model in paper is Eq. (6). $$ L_{\\text{Ours}}(\\theta) = \\mathbb{E} \\left \\| \\mathbf{\\epsilon} - f_\\theta \\left ( \\sqrt{\\bar{\\alpha}} (\\underbrace{ \\mathbf{x}_0 - g_\\theta({\\color{red} \\mathbf{x}_0})}_{\\text{residual}}) + \\sqrt{1 - \\bar{\\alpha}} \\epsilon, \\bar{\\alpha}, \\mathbf{y} \\right ) \\right \\| \\tag{6} $$ Gaution! The red part of Eq. (6) is wrong. Here, $\\mathbf{x}_0$ and $g_\\theta$ stands for ground truth and initial predictor. The residual portion in the lower brackets should be the residual of ground truth and initial prediction. Therefore, the input to $g_\\theta$ should be the blurry image $\\mathbf{y}$.\nExperimental Study Quantitative Results The \u0026ldquo;SA\u0026rdquo; suffix in the table stands for Sample Averaging, i.e. averaging over multiple samples. This operation can significantly improve the distortion metrics at the expense of the perception metrics.\nTable 1. Image deblurring results on the GoPro dataset (Nah et al. 2017). Best values and second-best values for each metric are color-coded. (Table source: Jay et al. 2022 as a screenshot) Table 2. Image deblurring results on the HIDE dataset (Shen et al. 2019). Best values and second-best values for each metric are color-coded. (Table source: Jay et al. 2022 as a screenshot) The model in this paper achieves state-of-the-art performance across all perceptual metrics while maintaining competitive PSNR and SSIM to existing methods.\nP-D tradeoff Inference steps (T): 10, 20, 30, 50, 100, 200, 300, 500. Fig. 4. Additional Perception-Distortion plots with respect to different metrics. Left column contains perceptual metrics vs. PSNR, and the right column contains SSIM comparisons.(Image source: Jay et al. 2022) Traversing the Perception-Distortion curve: The more steps sampled, the better the subjective quality, and vice versa for the objective quality.\nNetwork Architecture Ablation Study Table 3. Ablation study on the effects of various hyperparameters. (Table source: Jay et al. 2022 as a screenshot) As the results show, all three hyperparameters were critical to the model\u0026rsquo;s performance.\nSummary The diffusion model is successfully applied to the deblurring task, enhancing the stochastic process of generating clear images. Good results were achieved in the quality of reconstruction observed by the human, and the metrics, such as PSNR, are comparable. The biggest highlight is that the idea of residual is proposed in the model, which makes the inference faster, and together with the initial inference achieved good results.\nReferences [1] Whang Jay et al. \u0026ldquo;Deblurring via Stochastic Refinement.\u0026rdquo; CVPR 2022.\n[2] Yochai Blau \u0026amp; Tomer Michaeli. \u0026ldquo;The Perception-Distortion Tradeoff.\u0026rdquo; CVPR 2018.\n[3] Seungjun Nah et al. \u0026ldquo;Deep Multi-Scale Convolutional Neural Network for Dynamic Scene Deblurring.\u0026rdquo; CVPR 2017.\n[4] Ziyi Shen et al. \u0026ldquo;Human-Aware Motion Deblurring.\u0026rdquo; ICCV 2019.\n","permalink":"https://gavinsun0921.github.io/posts/fast-paper-reading-01/","summary":"Image deblurring with \u0026ldquo;predict-and-refine\u0026rdquo; conditional diffusion model. An brand new strategy for ill-posed problem.","title":"[CVPR'22] Deblurring via Stochastic Refinement"},{"content":"This is the first post in the Paper Research series. In this series I will continue to update some personal study notes on reading papers. This post will introduce the basic work of diffusion probabilistic models (DPM), including the derivation of formulas and simple code verification. The content is mainly from Sohl-Dickstein et al. (2015) and Ho et al. (2020). If you have any suggestions on this post or would like to communicate with me, please leave comments below.\nDiffusion Models What are Diffusion Models? Refer to Weng, (2021):\nDiffusion models are inspired by non-equilibrium thermodynamics. They define a Markov chain of diffusion steps to slowly add random noise to data and then learn to reverse the diffusion process to construct desired data samples from the noise.\nFig. 1. Framework Diagram of Diffusion Models.\nMy personal understanding of Diffusion Models is a framework (Fig. 1) where there are no trainable parameters in the forward process and there are training parameters in the reverse process. And there is no restriction on what type of neural network to use in terms of the distribution that needs to be expressed implicitly in the reverse process.\nFig. 2. Flowchart of Diffusion Models. (Image source: Das, 2021)\nForward Process The forward process is a Markov process. According to Wikipedia, a Markov chain or Markov process is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. Informally, this may be thought of as, \u0026ldquo;What happens next depends only on the state of affairs now.\u0026rdquo;\nThe main goal of the forward process is to gradually convert the data distribution $q(\\mathbf{x}_0)$ into an analytically tractable distribution $\\pi(\\mathbf{y})$ by repeated application of a Markov diffusion kernel $T_\\pi(\\mathbf{y}|\\mathbf{y}'; \\beta)$ for $\\pi(\\mathbf{y})$, where $\\beta$ is the diffusion rate,\n$$\\pi(\\mathbf{y}) = \\int T_\\pi(\\mathbf{y}|\\mathbf{y}'; \\beta) \\mathrm{d}\\mathbf{y}' \\tag{1}$$ $$q(\\mathbf{x}_t|\\mathbf{x}_{t-1}) = T_\\pi(\\mathbf{x}_t|\\mathbf{x}_{t-1}; \\beta_t) \\tag{2}$$ The forward trajectory (joint distribution), corresponding to starting at the data distribution and performing T steps of diffusion, is thus\n$$q(\\mathbf{x}_0, \\mathbf{x}_1, \\cdots, \\mathbf{x}_T) = q(\\mathbf{x}_{(0\\cdots T)}) = q(\\mathbf{x}_0)\\prod_{t=1}^T q(\\mathbf{x}_t | \\mathbf{x}_{t-1}) \\tag{3}$$ Fig. 3. Illustration of forward (diffusion) trajectory.\nReverse Process The reverse process also is a Markov process. If we can reverse the above process and sample from $q(\\mathbf{x}_{t-1} | \\mathbf{x}_t)$, we will be able to recreate the true sample from a Gaussian noise input, $\\mathbf{x}_T \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$. Unfortunately, we cannot easily estimate $q(\\mathbf{x}_{t-1} | \\mathbf{x}_t)$ and there fore we need to learn a model $p_\\theta$ to approximate these conditional probabilities in order to run the reverse process. We want $p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t)$ to approximate $q(\\mathbf{x}_{t-1} | \\mathbf{x}_t)$ as closely as possible for all $t$.\nThe generative distribution $p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}\\_t)$ will be trained to describe the same trajectory (also a joint distribution), but in reverse,\n$$p_\\theta (\\mathbf{x}_T) = \\pi(\\mathbf{x}_T) \\tag{4}$$ $$ p_\\theta(\\mathbf{x}_0, \\mathbf{x}_1, \\cdots, \\mathbf{x}_T) = p_\\theta(\\mathbf{x}_{(0\\cdots T)}) = p_\\theta(\\mathbf{x}_T)\\prod_{t=1}^T p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}) \\tag{5}$$ Generative Model The forward trajectory (joint distribution): image to noise. The reverse trajectory (joint distribution): noise to image. The Model Probability (marginal distribution): the probability the generative model assigns to the data. The probability the generative model assigns to the data is $$p_\\theta(\\mathbf{x}_0) = \\int \\int \\cdots \\int p_\\theta(\\mathbf{x}_0, \\mathbf{x}_1, \\cdots, \\mathbf{x}_T) \\mathrm{d}\\mathbf{x}_1 \\mathrm{d}\\mathbf{x}_2 \\cdots \\mathrm{d}\\mathbf{x}_T \\tag{6}$$ For convenience, we simply denote it as: $$p_\\theta(\\mathbf{x}_0) = \\int \\mathrm{d}\\mathbf{x}_{(1\\cdots T)} \\ p_\\theta(\\mathbf{x}_{(0\\cdots T)}) \\tag{7}$$\nBut this integral (7) is intractable! We can handle this integral similarly to some of the ways in VAE. Taking a cue from annealed importance sampling and the Jarzynski equality, we instead evaluate the relative probability of the forward and reverse trajectories, averaged over forward trajectories,\n$$ \\begin{equation*} \\begin{split} a=b \\end{split} \\end{equation*} $$ $$ \\begin{equation*} \\begin{split} p_\\theta(\\mathbf{x}_0) \u0026= \\int \\mathrm{d}\\mathbf{x}_{(1\\cdots T)} \\ p_\\theta(\\mathbf{x}_{(0\\cdots T)}) \\frac{q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0)}{q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0)} \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(1\\cdots T)} \\ q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0) \\frac{\\color{red} p_\\theta(\\mathbf{x}_{(0\\cdots T)})}{\\color{blue} q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0)} \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(1\\cdots T)} \\ q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0) \\frac{\\color{red} p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{\\color{blue} \\frac{q(\\mathbf{x}_0, \\mathbf{x}_{(1\\cdots T)})}{q(\\mathbf{x}_0)}} \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(1\\cdots T)} \\ q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0) \\frac{p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{\\color{blue} \\frac{q(\\mathbf{x}_0) \\prod_{t=1}^T q(\\mathbf{x}_t | \\mathbf{x}_{t-1})}{q(\\mathbf{x}_0)}} \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(1\\cdots T)} \\ q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0) \\frac{p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{\\prod_{t=1}^T q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\\\ \u0026= \\int \\mathrm{d}\\mathbf{x}_{(1\\cdots T)} \\ q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0) p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\end{split} \\end{equation*} \\tag{8} $$ Model Log Likelihood We want the estimated data distribution ($p_\\theta(\\mathbf{x}\\_0)$) to be as close as possible to the actual data distribution ($q(\\mathbf{x}\\_0)$). So training amounts to maximizing the model log likelihood, $$ \\begin{equation*} \\begin{split} \\mathcal{L} \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_0 \\ q(\\mathbf{x}_0) \\log p_\\theta (\\mathbf{x}_0) \\\\ \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_0 \\ q(\\mathbf{x}_0) { \\log \\left [ \\int \\mathrm{d}\\mathbf{x}_{(1\\cdots T)} q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0) p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ]} \\\\ \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_0 \\ q(\\mathbf{x}_0) {\\color{blue} \\log \\left \\{\\mathbb{E}_{\\mathbf{x}_{(1\\cdots T)} \\sim q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0)} \\left [ p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] \\right \\}} \\\\ \u0026amp;\\geq \\int \\mathrm{d}\\mathbf{x}_0 \\ q(\\mathbf{x}_0) {\\color{blue} \\mathbb{E}_{\\mathbf{x}_{(1\\cdots T)} \\sim q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0)} \\left \\{ \\log \\left [ p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] \\right \\}} \\\\ \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_0 \\ q(\\mathbf{x}_0) \\int \\mathbb{d}\\mathbf{x}_{(1\\cdots T)} \\ q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0) \\log \\left [ p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] \\\\ \u0026amp;= \\int \\mathbb{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_0) q(\\mathbf{x}_{(1\\cdots T)} | \\mathbf{x}_0) \\log \\left [ p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] \\\\ \u0026amp;= \\int \\mathbb{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\log \\left [ p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] \\\\ \\end{split} \\end{equation*} \\tag{9} $$\nThe blue part in Eq. (9) provided by Jensen\u0026rsquo;s inequality as Fig. 5.\nFig. 4. Visualization of Jensen's inequality in logarithmic function. So we have the lower bound of $\\mathcal{L}$, let\u0026rsquo;s write it down as $$\\mathcal{K} = \\int \\mathbb{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\log \\left [ p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] \\tag{10}$$\n1) Peel off $p_\\theta(\\mathbf{x}_T)$ in $\\mathcal{K}$ as an entropy\nWe can peel off the contribution from $p_\\theta(\\mathbf{x}_T)$, and rewrite it as an entropy, $$ \\begin{equation*} \\begin{split} \\mathcal{K} \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) {\\color{blue} \\log \\left [ p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^T \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ]} \\\\ \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) {\\color{blue} \\left \\{ \\log p_\\theta(\\mathbf{x}_T) + \\sum_{t=1}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] \\right \\} } \\\\ \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) {\\color{blue} \\sum_{t=1}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ]} + \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) {\\color{blue} \\log p_\\theta(\\mathbf{x}_T)} \\\\ \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) { \\sum_{t=1}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ]} + {\\color{red} \\int \\mathrm{d}\\mathbf{x}_T \\ q(\\mathbf{x}_T) \\log \\underbrace{p_\\theta(\\mathbf{x}_T)}_{{\\normalsize \\pi}(\\mathbf{x}_T)}} \\\\ \\end{split} \\end{equation*} \\tag{11} $$\nBy design, the cross entropy to $\\pi(\\mathbf{x}_T)$ is constant under our diffusion kernels, and equal to the entropy of $p_\\theta(\\mathbf{x}_T)$. Therefore, $$ \\mathcal{K} = \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=1}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] {\\color{red} - \\ \\mathcal{H}_p(\\mathbf{x}_T)} \\tag{12} $$\n2) Remove the edge effect at $t=0$\nIn order to avoid edge effects, we set the final step of the reverse trajectory to be identical to the corresponding forward diffusion step, $$p_\\theta(\\mathbf{x}_0 | \\mathbf{x}_1) = q(\\mathbf{x}_1 | \\mathbf{x}_0) \\frac{\\pi(\\mathbf{x}_{0})}{\\pi(\\mathbf{x}_{1})} = T_\\pi(\\mathbf{x}_0 | \\mathbf{x}_1 ; \\beta) \\tag{13}$$\nWe then use this equivalence to remove the contribution of the first time-step in the sum, $$ \\begin{equation*} \\begin{split} \\mathcal{K} \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) {\\color{blue} \\sum_{t=1}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ]} - \\mathcal{H}_p(\\mathbf{x}_T) \\\\ \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) {\\color{blue} \\sum_{t=2}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ]} + \\underbrace{\\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) {\\color{blue} \\log \\frac{p_\\theta(\\mathbf{x}_0 | \\mathbf{x}_1)}{q(\\mathbf{x}_1 | \\mathbf{x}_0)}}}_{ {\\large \\mathbb{E}}_{\\mathbf{x}_{(0\\cdots T)} \\sim q(\\mathbf{x}_{(0\\cdots T)})} {\\normalsize \\log \\frac{p_\\theta(\\mathbf{x}_0 | \\mathbf{x}_1)}{q(\\mathbf{x}_1 | \\mathbf{x}_0)}}} - \\mathcal{H}_p(\\mathbf{x}_T) \\\\ \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] + \\int \\mathrm{d}\\mathbf{x}_{(0, 1)} \\ q(\\mathbf{x}_0, \\mathbf{x}_1) \\log \\frac{\\color{red} p_\\theta(\\mathbf{x}_0 | \\mathbf{x}_1)}{q(\\mathbf{x}_1 | \\mathbf{x}_0)} - \\mathcal{H}_p(\\mathbf{x}_T) \\\\ \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] + \\int \\mathrm{d}\\mathbf{x}_{(0, 1)} \\ q(\\mathbf{x}_0, \\mathbf{x}_1) \\log \\frac{\\color{red} q(\\mathbf{x}_1 | \\mathbf{x}_0) \\pi(\\mathbf{x}_0)}{q(\\mathbf{x}_1 | \\mathbf{x}_0) {\\color{red} \\pi(\\mathbf{x}_1)}} - \\mathcal{H}_p(\\mathbf{x}_T) \\\\ \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] + {\\color{green} \\int \\mathrm{d}\\mathbf{x}_{(0, 1)} \\ q(\\mathbf{x}_0, \\mathbf{x}_1) \\log \\frac{\\pi(\\mathbf{x}_0)}{\\pi(\\mathbf{x}_1)}} - \\mathcal{H}_p(\\mathbf{x}_T) \\\\ \\end{split} \\end{equation*} \\tag{14} $$\nFor ease of presentation, the green part of Eq. (14) is derived separately, $$ \\begin{equation*} \\begin{split} {\\color{green} \\int \\mathrm{d}\\mathbf{x}_{(0, 1)} \\ q(\\mathbf{x}_0, \\mathbf{x}_1) \\log \\frac{\\pi(\\mathbf{x}_0)}{\\pi(\\mathbf{x}_1)}} \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_{(0, 1)} \\ q(\\mathbf{x}_0, \\mathbf{x}_1) \\left [ \\log \\pi(\\mathbf{x}_0) - \\log \\pi(\\mathbf{x}_1) \\right ] \\\\ \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_{(0, 1)} \\ q(\\mathbf{x}_0, \\mathbf{x}_1) \\log \\pi(\\mathbf{x}_0) - \\int \\mathrm{d}\\mathbf{x}_{(0, 1)} \\ q(\\mathbf{x}_0, \\mathbf{x}_1) \\log \\pi(\\mathbf{x}_1) \\\\ \u0026amp;= {\\color{red} \\int \\mathrm{d}\\mathbf{x}_{0} \\ q(\\mathbf{x}_{0}) \\log \\pi(\\mathbf{x}_0)} - {\\color{red} \\int \\mathrm{d}\\mathbf{x}_{1} \\ q(\\mathbf{x}_{1}) \\log \\pi(\\mathbf{x}_1)} \\\\ \u0026amp;= {\\color{red} \\mathcal{H}_p(\\mathbf{x}_T)} - {\\color{red} \\mathcal{H}_p(\\mathbf{x}_T)} \\\\ \u0026amp;= 0 \\\\ \\end{split} \\end{equation*} \\tag{15} $$\nwhere we again used the fact that by design $\\color{red} -\\int \\mathrm{d}\\mathbf{x}_t \\ q(\\mathbf{x}_t) \\log \\pi(\\mathbf{x}_t) = \\mathcal{H}_p(\\mathbf{x}_T)$ is a constant for all $t$.\nTherefore, the lower bound in Eq. (14) becomes $$\\mathcal{K} = \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right ] - \\mathcal{H}_p(\\mathbf{x}_T) \\tag{16}$$\n3) Rewrite in terms of $q(\\mathbf{x}_{t-1} | \\mathbf{x}_t)$\nBecause the forward trajectory is a Markov process, $$ \\begin{equation*} q(\\mathbf{x}_t | \\mathbf{x}_{t-1}) = \\left \\{ \\begin{matrix} q(\\mathbf{x}_t | \\mathbf{x}_{t-1}, \\mathbf{x}_0) \u0026amp; , t \u0026gt; 1 \\\\ q(\\mathbf{x}_1 | \\mathbf{x}_{0}, \\mathbf{x}_0) = q(\\mathbf{x}_1 | \\mathbf{x}_{0}) \u0026amp; , t = 1 \\end{matrix} \\right . \\end{equation*} \\tag{17} $$\n$$ \\mathcal{K} = \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{\\color{blue} q(\\mathbf{x}_t | \\mathbf{x}_{t-1}, \\mathbf{x}_0)} \\right ] - \\mathcal{H}_p(\\mathbf{x}_T) \\tag{18} $$\nUsing Bayes’ rule we can rewrite this in terms of a posterior and marginals from the forward trajectory, $$ \\mathcal{K} = \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{\\color{blue} q(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}, \\mathbf{x}_0)} \\frac{\\color{blue} q(\\mathbf{x}_{t-1} | \\mathbf{x}_0)}{\\color{blue} q(\\mathbf{x}_{t} | \\mathbf{x}_0)} \\right ] - \\mathcal{H}_p(\\mathbf{x}_T) \\tag{19} $$\n4) Rewrite in terms of KL divergences and entropies\n$$ \\begin{equation*} \\begin{split} \\mathcal{K} \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\left [ \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}, \\mathbf{x}_0)} \\frac{q(\\mathbf{x}_{t-1} | \\mathbf{x}_0)}{q(\\mathbf{x}_{t} | \\mathbf{x}_0)} \\right ] - \\mathcal{H}_p(\\mathbf{x}_T) \\\\ \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\left [ \\log \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}, \\mathbf{x}_0)} + \\log \\frac{q(\\mathbf{x}_{t-1} | \\mathbf{x}_0)}{q(\\mathbf{x}_{t} | \\mathbf{x}_0)} \\right ] - \\mathcal{H}_p(\\mathbf{x}_T) \\\\ \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}, \\mathbf{x}_0)} \\\\ \u0026amp;\\quad + {\\color{green} \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\frac{q(\\mathbf{x}_{t-1} | \\mathbf{x}_0)}{q(\\mathbf{x}_{t} | \\mathbf{x}_0)}} - \\mathcal{H}_p(\\mathbf{x}_T) \\\\ \\end{split} \\end{equation*} \\tag{20} $$\nFor ease of presentation, the green part of Eq. (20) is derived separately, $$ \\begin{equation*} \\begin{split} {\\color{green} \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)}} \u0026amp;\\ {\\color{green} q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\frac{q(\\mathbf{x}_{t-1} | \\mathbf{x}_0)}{q(\\mathbf{x}_{t} | \\mathbf{x}_0)}} \\\\ \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\log {\\color{blue} \\prod_{t=2}^T \\frac{q(\\mathbf{x}_{t-1} | \\mathbf{x}_0)}{q(\\mathbf{x}_{t} | \\mathbf{x}_0)}} \\\\ \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\log {\\color{blue} \\frac{q(\\mathbf{x}_{1} | \\mathbf{x}_0)}{q(\\mathbf{x}_{T} | \\mathbf{x}_0)}} \\\\ \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\left [ \\log q(\\mathbf{x}_{1} | \\mathbf{x}_0) - \\log q(\\mathbf{x}_{T} | \\mathbf{x}_0) \\right ] \\\\ \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\log q(\\mathbf{x}_{1} | \\mathbf{x}_0) - \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\log q(\\mathbf{x}_{T} | \\mathbf{x}_0) \\\\ \u0026amp;= {\\color{red} \\int \\mathrm{d}\\mathbf{x}_{(0,1)} \\ q(\\mathbf{x}_0, \\mathbf{x}_1) \\log q(\\mathbf{x}_{1} | \\mathbf{x}_0)} - {\\color{red} \\int \\mathrm{d}\\mathbf{x}_{(0,T)} \\ q(\\mathbf{x}_0, \\mathbf{x}_T) \\log q(\\mathbf{x}_{T} | \\mathbf{x}_0)} \\\\ \u0026amp;= {\\color{red} \\mathcal{H}_q(\\mathbf{x}_T | \\mathbf{x}_0)} - {\\color{red} \\mathcal{H}_q(\\mathbf{x}_1 | \\mathbf{x}_0)} \\quad ; \\text{(conditional entropy)} \\end{split} \\end{equation*} \\tag{21} $$\nTherefore, the lower bound in Eq. (20) becomes $$ \\mathcal{K} = {\\color{brown} \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}, \\mathbf{x}_0)}} + \\mathcal{H}_q(\\mathbf{x}_T | \\mathbf{x}_0) - \\mathcal{H}_q(\\mathbf{x}_1 | \\mathbf{x}_0) - \\mathcal{H}_p(\\mathbf{x}_T) \\tag{22} $$\nFor ease of presentation, the brown part of Eq. (22) is derived separately, $$ \\begin{equation*} \\begin{split} {\\color{brown} \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)}} \u0026amp; \\ {\\color{brown} q(\\mathbf{x}_{(0\\cdots T)}) \\sum_{t=2}^T \\log \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}, \\mathbf{x}_0)}} \\\\ \u0026amp;= \\sum_{t=2}^T \\int \\mathrm{d}\\mathbf{x}_{(0\\cdots T)} \\ q(\\mathbf{x}_{(0\\cdots T)}) \\log \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}, \\mathbf{x}_0)} \\\\ \u0026amp;= \\sum_{t=2}^T \\int \\mathrm{d}\\mathbf{x}_{0}\\mathrm{d}\\mathbf{x}_{t-1}\\mathrm{d}\\mathbf{x}_{t} \\ {\\color{blue} q(\\mathbf{x}_0, \\mathbf{x}_{t-1}, \\mathbf{x}_t)} \\log \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}, \\mathbf{x}_0)} \\\\ \u0026amp;= \\sum_{t=2}^T \\int \\mathrm{d}\\mathbf{x}_{0}\\mathrm{d}\\mathbf{x}_{t-1}\\mathrm{d}\\mathbf{x}_{t} \\ {\\color{blue} q(\\mathbf{x}_0, \\mathbf{x}_t) q(\\mathbf{x}_{t-1}| \\mathbf{x}_t, \\mathbf{x}_0)} \\log \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}, \\mathbf{x}_0)} \\\\ \u0026amp;= \\sum_{t=2}^T \\int \\mathrm{d}\\mathbf{x}_{0}\\mathrm{d}\\mathbf{x}_{t} \\ q(\\mathbf{x}_0, \\mathbf{x}_t) \\underbrace{\\color{red} \\left \\{ \\int \\mathrm{d}\\mathbf{x}_{t-1} \\ q(\\mathbf{x}_{t-1}| \\mathbf{x}_t, \\mathbf{x}_0) \\log \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}, \\mathbf{x}_0)} \\right \\} }_{ \\begin{array}{c} \\small \\text{KL Divergence (also called relative entropy)} \\\\ {\\color{violet} \\mathcal{D}_{KL}(P \\| Q) = \\int_{-\\infty}^{+\\infty} p(x) \\log \\frac{p(x)}{q(x)} \\mathrm{d}x} \\end{array} } \\\\ \u0026amp;= {\\color{red} -} \\sum_{t=2}^T \\int \\mathrm{d}\\mathbf{x}_{0}\\mathrm{d}\\mathbf{x}_{t} \\ q(\\mathbf{x}_0, \\mathbf{x}_t) {\\color{red} \\mathcal{D}_{KL}(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) \\| p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t))} \\end{split} \\end{equation*} \\tag{23} $$\nTherefore, the lower bound in Eq. (22) becomes $$ \\begin{equation*} \\begin{split} \\mathcal{K} = \u0026amp;- \\sum_{t=2}^T \\int \\mathrm{d}\\mathbf{x}_{0}\\mathrm{d}\\mathbf{x}_{t} \\ q(\\mathbf{x}_0, \\mathbf{x}_t) \\mathcal{D}_{KL}(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) \\| p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t)) \\\\ \u0026amp;+ \\mathcal{H}_q(\\mathbf{x}_T | \\mathbf{x}_0) - \\mathcal{H}_q(\\mathbf{x}_1 | \\mathbf{x}_0) - \\mathcal{H}_p(\\mathbf{x}_T) \\end{split} \\end{equation*} \\tag{24} $$\nNote that the entropies can be analytically computed, and the KL divergence can be analytically computed given $\\mathbf{x}_0$ and $\\mathbf{x}_t$.\nTraining consists of finding the reverse Markov transitions which maximize this lower bound on the log likelihood, $$ p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t) = \\argmax_{\\theta} \\mathcal{K} \\tag{25} $$\nSpecific Diffusion Kernel Forward Process Specify that the Markov diffusion kernel in Eq. (2) is subject to a Gaussian distribution, $$ q(\\mathbf{x}_t | \\mathbf{x}_{t-1}) = T_\\pi(\\mathbf{x}_t | \\mathbf{x}_{t-1}; \\beta_t) = \\mathcal{N}(\\mathbf{x}_t; \\sqrt{1 - \\beta_t} \\mathbf{x}_{t-1}, \\beta_t \\mathbf{I}) \\tag{26} $$\nA nice property of the above process is that we can sample $\\mathbf{x}_t$ at any arbitrary time step $t$ in a closed form using reparameterization trick. Let $\\alpha_t = 1 - \\beta_t$ and $\\bar{\\alpha}_t = \\prod_{i=1}^t \\alpha_i$ : $$ \\begin{equation*} \\begin{split} \\mathbf{x}_t \u0026amp;= \\sqrt{\\alpha_t} {\\color{blue} \\mathbf{x}_{t-1}} + \\sqrt{1 - \\alpha_t} \\bm{\\epsilon}_{t-1} \\\\ \u0026amp;= \\sqrt{\\alpha_t} {\\color{blue} (\\sqrt{\\alpha_{t-1}} \\mathbf{x}_{t-2} + \\sqrt{1 - \\alpha_{t-1}} \\bm{\\epsilon}_{t-2})} + \\sqrt{1 - \\alpha_t} \\bm{\\epsilon}_{t-1} \\\\ \u0026amp;= \\sqrt{\\alpha_t \\alpha_{t-1}} \\mathbf{x}_{t-2} + {\\color{red} \\sqrt{\\alpha_t - \\alpha_t \\alpha_{t-1}} \\bm{\\epsilon}_{t-2} + \\sqrt{1 - \\alpha_t} \\bm{\\epsilon}_{t-1}} \\\\ \u0026amp;= \\sqrt{\\alpha_t \\alpha_{t-1}} \\mathbf{x}_{t-2} + {\\color{red} \\sqrt{\\sqrt{\\alpha_t - \\alpha_t \\alpha_{t-1}}^2 + \\sqrt{1 - \\alpha_t}^2} \\bar{\\bm{\\epsilon}}_{t-2}} \\\\ \u0026amp;= \\sqrt{\\alpha_t \\alpha_{t-1}} \\mathbf{x}_{t-2} + \\sqrt{1 - \\alpha_t \\alpha_{t-1}} \\bar{\\bm{\\epsilon}}_{t-2} \\\\ \u0026amp;= \\cdots \\\\ \u0026amp;= \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_{0} + \\sqrt{1 - \\bar{\\alpha}_t} \\bar{\\bm{\\epsilon}}_0 \\\\ \u0026amp;= \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_{0} + \\sqrt{1 - \\bar{\\alpha}_t} {\\color{green} \\bm{\\epsilon}_{t}} \\quad \\text{; to correspond to the subscript of } \\mathbf{x}_t \\\\ \\end{split} \\end{equation*} \\tag{27} $$ where ${\\color{green} \\bm{\\epsilon}_{t}}, \\bm{\\epsilon}_{t-1}, \\bm{\\epsilon}_{t-2}, \\cdots \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$.\nRecall the red part of Eq. (27) when we merge two Gaussians with different variance, $\\mathcal{N}(\\mathbf{0}, \\sigma_1^2\\mathbf{I})$ and $\\mathcal{N}(\\mathbf{0}, \\sigma_2^2\\mathbf{I})$, the new distribution is $\\mathcal{N}(\\mathbf{0}, (\\sigma_1^2 + \\sigma_2^2)\\mathbf{I})$.\nThus, we have $$ q(\\mathbf{x}_t | \\mathbf{x}_0) = \\mathcal{N}(\\mathbf{x}_t; \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0, (1 - \\bar{\\alpha}_t) \\mathbf{I}) \\tag{28} $$\nUsually, we can afford a larger update step when the sample gets noisier, so $\\beta_1 \u0026lt; \\beta_2 \u0026lt; \\cdots \u0026lt; \\beta_T$ and therefore $\\bar{\\alpha}_1 \u0026gt; \\bar{\\alpha}_2 \u0026gt; \\cdots \u0026gt; \\bar{\\alpha}_T$.\nReverse Process According to Eq. (26), $$ p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t) = \\mathcal{N}(\\mathbf{x}_{t-1}; \\bm{\\mu}_\\theta(\\mathbf{x}_t, t), \\bm{\\sigma}_\\theta(\\mathbf{x}_t, t)) \\tag{29} $$\nIt is noteworthy that the reverse conditional probability is tractable when conditioned on $\\mathbf{x}_0$: $$ q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) = \\mathcal{N}(\\mathbf{x}_{t-1}; { \\bm{\\tilde{\\mu}}_t(\\mathbf{x}_t, \\mathbf{x}_0)}, { \\tilde{\\beta}_t \\mathbf{I}}) \\tag{30} $$\nUsing Bayes\u0026rsquo; rule, we have: $$ \\begin{equation*} \\begin{split} q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) \u0026amp;= q(\\mathbf{x}_{t} | \\mathbf{x}_{t-1}, \\mathbf{x}_0) \\frac{q(\\mathbf{x}_{t-1} | \\mathbf{x}_0)}{q(\\mathbf{x}_{t} | \\mathbf{x}_0)} \\quad ; \\text{bringing in Eq. (26) and Eq. (28)} \\\\ \u0026amp;\\propto \\exp \\left ( -\\frac{1}{2}(\\frac{(\\mathbf{x}_t - \\sqrt{\\alpha_t} \\mathbf{x}_{t-1})^2}{\\beta_t}) \\right ) \\frac{\\displaystyle \\exp \\left ( -\\frac{1}{2}( \\frac{(\\mathbf{x}_{t-1} - \\sqrt{\\bar{\\alpha}_{t-1}} \\mathbf{x}_0)^2}{1 - \\bar{\\alpha}_{t-1}} ) \\right ) }{\\displaystyle \\exp \\left ( -\\frac{1}{2}( \\frac{(\\mathbf{x}_{t} - \\sqrt{\\bar{\\alpha}_{t}} \\mathbf{x}_0)^2}{1 - \\bar{\\alpha}_{t}} ) \\right ) } \\\\ \u0026amp;= \\exp \\left ( -\\frac{1}{2} ( \\frac{(\\mathbf{x}_t - \\sqrt{\\alpha_t} \\mathbf{x}_{t-1})^2}{\\beta_t} + \\frac{(\\mathbf{x}_{t-1} - \\sqrt{\\bar{\\alpha}_{t-1}} \\mathbf{x}_0)^2}{1 - \\bar{\\alpha}_{t-1}} - \\frac{(\\mathbf{x}_{t} - \\sqrt{\\bar{\\alpha}_{t}} \\mathbf{x}_0)^2}{1 - \\bar{\\alpha}_{t}} ) \\right ) \\\\ \u0026amp;= \\exp \\left ( -\\frac{1}{2}( \\frac{ \\mathbf{x}_t^2 - 2\\sqrt{\\alpha_t} \\mathbf{x}_t {\\color{blue} \\mathbf{x}_{t-1}} + \\alpha_t {\\color{red} \\mathbf{x}_{t-1}^2} }{\\beta_t} + \\frac{ {\\color{red} \\mathbf{x}_{t-1}^2} -2\\sqrt{\\bar{\\alpha}_{t-1}}\\mathbf{x}_0 {\\color{blue} \\mathbf{x}_{t-1}} + \\bar{\\alpha}_{t-1} \\mathbf{x}_0^2 }{1 - \\bar{\\alpha}_{t-1}} \\right. \\\\ \u0026amp;\\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\left. - \\ \\frac{(\\mathbf{x}_{t} - \\sqrt{\\bar{\\alpha}_{t}} \\mathbf{x}_0)^2}{1 - \\bar{\\alpha}_{t}} ) \\right ) \\\\ \u0026amp;= \\exp \\left ( -\\frac{1}{2} {\\Large (} (\\frac{\\alpha_t}{\\beta_t} + \\frac{1}{1 - \\bar{\\alpha}_{t-1}}) {\\color{red} \\mathbf{x}_{t-1}^2} - (\\frac{2\\sqrt{\\alpha_t}}{\\beta_t} \\mathbf{x}_t + \\frac{2\\sqrt{\\bar{\\alpha}_{t-1}}}{1 - \\bar{\\alpha}_{t-1}} \\mathbf{x}_t) {\\color{blue} \\mathbf{x}_{t-1}} + C(\\mathbf{x}_t, \\mathbf{x}_0) {\\Large )} \\right ) \\end{split} \\end{equation*} \\tag{31} $$ where $C(\\mathbf{x}_t, \\mathbf{x}_0)$ is some function not involving $\\mathbf{x}_{t-1}$ and details are omitted.\nFollowing the general form of $\\mathcal{N}(\\mu, \\sigma^2)$ probability density function $f(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\left ( -\\frac{1}{2} (\\frac{x - \\mu}{\\sigma})^2 \\right )$, $$ (\\frac{\\alpha_t}{\\beta_t} + \\frac{1}{1 - \\bar{\\alpha}_{t-1}}) {\\color{red} \\mathbf{x}_{t-1}^2} - (\\frac{2\\sqrt{\\alpha_t}}{\\beta_t} \\mathbf{x}_t + \\frac{2\\sqrt{\\bar{\\alpha}_{t-1}}}{1 - \\bar{\\alpha}_{t-1}} \\mathbf{x}_t) {\\color{blue} \\mathbf{x}_{t-1}} + C(\\mathbf{x}_t, \\mathbf{x}_0) = (\\frac{x-\\mu}{\\sigma})^2 = \\frac{{\\color{red} x^2} - 2\\mu {\\color{blue} x} + \\mu^2}{\\sigma^2} \\tag{32} $$\nThe variance $(\\tilde{\\beta}_t \\mathbf{I})$ and mean $(\\bm{\\tilde{\\mu}}_t(\\mathbf{x}_t, \\mathbf{x}_0))$ in Eq. (30) can be parameterized as follows: $$ \\begin{equation*} \\begin{split} \\tilde{\\beta}_t = 1 / (\\frac{\\alpha_t}{\\beta_t} + \\frac{1}{1 - \\bar{\\alpha}_{t-1}}) = \\frac{1 - \\bar{\\alpha}_{t-1}}{1 - \\bar{\\alpha}_{t}} \\beta_t \\end{split} \\end{equation*} \\tag{33} $$\n$$ \\begin{equation*} \\begin{split} \\bm{\\tilde{\\mu}}_t(\\mathbf{x}_t, \\mathbf{x}_0) \u0026amp;= \\frac{(\\frac{2\\sqrt{\\alpha_t}}{\\beta_t} \\mathbf{x}_t + \\frac{2\\sqrt{\\bar{\\alpha}_{t-1}}}{1 - \\bar{\\alpha}_{t-1}} \\mathbf{x}_t) \\tilde{\\beta}_t }{-2} = \\frac{\\sqrt{\\alpha}_t (1 - \\bar{\\alpha}_{t-1})}{1 - \\bar{\\alpha}_t} \\mathbf{x}_t + \\frac{\\sqrt{\\bar{\\alpha}_{t-1}} \\beta_t}{1 - \\bar{\\alpha}_t} \\mathbf{x}_0 \\end{split} \\end{equation*} \\tag{34} $$\nThanks to the nice property, we can represent Eq. (27) to $\\mathbf{x}_0 = (\\mathbf{x}_t - \\sqrt{1 - \\bar{\\alpha}_t} \\bm{\\epsilon}_t) / \\sqrt{\\bar{\\alpha}_t}$ and bring it into Eq. (34), $$ \\begin{equation*} \\begin{split} \\bm{\\mu}_t(\\mathbf{x}_t) \u0026amp;= \\bm{\\tilde{\\mu}}_t\\left (\\mathbf{x}_t, (\\mathbf{x}_t - \\sqrt{1 - \\bar{\\alpha}_t} \\bm{\\epsilon}_t) / \\sqrt{\\bar{\\alpha}_t} \\right ) \\\\ \u0026amp;= \\frac{\\sqrt{\\alpha}_t (1 - \\bar{\\alpha}_{t-1})}{1 - \\bar{\\alpha}_t} \\mathbf{x}_t + \\frac{\\sqrt{\\bar{\\alpha}_{t-1}} \\beta_t}{1 - \\bar{\\alpha}_t} (\\frac{(\\mathbf{x}_t - \\sqrt{1 - \\bar{\\alpha}_t} \\bm{\\epsilon}_t)}{\\sqrt{\\bar{\\alpha}_t}}) \\\\ \u0026amp;= {\\color{red} \\frac{1}{\\sqrt{\\alpha_t}} \\left ( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\bm{\\epsilon}_t \\right ) } \\end{split} \\end{equation*} \\tag{35} $$\nLoss Function We define the lower bound of the negative log likelihood as the variational lower bound loss function, $$ \\begin{equation*} \\begin{split} \\mathcal{L}_{VLB} \u0026amp;= - \\mathcal{K} \\\\ \u0026amp;= \\sum_{t=2}^T \\int \\mathrm{d}\\mathbf{x}_{0}\\mathrm{d}\\mathbf{x}_{t} \\ q(\\mathbf{x}_0, \\mathbf{x}_t) {\\color{blue} \\mathcal{D}_{KL}(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) \\| p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t))} \\\\ \u0026amp;\\quad - \\mathcal{H}_q(\\mathbf{x}_T | \\mathbf{x}_0) + \\mathcal{H}_q(\\mathbf{x}_1 | \\mathbf{x}_0) + \\mathcal{H}_p(\\mathbf{x}_T) \\\\ \u0026amp;= \\sum_{t=2}^T {\\Large \\mathbb{E}}_{\\mathbf{x}_0, \\mathbf{x}_t \\sim q(\\mathbf{x}_0, \\mathbf{x}_t)} {\\Large [} \\underbrace{\\color{blue} \\mathcal{D}_{KL}(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) \\| p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t))}_{\\color{blue} \\mathcal{L}_{t-1}} {\\Large ]} - \\mathcal{H}_q(\\mathbf{x}_T | \\mathbf{x}_0) + \\mathcal{H}_q(\\mathbf{x}_1 | \\mathbf{x}_0) + \\mathcal{H}_p(\\mathbf{x}_T) \\end{split} \\end{equation*} \\tag{36} $$\nRecall that we need to learn a model to approximate the conditioned probability distributions in the reverse diffusion process, $p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t) = \\mathcal{N}(\\mathbf{x}_{t-1}; \\bm{\\mu}_\\theta(\\mathbf{x}_t, t), \\bm{\\sigma}_\\theta(\\mathbf{x}_t, t))$. We would like to train $\\bm{\\mu}_\\theta(\\mathbf{x}_t, t)$ to predict $\\bm{\\mu}_t(\\mathbf{x}_t)$ in Eq. (35), and set $\\bm{\\sigma}_\\theta(\\mathbf{x}_t, t)$ is equal to $\\sigma_t^2\\mathbf{I}$, where $\\sigma_t^2$ is equal to $\\tilde{\\beta}_t$ in Eq. (33) or $\\beta_t$ for simplify. The loss term $\\mathcal{L}_{t-1}$ in Eq. (36) is parameterized to minimize the difference from $\\bm{\\mu}_t(\\mathbf{x}_t)$: $$ \\begin{equation*} \\begin{split} \\mathcal{L}_{t-1} \u0026amp;= \\mathcal{D}_{KL}(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) \\| p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t)) \\\\ \u0026amp;= \\int \\mathrm{d}\\mathbf{x}_{t-1} \\ q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) \\log \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_(t))}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_(t), \\mathbf{x}_0)} \\\\ \u0026amp;= {\\Large \\mathbb{E}}_{\\small \\mathbf{x}_{t-1} \\sim q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0)} \\left [ \\log \\frac{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_(t))}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_(t), \\mathbf{x}_0)} \\right ] \\\\ \u0026amp;\\propto {\\Large \\mathbb{E}}_{\\small \\mathbf{x}_0 \\sim q(\\mathbf{x}_0), \\bm{\\epsilon}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})} \\left [ \\frac{1}{2\\sigma_t^2} \\left \\| {\\color{blue} \\bm{\\mu}_t(\\mathbf{x}_t)} - {\\color{red} \\bm{\\mu}_\\theta(\\mathbf{x}_t, t)} \\right \\| ^2 \\right ] \\\\ \u0026amp;= {\\Large \\mathbb{E}}_{\\small \\mathbf{x}_0 \\sim q(\\mathbf{x}_0), \\bm{\\epsilon}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})} \\left [ \\frac{1}{2\\sigma_t^2} \\left \\| {\\color{blue} \\frac{1}{\\sqrt{\\alpha_t}} \\left ( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\bm{\\epsilon}_t \\right )} - {\\color{red} \\bm{\\mu}_\\theta(\\mathbf{x}_t, t)} \\right \\| ^2 \\right ] \\end{split} \\end{equation*} \\tag{37} $$\nBecause $\\mathbf{x}_t$ is available as input at training time, we can reparameterize the Gaussian noise term instead to make it predict $\\bm{\\epsilon}$ from the input $\\mathbf{x}_t$ at time step $t$: $$ \\bm{\\mu}_\\theta(\\mathbf{x}_t, t) = \\frac{1}{\\sqrt{\\alpha_t}} \\left ( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}}_t} \\bm{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\right ) \\tag{38} $$ where $\\bm{\\epsilon}_\\theta$ is a function approximator (the model) intended to predict $\\bm{\\epsilon}$ from $\\mathbf{x}_t$.\nThus, Eq. (29) can be written as $$ p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t}) = \\mathcal{N} \\left ( \\mathbf{x}_{t-1} ; \\frac{1}{\\sqrt{\\alpha_t}} \\left ( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}}_t} \\bm{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\right ) , \\tilde{\\beta}_t \\mathbf{I} \\right ) \\tag{39} $$\nAccording to Eq. (39), sampling $\\mathbf{x}_{t-1} \\sim p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_{t})$ is: $$ \\mathbf{x}_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left ( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}}_t} \\bm{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\right ) + \\sqrt{\\tilde{\\beta}_t} \\bm{\\epsilon}^* \\tag{40} $$ where $\\bm{\\epsilon}^* \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$.\nFurthermore, with the parameterization Eq. (38), the $\\mathcal{L}_{t-1}$ in Eq. (37) simplifies to: $$ \\begin{equation*} \\begin{split} \\mathcal{L}_{t-1} \u0026amp;= {\\Large \\mathbb{E}}_{\\small \\mathbf{x}_0 \\sim q(\\mathbf{x}_0), \\bm{\\epsilon}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})} \\left [ \\frac{1}{2\\sigma_t^2} \\left \\| {\\color{blue} \\frac{1}{\\sqrt{\\alpha_t}} \\left ( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\bm{\\epsilon}_t \\right )} - {\\color{red} \\bm{\\mu}_\\theta(\\mathbf{x}_t, t)} \\right \\| ^2 \\right ] \\\\ \u0026amp;= {\\Large \\mathbb{E}}_{\\small \\mathbf{x}_0 \\sim q(\\mathbf{x}_0), \\bm{\\epsilon}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})} \\left [ \\frac{1}{2\\sigma_t^2} \\left \\| {\\color{blue} \\frac{1}{\\sqrt{\\alpha_t}} \\left ( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\bm{\\epsilon}_t \\right )} - {\\color{red} \\frac{1}{\\sqrt{\\alpha_t}} \\left ( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}}_t} \\bm{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\right )} \\right \\| ^2 \\right ] \\\\ \u0026amp;= {\\Large \\mathbb{E}}_{\\small \\mathbf{x}_0 \\sim q(\\mathbf{x}_0), \\bm{\\epsilon}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})} \\left [ \\frac{1}{2\\sigma_t^2} \\left \\| \\frac{1}{\\sqrt{\\alpha_t}} \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\left (\\bm{\\epsilon}_t - \\bm{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\right ) \\right \\| ^2 \\right ] \\\\ \u0026amp;= {\\Large \\mathbb{E}}_{\\small \\mathbf{x}_0 \\sim q(\\mathbf{x}_0), \\bm{\\epsilon}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})} \\left [ \\frac{\\beta_t^2}{2 \\alpha_t (1 - \\alpha_t) \\sigma_t^2} \\left \\| \\bm{\\epsilon}_t - \\bm{\\epsilon}_\\theta({\\color{orange} \\mathbf{x}_t}, t) \\right \\| ^2 \\right ] \\quad ; \\text{bringing in Eq. (27)} \\\\ \u0026amp;= {\\Large \\mathbb{E}}_{\\small \\mathbf{x}_0 \\sim q(\\mathbf{x}_0), \\bm{\\epsilon}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})} \\left [ {\\color{green} \\frac{\\beta_t^2}{2 \\alpha_t (1 - \\alpha_t) \\sigma_t^2}} \\left \\| \\bm{\\epsilon}_t - \\bm{\\epsilon}_\\theta({\\color{orange} \\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\bm{\\epsilon}_t}, t) \\right \\| ^2 \\right ] \\\\ \\end{split} \\end{equation*} \\tag{41} $$\nSimplification Empirically, Ho et al. (2020) found that training the diffusion model works better with a simplified objective that ignores the weighting term (the green part in Eq. (41)): $$ \\mathcal{L}_t^{\\text{simple}} = {\\Large \\mathbb{E}}_{\\small \\mathbf{x}_0 \\sim q(\\mathbf{x}_0), \\bm{\\epsilon}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})} \\left [ \\left \\| \\bm{\\epsilon}_t - \\bm{\\epsilon}_\\theta(\\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\bm{\\epsilon}_t, t) \\right \\| ^2 \\right ] \\tag{42} $$\nSimple Code Implementation The jupyter notebook is available at GitHub Gist.\nYou can click the button at the top of the notebook to open it in Colab and run the code for free.\nCitation Cited as:\nGavin, Sun. (May 2023). A Brief Exploration to Diffusion Probabilistic Models [Blog post]. Retrieved from https://gavinsun0921.github.io/posts/paper-reading-01/. Or\n@online{gavin2023diffusion, title = {A Brief Exploration to Diffusion Probabilistic Models}, author = {Gavin, Sun}, year = {2023}, month = {May}, url = {\\url{https://gavinsun0921.github.io/posts/paper-reading-01/}} } References [1] Jascha Sohl-Dickstein et al. \u0026ldquo;Deep Unsupervised Learning using Nonequilibrium Thermodynamics.\u0026rdquo; ICML 2015.\n[2] Jonathan Ho et al. \u0026ldquo;Denoising Diffusion Probabilistic Models.\u0026rdquo; NeurIPS 2020.\n[3] Jiaming Song et al. \u0026ldquo;Denoising Diffusion Implicit Models.\u0026rdquo; ICLR 2021.\n[4] Alex Nichol \u0026amp; Prafulla Dhariwal. \u0026ldquo;Improved Denoising Diffusion Probabilistic Models.\u0026rdquo; ICML 2021.\n[5] Lilian Weng. \u0026ldquo;What are Diffusion Models? Lil’Log.\u0026rdquo; [Blog post] Lil\u0026rsquo;Log 2021.\n[6] Ayan Das. \u0026ldquo;An Introduction to Diffusion Probabilistic Models.\u0026rdquo; [Blog post] Ayan\u0026rsquo;s Blog 2021.\n","permalink":"https://gavinsun0921.github.io/posts/paper-research-01/","summary":"Learn diffusion probabilistic models (DPM) by reading and analyzing the papers: \u0026ldquo;Deep Unsupervised Learning using Nonequilibrium Thermodynamics\u0026rdquo; and \u0026ldquo;Denoising Diffusion Probabilistic Models\u0026rdquo;. This post will introduce the basic work of DPM, including the derivation of formulas and simple code verification.","title":"A Brief Exploration to Diffusion Probabilistic Models with Code Implementation"},{"content":"👋 Hi, I\u0026rsquo;m Gavin Sun (孙国栋) I\u0026rsquo;m a PhD student at the Northwestern Polytechnical University, advised by Prof. Yuchao Dai. My research focuses on 3D/4D Reconstruction \u0026amp; Generation. I\u0026rsquo;m especially interested in developing robust and scalable methods for dynamic scene understanding, and exploring how tracking and generative priors can enhance 4D representations.\n📚 Education PhD Candidate (2025 - Present) Northwestern Polytechnical University Majoring in Information and Communication Engineering Master Degree (2022 - 2025) Northwestern Polytechnical University Majoring in Artificial Intelligence Bachelor Degree (2018-2022) Shandong University of Science and Technology Majoring in Statistics 🏆 Selected Awards 2022 \u0026ldquo;航天宏图杯\u0026rdquo; 遥感影像智能处理算法大赛 - 国家自然学科基金委信息科学部 - 全国冠军（十万元） 2023 \u0026ldquo;国丰东方慧眼杯\u0026rdquo; 遥感影响智能处理算法大赛 - 国家自然学科基金委信息科学部 - 全国亚军（三万元） 中国高校计算机大赛 2020团体程序设计天梯赛 - 全国高等学校计算机教育研究会 - 团队金奖 The 2020 ICPC Asia Nanjing Regional Contest - The International Collegiate Programming Contest Foundation - Silver Medal The 2019 ICPC Asia Shanghai Regional Contest - The International Collegiate Programming Contest Foundation - Bronze Medal 2024 华为软件精英挑战赛——普朗克计划 - 华为技术有限公司 - 西北赛区二等奖 昇腾AI创新大赛2023全国总决赛 - 华为技术有限公司 - 铜奖 📖 Selected Publications Cong Wang, Guodong Sun (共同第一作者 \u0026amp; 第一学生作者), Cailing Wang, Zixuan Gao and Hongwei Wang, \u0026ldquo;Monte Carlo-Based Restoration of Images Degraded by Atmospheric Turbulence,\u0026rdquo; in IEEE Transactions on Systems, Man, and Cybernetics: Systems, vol. 54, no. 11, pp. 6610-6620, Nov. 2024, doi: 10.1109/TSMC.2024.3399464. Qixiang Ma, Jian Wu, Runze Fan, Guodong Sun, Xuehuai Shi, \u0026ldquo;ViP-Fluid: Visual Perception Driven Method for VR Fluid Rendering,\u0026rdquo; 2024 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), Bellevue, WA, USA, 2024, pp. 359-367, doi: 10.1109/ISMAR62088.2024.00050. Guodong Sun, Qixiang Ma, Liqiang Zhang, Hongwei Wang, Zixuan Gao, Haotian Zhang, \u0026ldquo;Probabilistic Prior Driven Attention Mechanism Based on Diffusion Model for Imaging Through Atmospheric Turbulence,\u0026rdquo; arXiv preprint, arXiv:2411.10321, 2024. 🌐 Connect With Me Google Scholar: Gavin Sun GitHub: @GavinSun0921 Email: gavinsun0921@foxmail.com Feel free to reach out if you\u0026rsquo;re interested in collaboration or have any questions about my research!\n","permalink":"https://gavinsun0921.github.io/about/","summary":"\u003ch2 id=\"-hi-im-gavin-sun-孙国栋\"\u003e👋 Hi, I\u0026rsquo;m Gavin Sun (孙国栋)\u003c/h2\u003e\n\u003cp\u003eI\u0026rsquo;m a PhD student at the \u003cstrong\u003eNorthwestern Polytechnical University\u003c/strong\u003e, advised by Prof. \u003ca href=\"https://scholar.google.com/citations?user=fddAbqsAAAAJ\u0026amp;hl=en\"\u003eYuchao Dai\u003c/a\u003e. My research focuses on \u003cstrong\u003e3D/4D Reconstruction \u0026amp; Generation\u003c/strong\u003e. I\u0026rsquo;m especially interested in developing robust and scalable methods for dynamic scene understanding, and exploring how tracking and generative priors can enhance 4D representations.\u003c/p\u003e\n\u003ch2 id=\"-education\"\u003e📚 Education\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ePhD Candidate\u003c/strong\u003e (2025 - Present)\n\u003cul\u003e\n\u003cli\u003eNorthwestern Polytechnical University\u003c/li\u003e\n\u003cli\u003eMajoring in \u003cstrong\u003eInformation and Communication Engineering\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMaster Degree\u003c/strong\u003e (2022 - 2025)\n\u003cul\u003e\n\u003cli\u003eNorthwestern Polytechnical University\u003c/li\u003e\n\u003cli\u003eMajoring in \u003cstrong\u003eArtificial Intelligence\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eBachelor Degree\u003c/strong\u003e (2018-2022)\n\u003cul\u003e\n\u003cli\u003eShandong University of Science and Technology\u003c/li\u003e\n\u003cli\u003eMajoring in \u003cstrong\u003eStatistics\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"-selected-awards\"\u003e🏆 Selected Awards\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e2022 \u0026ldquo;航天宏图杯\u0026rdquo; 遥感影像智能处理算法大赛 - 国家自然学科基金委信息科学部 - \u003cstrong\u003e全国冠军\u003c/strong\u003e（十万元）\u003c/li\u003e\n\u003cli\u003e2023 \u0026ldquo;国丰东方慧眼杯\u0026rdquo; 遥感影响智能处理算法大赛 - 国家自然学科基金委信息科学部 - \u003cstrong\u003e全国亚军\u003c/strong\u003e（三万元）\u003c/li\u003e\n\u003cli\u003e中国高校计算机大赛 2020团体程序设计天梯赛 - 全国高等学校计算机教育研究会 - \u003cstrong\u003e团队金奖\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eThe 2020 ICPC Asia Nanjing Regional Contest - The International Collegiate Programming Contest Foundation - \u003cstrong\u003eSilver Medal\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eThe 2019 ICPC Asia Shanghai Regional Contest - The International Collegiate Programming Contest Foundation - \u003cstrong\u003eBronze Medal\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e2024 华为软件精英挑战赛——普朗克计划 - 华为技术有限公司 - 西北赛区二等奖\u003c/li\u003e\n\u003cli\u003e昇腾AI创新大赛2023全国总决赛 - 华为技术有限公司 - 铜奖\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"-selected-publications\"\u003e📖 Selected Publications\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eCong Wang, \u003cstrong\u003eGuodong Sun\u003c/strong\u003e (共同第一作者 \u0026amp; 第一学生作者), Cailing Wang, Zixuan Gao and Hongwei Wang, \u0026ldquo;Monte Carlo-Based Restoration of Images Degraded by Atmospheric Turbulence,\u0026rdquo; in \u003cstrong\u003eIEEE Transactions on Systems, Man, and Cybernetics: Systems\u003c/strong\u003e, vol. 54, no. 11, pp. 6610-6620, Nov. 2024, doi: 10.1109/TSMC.2024.3399464.\u003c/li\u003e\n\u003cli\u003eQixiang Ma, Jian Wu, Runze Fan, \u003cstrong\u003eGuodong Sun\u003c/strong\u003e, Xuehuai Shi, \u0026ldquo;ViP-Fluid: Visual Perception Driven Method for VR Fluid Rendering,\u0026rdquo; \u003cstrong\u003e2024 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)\u003c/strong\u003e, Bellevue, WA, USA, 2024, pp. 359-367, doi: 10.1109/ISMAR62088.2024.00050.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eGuodong Sun\u003c/strong\u003e, Qixiang Ma, Liqiang Zhang, Hongwei Wang, Zixuan Gao, Haotian Zhang, \u0026ldquo;Probabilistic Prior Driven Attention Mechanism Based on Diffusion Model for Imaging Through Atmospheric Turbulence,\u0026rdquo; arXiv preprint, arXiv:2411.10321, 2024.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"-connect-with-me\"\u003e🌐 Connect With Me\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eGoogle Scholar\u003c/strong\u003e: \u003ca href=\"https://scholar.google.com/citations?user=IwscJpsAAAAJ\u0026amp;hl=en\"\u003eGavin Sun\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eGitHub\u003c/strong\u003e: \u003ca href=\"https://github.com/GavinSun0921\"\u003e@GavinSun0921\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEmail\u003c/strong\u003e: \u003ca href=\"mailto:gavinsun0921@foxmail.com\"\u003egavinsun0921@foxmail.com\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cem\u003eFeel free to reach out if you\u0026rsquo;re interested in collaboration or have any questions about my research!\u003c/em\u003e\u003c/p\u003e","title":"About Me"}]